{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Textile documentation. \u00b6 Textile is designed to connect and extend Libp2p , IPFS , and Filecoin . Latest announcements \u00b6 Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. We've been working hard to deliver you new and improved tools building on Web3. Today, we are excited to announce Tableland, where we are building a novel protocol to enable relational tables and SQL in Web3. Come learn more about our plans, join our community, or get started as a developer. https://t.co/DY9ouVxT0f \u2014 Tableland (@tableland__) February 17, 2022 Read the docs over at https://tableland.xyz/ . Thanks! \u00b6 To all of the great people who have contributed to the Textile projects recently.","title":"Home"},{"location":"#welcome-to-the-textile-documentation","text":"Textile is designed to connect and extend Libp2p , IPFS , and Filecoin .","title":"Welcome to the Textile documentation."},{"location":"#latest-announcements","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. We've been working hard to deliver you new and improved tools building on Web3. Today, we are excited to announce Tableland, where we are building a novel protocol to enable relational tables and SQL in Web3. Come learn more about our plans, join our community, or get started as a developer. https://t.co/DY9ouVxT0f \u2014 Tableland (@tableland__) February 17, 2022 Read the docs over at https://tableland.xyz/ .","title":"Latest announcements"},{"location":"#thanks","text":"To all of the great people who have contributed to the Textile projects recently.","title":"Thanks!"},{"location":"buckets/","text":"Buckets \u00b6 Getting Started \u00b6 If you're familiar with cloud storage, you'll find buckets easy to understand. However, unlike traditional cloud services, buckets are built on open, decentralized protocols including the IPFS and Libp2p. You can serve websites, data, and apps from buckets. Buckets are packed with useful features: Explore your Buckets on the Hub gateway . Render web content in your Bucket on a persistent website . Automatically distribute your updates on IPFS using IPNS . Collaboratively manage Buckets as an organization . Create private Buckets where your app users can store data . (Soon) Archive Bucket data on Filecoin to ensure long-term security and access to your files. Initialize a Bucket \u00b6 To start a Bucket in your current working directory, you must first initialize it. You can initialize a bucket with an existing UnixFS DAG, available in the IPFS network, or import it interactively in an existing bucket. When working on your local machine, buckets are mapped to working directories. Once you initialize a bucket in a directory, anytime you return to the directory, the Textile CLI will automatically detect the Bucket you're interacting with. Read CLI docs for buckets . Info Bucket names are unique to a developer and within an Org. They're not globally unique. Warning Be careful about creating a bucket in a root directory because all children directories become linked to that bucket. To move or remove a bucket's link to a directory, edit, move or delete the .textile/config.yml file (it will be a hidden folder in the bucket's directory) Shared buckets \u00b6 You can create buckets to share with all members of an organization. To do so, simply initialize an Org first and then initialize a Bucket using the HUB_ORG environmental flag, by specifying the name of the Org you want to share the bucket with. For example, HUB_ORG=astronauts hub bucket init . All members of the Org will be able to push and pull files to and from the shared Bucket. Read more about creating Orgs . Info To check which org a bucket is registered with, examine the .textile/config.yml file (it will be a hidden folder in the bucket's directory). Encrypted buckets \u00b6 It's possible to create encrypted buckets. The contents of encrypted buckets will still exist on IPFS but the contents will be obfuscated to any viewer that doesn't have access to the encryption keys. You can choose to create encrypted buckets when creating them in the CLI or when initializing them in the JavaScript library . Publishing content \u00b6 Push new files \u00b6 View the Bucket push CLI docs . hub bucket push Diffing and Syncing \u00b6 When a bucket is pushed to the remote API (the Hub): Its Merkle DAG representation is saved locally as a reference of the latest pushed version. When you execute hub buck status , it compares the persisted Merkle DAG with a generated Merkle DAG of the Bucket local state. Walking both DAGs and comparing CIDs can quickly provide paths that changed to the last known version. In a nutshell, when a bucket is pushed, the persisted Merkle DAG contains the minimum amount of information about the directory structure and data fingerprints. Read more about this process . Encryption \u00b6 You can encrypt bucket contents by opting-in to the option when you create your bucket. The encryption setup is based on AES-CTR + AES-512 HMAC as seen here . This is a modified version of the encryption library Google Drive uses to handle large streams (files). Encrypted buckets have a couple of goals: Obfuscate bucket data/files (the normal goal of encryption). Obfuscate directory structure, which means encrypting IPLD nodes and their links. The AES and HMAC keys used for bucket encryption are stored in the ThreadDB collection instance. That means each bucket has a model entry as a key. This setup allows for bucket access to be inherited by thread ACL rules. This also means that if you can break into the thread, and you gain access to the thread read key, you can decrypt the bucket content. As a compromise, we've added some convenience methods to the local buck client which allows you to encrypt content locally (protected by a password) before it gets added to the bucket. This has the downside that you must remember the password. Finally, you can run the standalone buckets daemon buckd locally and use a remote peer as a thread replicator (no read key access). This means that there\u2019s no downside to the keys being stored in the bucket collection instance. Password-based encryption uses the same approach but also leverages scrypt to derive the keys from the password. This carries the normal tradeoff: The encryption is only as good as the password. Retrieving content \u00b6 Pull files \u00b6 hub bucket init --existing Info Use the --existing flag to list buckets already pushed by you. Use HUB_ORG to list buckets already pushed by your collaborators. Explore on the gateway \u00b6 To inspect your pushed files, explore on the gateway: hub bucket links then open the first result 'Thread links' in your browser. The Hub gateway gives you a static URL where you can explore, download, and share your latest Bucket content. Render on a website \u00b6 If your Bucket contains web content, the Bucket website endpoint will provide you a static URL that'll always render the latest content from your Bucket. See HTTP Domains . Render on IPFS gateways \u00b6 Buckets are dynamic folders distributed over IPFS using ThreadDB. Each time you create a new Bucket, you'll receive a new IPNS Address that you can use on the IPFS address to fetch the latest Bucket content. The IPNS address will not change but the content will update each time you push changes to your Bucket. Each time you update your Bucket, you'll receive a new IPFS address to fetch that version of your Bucket content. HTTP Domain \u00b6 All public Buckets are automatically provided a subdomain on textile.space that reflects the latest changes in your Bucket. Your Bucket's IPNS address is used as the subdomain, such that your Bucket URL will always be: <ipns-address>.textile.space . This is designed to enhance the interoperability of protocols using Textile Buckets. IPNS Address \u00b6 Each Bucket has a unique IPNS address that allows you to render or fetch your Bucket on any IPFS peer or gateway that supports IPNS, including ipfs.io and Cloudflare . Buckets can't change the speed of IPNS propagation through the network but we recommend you explore and try for yourself. The Hub gateway will always render the latest data right away. Bucket Automation (CI/CD) \u00b6 Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions make this easy. We've provided a configurable GitHub Action that allows you to: Push or update your Bucket based on pull requests, commits, and merges. Generate IPNS, IPFS, and HTTP addresses for every Bucket creation or update. Create temporary Buckets for staging or review that can be removed automatically when content is merged or pull requests are closed. Example output from Textile Bucket GitHub Action Cross Protocol Support \u00b6 Buckets are designed to be interoperable across protocols and services. Here are a few examples. Buckets and Threads \u00b6 Buckets are built on ThreadDB . In fact, in their most basic form, Buckets are just a document in a Thread that is updated each time the directory of data is updated. Since buckets run on Threads, it opens the door to many new integrations that can be built on Buckets! Buckets and HTTP \u00b6 Buckets can be rendered over HTTP through either the Hub Gateway , the Bucket subdomains , or on any IPFS gateway supporting IPNS (see below). Buckets and IPFS \u00b6 Data in a Bucket is stored as IPLD and pinned on IPFS. You can use the underlying content addresses to pin new Bucket content on additional pinning services such as Pinata or Infura . This can be useful if you want additional replication of your content on the IPFS network. Buckets and IPNS \u00b6 Every Bucket you create has a unique ID associated with it. The Bucket ID is an IPNS address that you can use to fetch the latest Bucket content from any IPFS peer or view it over IPFS gateways that support the IPNS protocol. More resources \u00b6 Textile Hub CLI Read the full CLI documentation. Textile JavaScript SDK Persist Buckets on IPFS from your JavaScript app. GitHub Action for Buckets Push and updates from your GitHub repos.","title":"Overview"},{"location":"buckets/#buckets","text":"","title":"Buckets"},{"location":"buckets/#getting-started","text":"If you're familiar with cloud storage, you'll find buckets easy to understand. However, unlike traditional cloud services, buckets are built on open, decentralized protocols including the IPFS and Libp2p. You can serve websites, data, and apps from buckets. Buckets are packed with useful features: Explore your Buckets on the Hub gateway . Render web content in your Bucket on a persistent website . Automatically distribute your updates on IPFS using IPNS . Collaboratively manage Buckets as an organization . Create private Buckets where your app users can store data . (Soon) Archive Bucket data on Filecoin to ensure long-term security and access to your files.","title":"Getting Started"},{"location":"buckets/#initialize-a-bucket","text":"To start a Bucket in your current working directory, you must first initialize it. You can initialize a bucket with an existing UnixFS DAG, available in the IPFS network, or import it interactively in an existing bucket. When working on your local machine, buckets are mapped to working directories. Once you initialize a bucket in a directory, anytime you return to the directory, the Textile CLI will automatically detect the Bucket you're interacting with. Read CLI docs for buckets . Info Bucket names are unique to a developer and within an Org. They're not globally unique. Warning Be careful about creating a bucket in a root directory because all children directories become linked to that bucket. To move or remove a bucket's link to a directory, edit, move or delete the .textile/config.yml file (it will be a hidden folder in the bucket's directory)","title":"Initialize a Bucket"},{"location":"buckets/#shared-buckets","text":"You can create buckets to share with all members of an organization. To do so, simply initialize an Org first and then initialize a Bucket using the HUB_ORG environmental flag, by specifying the name of the Org you want to share the bucket with. For example, HUB_ORG=astronauts hub bucket init . All members of the Org will be able to push and pull files to and from the shared Bucket. Read more about creating Orgs . Info To check which org a bucket is registered with, examine the .textile/config.yml file (it will be a hidden folder in the bucket's directory).","title":"Shared buckets"},{"location":"buckets/#encrypted-buckets","text":"It's possible to create encrypted buckets. The contents of encrypted buckets will still exist on IPFS but the contents will be obfuscated to any viewer that doesn't have access to the encryption keys. You can choose to create encrypted buckets when creating them in the CLI or when initializing them in the JavaScript library .","title":"Encrypted buckets"},{"location":"buckets/#publishing-content","text":"","title":"Publishing content"},{"location":"buckets/#push-new-files","text":"View the Bucket push CLI docs . hub bucket push","title":"Push new files"},{"location":"buckets/#diffing-and-syncing","text":"When a bucket is pushed to the remote API (the Hub): Its Merkle DAG representation is saved locally as a reference of the latest pushed version. When you execute hub buck status , it compares the persisted Merkle DAG with a generated Merkle DAG of the Bucket local state. Walking both DAGs and comparing CIDs can quickly provide paths that changed to the last known version. In a nutshell, when a bucket is pushed, the persisted Merkle DAG contains the minimum amount of information about the directory structure and data fingerprints. Read more about this process .","title":"Diffing and Syncing"},{"location":"buckets/#encryption","text":"You can encrypt bucket contents by opting-in to the option when you create your bucket. The encryption setup is based on AES-CTR + AES-512 HMAC as seen here . This is a modified version of the encryption library Google Drive uses to handle large streams (files). Encrypted buckets have a couple of goals: Obfuscate bucket data/files (the normal goal of encryption). Obfuscate directory structure, which means encrypting IPLD nodes and their links. The AES and HMAC keys used for bucket encryption are stored in the ThreadDB collection instance. That means each bucket has a model entry as a key. This setup allows for bucket access to be inherited by thread ACL rules. This also means that if you can break into the thread, and you gain access to the thread read key, you can decrypt the bucket content. As a compromise, we've added some convenience methods to the local buck client which allows you to encrypt content locally (protected by a password) before it gets added to the bucket. This has the downside that you must remember the password. Finally, you can run the standalone buckets daemon buckd locally and use a remote peer as a thread replicator (no read key access). This means that there\u2019s no downside to the keys being stored in the bucket collection instance. Password-based encryption uses the same approach but also leverages scrypt to derive the keys from the password. This carries the normal tradeoff: The encryption is only as good as the password.","title":"Encryption"},{"location":"buckets/#retrieving-content","text":"","title":"Retrieving content"},{"location":"buckets/#pull-files","text":"hub bucket init --existing Info Use the --existing flag to list buckets already pushed by you. Use HUB_ORG to list buckets already pushed by your collaborators.","title":"Pull files"},{"location":"buckets/#explore-on-the-gateway","text":"To inspect your pushed files, explore on the gateway: hub bucket links then open the first result 'Thread links' in your browser. The Hub gateway gives you a static URL where you can explore, download, and share your latest Bucket content.","title":"Explore on the gateway"},{"location":"buckets/#render-on-a-website","text":"If your Bucket contains web content, the Bucket website endpoint will provide you a static URL that'll always render the latest content from your Bucket. See HTTP Domains .","title":"Render on a website"},{"location":"buckets/#render-on-ipfs-gateways","text":"Buckets are dynamic folders distributed over IPFS using ThreadDB. Each time you create a new Bucket, you'll receive a new IPNS Address that you can use on the IPFS address to fetch the latest Bucket content. The IPNS address will not change but the content will update each time you push changes to your Bucket. Each time you update your Bucket, you'll receive a new IPFS address to fetch that version of your Bucket content.","title":"Render on IPFS gateways"},{"location":"buckets/#http-domain","text":"All public Buckets are automatically provided a subdomain on textile.space that reflects the latest changes in your Bucket. Your Bucket's IPNS address is used as the subdomain, such that your Bucket URL will always be: <ipns-address>.textile.space . This is designed to enhance the interoperability of protocols using Textile Buckets.","title":"HTTP Domain"},{"location":"buckets/#ipns-address","text":"Each Bucket has a unique IPNS address that allows you to render or fetch your Bucket on any IPFS peer or gateway that supports IPNS, including ipfs.io and Cloudflare . Buckets can't change the speed of IPNS propagation through the network but we recommend you explore and try for yourself. The Hub gateway will always render the latest data right away.","title":"IPNS Address"},{"location":"buckets/#bucket-automation-cicd","text":"Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions make this easy. We've provided a configurable GitHub Action that allows you to: Push or update your Bucket based on pull requests, commits, and merges. Generate IPNS, IPFS, and HTTP addresses for every Bucket creation or update. Create temporary Buckets for staging or review that can be removed automatically when content is merged or pull requests are closed. Example output from Textile Bucket GitHub Action","title":"Bucket Automation (CI/CD)"},{"location":"buckets/#cross-protocol-support","text":"Buckets are designed to be interoperable across protocols and services. Here are a few examples.","title":"Cross Protocol Support"},{"location":"buckets/#buckets-and-threads","text":"Buckets are built on ThreadDB . In fact, in their most basic form, Buckets are just a document in a Thread that is updated each time the directory of data is updated. Since buckets run on Threads, it opens the door to many new integrations that can be built on Buckets!","title":"Buckets and Threads"},{"location":"buckets/#buckets-and-http","text":"Buckets can be rendered over HTTP through either the Hub Gateway , the Bucket subdomains , or on any IPFS gateway supporting IPNS (see below).","title":"Buckets and HTTP"},{"location":"buckets/#buckets-and-ipfs","text":"Data in a Bucket is stored as IPLD and pinned on IPFS. You can use the underlying content addresses to pin new Bucket content on additional pinning services such as Pinata or Infura . This can be useful if you want additional replication of your content on the IPFS network.","title":"Buckets and IPFS"},{"location":"buckets/#buckets-and-ipns","text":"Every Bucket you create has a unique ID associated with it. The Bucket ID is an IPNS address that you can use to fetch the latest Bucket content from any IPFS peer or view it over IPFS gateways that support the IPNS protocol.","title":"Buckets and IPNS"},{"location":"buckets/#more-resources","text":"","title":"More resources"},{"location":"buckets/archiving/","text":"Bucket Archiving \u00b6 Bucket archiving is the process of taking the existing snapshot of your bucket content and storing it on Filecoin . This allows you to leverage the decentralized nature of Filecoin for the storage of your buckets. Check out this video from a blog post demonstrating Filecoin bucket recovery using the Lotus client. Warning Archives are only encrypted if your bucket was configured to be encrypted. The Textile Hub is currently connected to Mainnet and account balances are in FIL. When you create a new archive, you store your data on the decentralized Filecoin network and outside of the Textile platform. We provide this connection for users but do not offer any guarantees about the Filecoin network, data privacy or security, or access and availability once you create deals on that network. Read our full terms and use these features with caution. Create your first archive \u00b6 Archiving is available in all Textile client libraries and can be requested on a developer, user, or organization buckets. To start testing archiving, let's use a bucket created in the hub CLI. Let's try archiving the bucket. hub buck archive > Warning! Archives are Filecoin Mainnet. Use with caution. ? Proceed? [ y/N ] Any Bucket archive you create will be stored on the Filecoin Mainnet. You should see a success message if you proceed. Success > Success! Archive queued successfully This means that archiving has been initiated. It may take some time to complete... You can get the current status of your archive as well as any previous archives. Notice that the dealInfo property of the returned data includes information about the Filecoin deal(s) created for your archive: hub buck archives list > Success! { \"current\" : { \"cid\" : \"bafybeiaxkbr6fudtgbayg5yndy6vpmz7c4ucjevdl5d5j2r77rkri4fftm\" , \"jobId\" : \"e45bfc6d-79f1-4952-b483-7a644f20d976\" , \"archiveStatus\" : \"ARCHIVE_STATUS_EXECUTING\" , \"aborted\" : false, \"abortedMsg\" : \"\" , \"failureMsg\" : \"\" , \"createdAt\" : \"1606772858\" , \"dealInfo\" : [ { \"proposalCid\" : \"bafyreie2uj42qvk7hqqhfrusj2k7ghbgqqtfydkxdabf6ucmbpzvpx2gni\" , \"stateId\" : \"13\" , \"stateName\" : \"StorageDealCheckForAcceptance\" , \"miner\" : \"f01000\" , \"pieceCid\" : \"baga6ea4seaqmd257xep2aqskphm5bew6goqiehdqypy37qicfrbnodfy6yodooi\" , \"size\" : \"508\" , \"pricePerEpoch\" : \"238\" , \"startEpoch\" : \"508\" , \"duration\" : \"521189\" , \"dealId\" : \"0\" , \"activationEpoch\" : \"0\" , \"message\" : \"\" } ] } , \"history\" : [] } Use the archive watch command to watch your archive progress through the Filecoin market deal stages. hub buck archive watch > Pushing new configuration... > Configuration saved successfully > Executing job e45bfc6d-79f1-4952-b483-7a644f20d976... > Ensuring Hot-Storage satisfies the configuration... > No actions needed in Hot Storage. > Hot-Storage execution ran successfully. > Ensuring Cold-Storage satisfies the configuration... > Current replication factor is lower than desired, making 1 new deals... > Entering deal preprocessing queue... > Calculating piece size... > Calculated piece size is 0 MiB. > Proposing deal to miner f01000 with 500000000 attoFIL per epoch... > Watching deals unfold... > Deal with miner f01000 changed state to StorageDealReserveClientFunds > Deal with miner f01000 changed state to StorageDealClientFunding > Deal with miner f01000 changed state to StorageDealCheckForAcceptance > Deal 2 with miner f01000 changed state to StorageDealSealing > Deal 2 with miner f01000 is active on-chain > Cold-Storage execution ran successfully. > Job e45bfc6d-79f1-4952-b483-7a644f20d976 execution finished with status Success. The output will look something like the above. With a little luck, you'll start seeing some successful storage deals. Limits \u00b6 Archiving is limited by the limits of buckets, so the maximum size is 4 GiB. Archives stored on Filecoin do not count toward your account storage limits. Only files that remain in your live bucket are counted.","title":"Bucket Archiving"},{"location":"buckets/archiving/#bucket-archiving","text":"Bucket archiving is the process of taking the existing snapshot of your bucket content and storing it on Filecoin . This allows you to leverage the decentralized nature of Filecoin for the storage of your buckets. Check out this video from a blog post demonstrating Filecoin bucket recovery using the Lotus client. Warning Archives are only encrypted if your bucket was configured to be encrypted. The Textile Hub is currently connected to Mainnet and account balances are in FIL. When you create a new archive, you store your data on the decentralized Filecoin network and outside of the Textile platform. We provide this connection for users but do not offer any guarantees about the Filecoin network, data privacy or security, or access and availability once you create deals on that network. Read our full terms and use these features with caution.","title":"Bucket Archiving"},{"location":"buckets/archiving/#create-your-first-archive","text":"Archiving is available in all Textile client libraries and can be requested on a developer, user, or organization buckets. To start testing archiving, let's use a bucket created in the hub CLI. Let's try archiving the bucket. hub buck archive > Warning! Archives are Filecoin Mainnet. Use with caution. ? Proceed? [ y/N ] Any Bucket archive you create will be stored on the Filecoin Mainnet. You should see a success message if you proceed. Success > Success! Archive queued successfully This means that archiving has been initiated. It may take some time to complete... You can get the current status of your archive as well as any previous archives. Notice that the dealInfo property of the returned data includes information about the Filecoin deal(s) created for your archive: hub buck archives list > Success! { \"current\" : { \"cid\" : \"bafybeiaxkbr6fudtgbayg5yndy6vpmz7c4ucjevdl5d5j2r77rkri4fftm\" , \"jobId\" : \"e45bfc6d-79f1-4952-b483-7a644f20d976\" , \"archiveStatus\" : \"ARCHIVE_STATUS_EXECUTING\" , \"aborted\" : false, \"abortedMsg\" : \"\" , \"failureMsg\" : \"\" , \"createdAt\" : \"1606772858\" , \"dealInfo\" : [ { \"proposalCid\" : \"bafyreie2uj42qvk7hqqhfrusj2k7ghbgqqtfydkxdabf6ucmbpzvpx2gni\" , \"stateId\" : \"13\" , \"stateName\" : \"StorageDealCheckForAcceptance\" , \"miner\" : \"f01000\" , \"pieceCid\" : \"baga6ea4seaqmd257xep2aqskphm5bew6goqiehdqypy37qicfrbnodfy6yodooi\" , \"size\" : \"508\" , \"pricePerEpoch\" : \"238\" , \"startEpoch\" : \"508\" , \"duration\" : \"521189\" , \"dealId\" : \"0\" , \"activationEpoch\" : \"0\" , \"message\" : \"\" } ] } , \"history\" : [] } Use the archive watch command to watch your archive progress through the Filecoin market deal stages. hub buck archive watch > Pushing new configuration... > Configuration saved successfully > Executing job e45bfc6d-79f1-4952-b483-7a644f20d976... > Ensuring Hot-Storage satisfies the configuration... > No actions needed in Hot Storage. > Hot-Storage execution ran successfully. > Ensuring Cold-Storage satisfies the configuration... > Current replication factor is lower than desired, making 1 new deals... > Entering deal preprocessing queue... > Calculating piece size... > Calculated piece size is 0 MiB. > Proposing deal to miner f01000 with 500000000 attoFIL per epoch... > Watching deals unfold... > Deal with miner f01000 changed state to StorageDealReserveClientFunds > Deal with miner f01000 changed state to StorageDealClientFunding > Deal with miner f01000 changed state to StorageDealCheckForAcceptance > Deal 2 with miner f01000 changed state to StorageDealSealing > Deal 2 with miner f01000 is active on-chain > Cold-Storage execution ran successfully. > Job e45bfc6d-79f1-4952-b483-7a644f20d976 execution finished with status Success. The output will look something like the above. With a little luck, you'll start seeing some successful storage deals.","title":"Create your first archive"},{"location":"buckets/archiving/#limits","text":"Archiving is limited by the limits of buckets, so the maximum size is 4 GiB. Archives stored on Filecoin do not count toward your account storage limits. Only files that remain in your live bucket are counted.","title":"Limits"},{"location":"buckets/permissions/","text":"Bucket Permissions \u00b6 Bucket owners \u00b6 Developer Buckets \u00b6 All buckets you create are scoped to your developer account. You can always find your currently logged in account with hub whoami . Organization Buckets \u00b6 Any bucket you create using the HUB_ORG setting will also be shared with Org members. The following sections will cover how to: Create a new Org. Create a new Bucket shared with an Org. Invite a collaborator to the Org. Create a new Org \u00b6 hub org create Choose an Org name: nasa\u2588 Please confirm: y\u2588 Success > Success! You have now created the nasa Org. Create a new Bucket shared with an Org \u00b6 The default bucket command is simply buck because it's two letters less to type each time. If you prefer, you can still type bucket . mkdir launchpad cd launchpad HUB_ORG = nasa hub buck init You've now created a new Bucket inside of the launchpad directory and owned by your nasa organization. Invite a new org member \u00b6 hub org invite The final step is to invite collaborators to your Org. Once they accept the invite, they'll be able to interact with buckets associated with the Org. App user Buckets \u00b6 If you're building an app using one of our developer libraries , you can use buckets from inside your apps. Apps generally will create buckets on behalf of each user, meaning the user should retain control of the Bucket metadata and contents. Bucket Access Roles \u00b6 Buckets can be shared in more ways than organizations. Multi-writer buckets leverage the distributed nature of ThreadDB by allowing multiple identities to write to the same buckets that are hosted by different Libp2p hosts. Since buckets are ThreadDB collection instances, this is no different than normal ThreadDB peer collaboration. Path access \u00b6 Read and write access roles are defined in a bucket at any path. Any subpaths automatically inherit the permissions of their parent. For example, granting read access to your bucket at / would also grant read access to a file that exists at /path/to/foo.jpg . You can set different access rules within the same bucket by using a combination of paths and specified roles at the path. Role types \u00b6 Admin Users with the ability to modify permissions. Writer Users allowed update data at the specified path. Reader Users allowed read data at the specified path. Unspecified Users with any permissions specified path. Authorizing users \u00b6 You can specify new users and their roles by inserting their public key into the bucket access rules. Let's take a look at how we update roles using the CLI. hub buck roles grant -r writer \\ bbaareicookqfgeosr225wwdknmpmvgemydxolzxesu6woxghpulxvizose /path/to Success IDENTITY ROLE * Reader bbaareicookqfgeosr225wwdknmpmvgemydxolzxesu6woxghpulxvizose Writer bbaareieyrq92sbfcx2bhbmsfxzj25pi7ldx2vkrtcn6hu3xzi4mpzwqvcy Admin > Success! Updated access roles for path /path/to Success! You can see the new user has been added as a writer to the path /path/to and that the bucket creator is still listed as the admin. More resources \u00b6 Buckets in your app View the tutorial on adding Buckets to your JavaScript app. JS Hub Docs Persist user buckets on IPFS from your JS app. React Native tutorial See how to create user buckets & threads in React Native.","title":"Permissions"},{"location":"buckets/permissions/#bucket-permissions","text":"","title":"Bucket Permissions"},{"location":"buckets/permissions/#bucket-owners","text":"","title":"Bucket owners"},{"location":"buckets/permissions/#developer-buckets","text":"All buckets you create are scoped to your developer account. You can always find your currently logged in account with hub whoami .","title":"Developer Buckets"},{"location":"buckets/permissions/#organization-buckets","text":"Any bucket you create using the HUB_ORG setting will also be shared with Org members. The following sections will cover how to: Create a new Org. Create a new Bucket shared with an Org. Invite a collaborator to the Org.","title":"Organization Buckets"},{"location":"buckets/permissions/#create-a-new-org","text":"hub org create Choose an Org name: nasa\u2588 Please confirm: y\u2588 Success > Success! You have now created the nasa Org.","title":"Create a new Org"},{"location":"buckets/permissions/#create-a-new-bucket-shared-with-an-org","text":"The default bucket command is simply buck because it's two letters less to type each time. If you prefer, you can still type bucket . mkdir launchpad cd launchpad HUB_ORG = nasa hub buck init You've now created a new Bucket inside of the launchpad directory and owned by your nasa organization.","title":"Create a new Bucket shared with an Org"},{"location":"buckets/permissions/#invite-a-new-org-member","text":"hub org invite The final step is to invite collaborators to your Org. Once they accept the invite, they'll be able to interact with buckets associated with the Org.","title":"Invite a new org member"},{"location":"buckets/permissions/#app-user-buckets","text":"If you're building an app using one of our developer libraries , you can use buckets from inside your apps. Apps generally will create buckets on behalf of each user, meaning the user should retain control of the Bucket metadata and contents.","title":"App user Buckets"},{"location":"buckets/permissions/#bucket-access-roles","text":"Buckets can be shared in more ways than organizations. Multi-writer buckets leverage the distributed nature of ThreadDB by allowing multiple identities to write to the same buckets that are hosted by different Libp2p hosts. Since buckets are ThreadDB collection instances, this is no different than normal ThreadDB peer collaboration.","title":"Bucket Access Roles"},{"location":"buckets/permissions/#path-access","text":"Read and write access roles are defined in a bucket at any path. Any subpaths automatically inherit the permissions of their parent. For example, granting read access to your bucket at / would also grant read access to a file that exists at /path/to/foo.jpg . You can set different access rules within the same bucket by using a combination of paths and specified roles at the path.","title":"Path access"},{"location":"buckets/permissions/#role-types","text":"Admin Users with the ability to modify permissions. Writer Users allowed update data at the specified path. Reader Users allowed read data at the specified path. Unspecified Users with any permissions specified path.","title":"Role types"},{"location":"buckets/permissions/#authorizing-users","text":"You can specify new users and their roles by inserting their public key into the bucket access rules. Let's take a look at how we update roles using the CLI. hub buck roles grant -r writer \\ bbaareicookqfgeosr225wwdknmpmvgemydxolzxesu6woxghpulxvizose /path/to Success IDENTITY ROLE * Reader bbaareicookqfgeosr225wwdknmpmvgemydxolzxesu6woxghpulxvizose Writer bbaareieyrq92sbfcx2bhbmsfxzj25pi7ldx2vkrtcn6hu3xzi4mpzwqvcy Admin > Success! Updated access roles for path /path/to Success! You can see the new user has been added as a writer to the path /path/to and that the bucket creator is still listed as the admin.","title":"Authorizing users"},{"location":"buckets/permissions/#more-resources","text":"","title":"More resources"},{"location":"filecoin/balances/","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details, including details about FIL balances. Every developer, organization, and API user on the Hub has its own Filecoin address. Below, we'll focus on exploring the Filecoin wallet and tools through the Hub CLI , as this is where you'll be able to start using Filecoin the fastest. Just know, you can build all of this into your app for your users too using our API and client libraries. Check your address and balances \u00b6 Personal account hub buck addrs Success > Success! { \"addresses\" : [ { \"name\" : \"Initial Address\" , \"address\" : \"f3wagei5pgdglrszjvowoc6clsbp5fqyplk3gze6vrttvxk4faxnjri5kqa5foaikgea7lv2jnlbvubywjp2pa\" , \"type\" : \"bls\" , \"balance\" : \"250000000000000000\" , \"verifiedClientInfo\" : null } ] } > Funds in this wallet are for network and storage fees only ; they cannot be transferred or sold. > Get your address verified on https://plus.fil.org/landing. Check your organization address HUB_ORG = <org name> hub buck addrs Remember, all members of an organization have access to this shared address. Each with the ability to store data using any Filecoin it holds. Funding your address \u00b6 Warning We are shutting down our hosted Hub infrastructure. Do not send any funds to any Hub-based Filecoin addresses. Textile is not able to provide any financial services. Due to that restriction, Filecoin you deposit in any address on the Hub can only be used to pay network fees for gas, storage, and retreival. Fil+ verification \u00b6 The Filecoin network has a concept of verified clients. These are addresses on the network that have demonstrated to some extent that they are real projects making storage requests with important data. You can get a great overview of the progam on the helpful notes at verify.glif.io/ or you can read the more technical overview on GitHub . The primary benefit to getting verified is that your storage costs are dramatically reduced. Sometimes to nearly nothing. You can check out the miner index to see some of the latest prices quoted by miners on the network for verified clients. We strongly recommend that every user get verified as soon as they are capable. Getting verified \u00b6 The quickest path to verification is also through verify.glif.io/ where you can get 8GiB of verified storage by simply authenticating with your GitHub account. If you need more than 8GiB of storage, there is a more thorough application and vetting process that you can start on plus.fil.org/ . For most serious projects, this is the preferred route to verification. Verification status \u00b6 You can check your address verification status on verify.glif.io/ .","title":"Balances"},{"location":"filecoin/balances/#check-your-address-and-balances","text":"Personal account hub buck addrs Success > Success! { \"addresses\" : [ { \"name\" : \"Initial Address\" , \"address\" : \"f3wagei5pgdglrszjvowoc6clsbp5fqyplk3gze6vrttvxk4faxnjri5kqa5foaikgea7lv2jnlbvubywjp2pa\" , \"type\" : \"bls\" , \"balance\" : \"250000000000000000\" , \"verifiedClientInfo\" : null } ] } > Funds in this wallet are for network and storage fees only ; they cannot be transferred or sold. > Get your address verified on https://plus.fil.org/landing. Check your organization address HUB_ORG = <org name> hub buck addrs Remember, all members of an organization have access to this shared address. Each with the ability to store data using any Filecoin it holds.","title":"Check your address and balances"},{"location":"filecoin/balances/#funding-your-address","text":"Warning We are shutting down our hosted Hub infrastructure. Do not send any funds to any Hub-based Filecoin addresses. Textile is not able to provide any financial services. Due to that restriction, Filecoin you deposit in any address on the Hub can only be used to pay network fees for gas, storage, and retreival.","title":"Funding your address"},{"location":"filecoin/balances/#fil-verification","text":"The Filecoin network has a concept of verified clients. These are addresses on the network that have demonstrated to some extent that they are real projects making storage requests with important data. You can get a great overview of the progam on the helpful notes at verify.glif.io/ or you can read the more technical overview on GitHub . The primary benefit to getting verified is that your storage costs are dramatically reduced. Sometimes to nearly nothing. You can check out the miner index to see some of the latest prices quoted by miners on the network for verified clients. We strongly recommend that every user get verified as soon as they are capable.","title":"Fil+ verification"},{"location":"filecoin/balances/#getting-verified","text":"The quickest path to verification is also through verify.glif.io/ where you can get 8GiB of verified storage by simply authenticating with your GitHub account. If you need more than 8GiB of storage, there is a more thorough application and vetting process that you can start on plus.fil.org/ . For most serious projects, this is the preferred route to verification.","title":"Getting verified"},{"location":"filecoin/balances/#verification-status","text":"You can check your address verification status on verify.glif.io/ .","title":"Verification status"},{"location":"filecoin/miner-index/","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. The miner index is an open API meant to help Filecoin clients store their data efficiently and cheaply on the network. It has three primary endpoints. Index: list and query miners based on their recent storage history. Calculate: calculate actual costs for verified and standard deal storage with specified miners. Profiles: review the complete set of data and recent history for a specific miner. There are two primary ways you can use the API. Rest API The first is by accessing the open API endpoint over REST. You can find the documentation for that endpoint here . We'll walk through some of the live results from that API in the next section. CLI The index is made available over the Hub CLI . We'll review some common commands below. Live Results \u00b6 Let's walk through each of the API endpoints while also reviewing some live results. MINER ASK-PRICE VERIFIED ASK-PRICE LOCATION MIN-PIECE-SIZE TEXTILE-LAST-DEAL All FIL columns (e.g., askPrice) are reported as attoFil . Understanding the results \u00b6 The data shown here are the latest five miners to successfully store data for a request originating from Textile. The table only represents a small portion of the data available from the index. The default sorting of results is simply the latest miners that have successfully stored online deal requests from one of the many nodes we monitor. The default sort ensures that even this basic view should give most clients a reliable list of storage miners to use right away. Just pick the first couple! You can use the API or CLI to change how sorting, filtering, and limits happen. If you want to see the complete data that comes back from the API, check out this direct query: https://minerindex.hub.textile.io/v1/index/query?sort.ascending=false&sort.field=TEXTILE_DEALS_LAST_SUCCESSFUL&limit=5 The following is the full JSON result returned from the API for just the first miner in the table. { \"minerAddr\" : \"f09848\" , \"metadata\" : { \"location\" : \"US\" }, \"filecoin\" : { \"relativePower\" : 0.000020719814040295776 , \"askPrice\" : \"10000000000\" , \"askVerifiedPrice\" : \"0\" , \"minPieceSize\" : \"536870912\" , \"maxPieceSize\" : \"34359738368\" , \"sectorSize\" : \"34359738368\" , \"activeSectors\" : \"2314\" , \"faultySectors\" : \"0\" , \"updatedAt\" : \"2021-03-17T20:03:22.059Z\" }, \"textile\" : { \"regions\" : { \"021\" : { \"deals\" : { \"total\" : \"120\" , \"last\" : \"2021-03-17T14:56:51.360Z\" , \"failures\" : \"57\" , \"lastFailure\" : \"2021-03-17T19:41:28.922Z\" , \"tailTransfers\" : [ { \"transferedAt\" : \"2021-03-16T16:02:57Z\" , \"mibPerSec\" : 13.257300327974415 }, { \"transferedAt\" : \"2021-03-15T19:43:35Z\" , \"mibPerSec\" : 20.399272781121926 }, { \"transferedAt\" : \"2021-03-15T20:19:30Z\" , \"mibPerSec\" : 20.739260660807293 }, { \"transferedAt\" : \"2021-03-05T17:23:59Z\" , \"mibPerSec\" : 13.070962601349134 }, { \"transferedAt\" : \"2021-03-05T17:00:31Z\" , \"mibPerSec\" : 14.778570542142964 }, { \"transferedAt\" : \"2021-03-05T16:56:07Z\" , \"mibPerSec\" : 16.953074109651737 }, { \"transferedAt\" : \"2021-03-05T17:32:04Z\" , \"mibPerSec\" : 15.791315223964943 }, { \"transferedAt\" : \"2021-03-03T18:16:38Z\" , \"mibPerSec\" : 9.75200344552067 }, { \"transferedAt\" : \"2021-02-27T02:47:50Z\" , \"mibPerSec\" : 7.480152248979115 }, { \"transferedAt\" : \"2021-02-24T20:46:23Z\" , \"mibPerSec\" : 20.966012990699625 }, { \"transferedAt\" : \"2021-02-23T02:00:08Z\" , \"mibPerSec\" : 12.749545486246953 } ], \"tailSealed\" : [ { \"sealedAt\" : \"2021-03-17T14:56:51Z\" , \"durationSeconds\" : \"9440\" }, { \"sealedAt\" : \"2021-03-16T14:02:38Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-16T13:56:09Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-06T05:49:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:49:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:46:35Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:45:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-04T07:00:50Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-27T15:57:58Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-25T08:57:14Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-02-23T14:44:18Z\" , \"durationSeconds\" : \"9000\" } ] }, \"retrievals\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [] } } }, \"dealsSummary\" : { \"total\" : \"120\" , \"last\" : \"2021-03-17T14:56:51.360Z\" , \"failures\" : \"57\" , \"lastFailure\" : \"2021-03-17T19:41:28.922Z\" }, \"retrievalsSummary\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null }, \"updatedAt\" : \"2021-03-17T20:03:02.813Z\" }, \"updatedAt\" : \"2021-03-17T20:03:02.813Z\" } Make a deal with one of the results \u00b6 Buckets \u00b6 If you are using bucket archives to store data, you can replicate your data with two miners as follows. hub buck archive set-default-config --fast-retrieval --trusted-miners { id1, id2 } Or, if you have your address verified on the network ( learn more here ), you can make a verified deal. hub buck archive set-default-config --fast-retrieval --verified-deal --trusted-miners { id1, id2 } Lotus \u00b6 If you are using lotus, you can use the above miners the same way, but you'll need to specify each deal at a time. lotus client deal --fast-retrieval --verified-deal <data-cid> {id1} 66355200000000000 518400 Calculator \u00b6 You can use the calculator endpoint to determine the cost of storage with one or multiple miners at a time. You can play with that below. MINER NORMAL COST VERIFIED COST DURATION PADDED SIZE The calculator results are based on storing 1,000,000 bytes for 180 days. You can use the API directly to modify those parameters or which miners you are calculating. The following is the complete JSON result from the calculator API request. { \"results\" : [ { \"miner\" : \"f09848\" , \"totalCost\" : \"5060000000000\" , \"verifiedTotalCost\" : \"0\" , \"price\" : \"10000000000\" , \"verifiedPrice\" : \"0\" }, { \"miner\" : \"f066596\" , \"totalCost\" : \"10120000000000\" , \"verifiedTotalCost\" : \"0\" , \"price\" : \"20000000000\" , \"verifiedPrice\" : \"0\" }, { \"miner\" : \"f0156452\" , \"totalCost\" : \"253000000000\" , \"verifiedTotalCost\" : \"25300000000\" , \"price\" : \"500000000\" , \"verifiedPrice\" : \"50000000\" }, { \"miner\" : \"f0165539\" , \"totalCost\" : \"25300000000\" , \"verifiedTotalCost\" : \"2530000000\" , \"price\" : \"50000000\" , \"verifiedPrice\" : \"5000000\" }, { \"miner\" : \"f0230200\" , \"totalCost\" : \"253000000000\" , \"verifiedTotalCost\" : \"25300000000\" , \"price\" : \"500000000\" , \"verifiedPrice\" : \"50000000\" } ], \"paddedSize\" : \"1048576\" , \"durationEpochs\" : \"518400\" } Miner profiles \u00b6 The API also has an endpoint to retrieve the latest stats and profile information for a single miner. Here is the request for the profile of the first miner in our results above. The following is the full JSON result from the profile API request. { \"info\" : { \"minerAddr\" : \"f0221135\" , \"metadata\" : { \"location\" : \"US\" }, \"filecoin\" : { \"relativePower\" : 1.7012885147319677e-7 , \"askPrice\" : \"1000000000\" , \"askVerifiedPrice\" : \"500000000\" , \"minPieceSize\" : \"10485760\" , \"maxPieceSize\" : \"34359738368\" , \"sectorSize\" : \"34359738368\" , \"activeSectors\" : \"19\" , \"faultySectors\" : \"0\" , \"updatedAt\" : \"2021-03-17T20:03:17.390Z\" }, \"textile\" : { \"regions\" : { \"021\" : { \"deals\" : { \"total\" : \"2\" , \"last\" : \"2021-03-06T14:30:38.165Z\" , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [ { \"transferedAt\" : \"2021-03-05T17:25:41Z\" , \"mibPerSec\" : 12.671646024933173 }, { \"transferedAt\" : \"2021-03-03T18:16:38Z\" , \"mibPerSec\" : 9.75200344552067 } ], \"tailSealed\" : [ { \"sealedAt\" : \"2021-03-06T14:30:38Z\" , \"durationSeconds\" : \"9900\" }, { \"sealedAt\" : \"2021-03-04T13:59:13Z\" , \"durationSeconds\" : \"9900\" } ] }, \"retrievals\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [] } } }, \"dealsSummary\" : { \"total\" : \"2\" , \"last\" : \"2021-03-06T14:30:38.165Z\" , \"failures\" : \"0\" , \"lastFailure\" : null }, \"retrievalsSummary\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null }, \"updatedAt\" : \"2021-03-17T20:03:01.056Z\" }, \"updatedAt\" : \"2021-03-17T20:03:01.056Z\" } } Hub CLI \u00b6 We leverage the REST API above to provide simple command-line access to the miner index. Here are some interesting places to get started. Query the index Calculate deal costs Get miner profiles Expanded results You can access a full table of results for any query by using the --show-full-details flag. hub fil index query --show-full-details --limit 20 Scripting Each CLI methods for the index supports a --json flag to output results to JSON. hub fil index query --show-full-details --limit 1 --json | jq -r \".miners[]\" How it works \u00b6 Textile's miner index is different than most others you'll find on the network. The key distinction is that this index pulls real data from many Lotus and Powergate nodes connected to mainnet. The index collects both the on-chain information plus a suite of off-chain telemetry that can be very informative for advanced selection of miners. All telemetry is currently measured from clients based in North America (region 021 in the API), but will expand in the future. Some interesting features of the index you may wish to leverage include the following. We've populated the below from real-time index results for the first miner listed above. Deals summary \u00b6 Calculated across all regions. { \"total\" : \"120\" , \"last\" : \"2021-03-17T14:56:51.360Z\" , \"failures\" : \"57\" , \"lastFailure\" : \"2021-03-17T19:41:28.922Z\" } Transfer stats \u00b6 Tail of latest transfer stats from clients in North America. [ { \"transferedAt\" : \"2021-03-16T16:02:57Z\" , \"mibPerSec\" : 13.257300327974415 }, { \"transferedAt\" : \"2021-03-15T19:43:35Z\" , \"mibPerSec\" : 20.399272781121926 }, { \"transferedAt\" : \"2021-03-15T20:19:30Z\" , \"mibPerSec\" : 20.739260660807293 }, { \"transferedAt\" : \"2021-03-05T17:23:59Z\" , \"mibPerSec\" : 13.070962601349134 }, { \"transferedAt\" : \"2021-03-05T17:00:31Z\" , \"mibPerSec\" : 14.778570542142964 }, { \"transferedAt\" : \"2021-03-05T16:56:07Z\" , \"mibPerSec\" : 16.953074109651737 }, { \"transferedAt\" : \"2021-03-05T17:32:04Z\" , \"mibPerSec\" : 15.791315223964943 }, { \"transferedAt\" : \"2021-03-03T18:16:38Z\" , \"mibPerSec\" : 9.75200344552067 }, { \"transferedAt\" : \"2021-02-27T02:47:50Z\" , \"mibPerSec\" : 7.480152248979115 }, { \"transferedAt\" : \"2021-02-24T20:46:23Z\" , \"mibPerSec\" : 20.966012990699625 }, { \"transferedAt\" : \"2021-02-23T02:00:08Z\" , \"mibPerSec\" : 12.749545486246953 } ] Sealing stats \u00b6 Tail of latest sealing stats from clients in North America. [ { \"sealedAt\" : \"2021-03-17T14:56:51Z\" , \"durationSeconds\" : \"9440\" }, { \"sealedAt\" : \"2021-03-16T14:02:38Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-16T13:56:09Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-06T05:49:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:49:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:46:35Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:45:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-04T07:00:50Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-27T15:57:58Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-25T08:57:14Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-02-23T14:44:18Z\" , \"durationSeconds\" : \"9000\" } ] Latest Retrievals \u00b6 Latest retrievals for clients in North America. { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [] } JavaScript Examples \u00b6 The tables and JSON results above are all generated in real-time by using the miner index API endpoint. Here are a few examples you can use. Query \u00b6 var table = document . getElementById ( \"miner-table\" ); fetch ( \"https://minerindex.hub.textile.io/v1/index/query?sort.ascending=false&sort.field=TEXTILE_DEALS_LAST_SUCCESSFUL&limit=5\" ) . then (( response ) => response . json ()) . then (( data ) => { var rct = 0 ; for ( var miner of data . miners ) { var row = table . insertRow ( rct ); var minerAddr = row . insertCell ( 0 ); minerAddr . innerHTML = miner . minerAddr ; rct += 1 ; } }); Calculate \u00b6 var table = document . getElementById ( \"miner-table\" ); fetch ( \"https://minerindex.hub.textile.io/v1/calculator/calculate?dataSizeBytes=1000000&durationDays=180&minerAddresses=f09848\" ) . then (( response ) => response . json ()) . then (( data ) => { console . log ( data ); }); Get Profile \u00b6 var table = document . getElementById ( \"miner-table\" ); fetch ( \"https://minerindex.hub.textile.io/v1/index/miner/f09848\" ) . then (( response ) => response . json ()) . then (( data ) => { console . log ( data ); }); Build on! function updateProfile(miner) { var url = \"https://minerindex.hub.textile.io/v1/index/miner/\" + miner var apiurl = document.getElementById(\"profile-api\"); apiurl.href = url; apiurl.text = url; var rct = 0; fetch(url) .then(response => response.json()) .then(data => { var res = document.querySelector(\"#profile-result pre code\") res.innerHTML = JSON.stringify(data, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); }) } function updateCalculator(miners) { var table = document.getElementById(\"calculator-results\"); var url = \"https://minerindex.hub.textile.io/v1/calculator/calculate?dataSizeBytes=1000000&durationDays=180&\" for (var miner of miners) { url += \"&minerAddresses=\" + miner } var apiurl = document.getElementById(\"calculator-api\"); apiurl.href = url; apiurl.text = url; var rct = 0; fetch(url) .then(response => response.json()) .then(data => { var res = document.querySelector(\"#calculator-result pre code\") res.innerHTML = JSON.stringify(data, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); for (var r of data.results) { var row = table.insertRow(rct); rct += 1; var minerAddr = row.insertCell(0); minerAddr.innerHTML = r.miner; var cost = row.insertCell(1); cost.innerHTML = r.totalCost; var verified = row.insertCell(2); verified.innerHTML = r.verifiedTotalCost; var duration = row.insertCell(3); duration.innerHTML = data.durationEpochs; var padded = row.insertCell(4); padded.innerHTML = data.paddedSize; } }) } var table = document.getElementById(\"miners-results\"); var rct = 0; var calc = [] fetch('https://minerindex.hub.textile.io/v1/index/query?sort.ascending=false&sort.field=TEXTILE_DEALS_LAST_SUCCESSFUL&limit=5') .then(response => response.json()) .then(data => { for (var row of data.miners) { var miner = row.miner; var row = table.insertRow(rct); if (rct === 0) { var res = document.querySelector(\"#first-result pre code\") res.innerHTML = JSON.stringify(miner, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); updateProfile(miner.minerAddr) res = document.querySelector(\"#deals-summary pre code\") res.innerHTML = JSON.stringify(miner.textile.dealsSummary, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); res = document.querySelector(\"#transfer-stats pre code\") res.innerHTML = JSON.stringify(miner.textile.regions[\"021\"].deals.tailTransfers, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); res = document.querySelector(\"#sealing-stats pre code\") res.innerHTML = JSON.stringify(miner.textile.regions[\"021\"].deals.tailSealed, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); res = document.querySelector(\"#latest-retrievals pre code\") res.innerHTML = JSON.stringify(miner.textile.regions[\"021\"].retrievals, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); } calc.push(miner.minerAddr); rct += 1; var minerAddr = row.insertCell(0); minerAddr.innerHTML = miner.minerAddr; var price = row.insertCell(1); price.innerHTML = miner[\"filecoin\"].askPrice; var verified = row.insertCell(2); verified.innerHTML = miner.filecoin.askVerifiedPrice; var location = row.insertCell(3); location.innerHTML = miner.metadata.location; var minSize = row.insertCell(4); minSize.innerHTML = miner.filecoin.minPieceSize; var lastDeal = row.insertCell(5); lastDeal.innerHTML = miner.textile.dealsSummary.last; } updateCalculator(calc); });","title":"Miner Index"},{"location":"filecoin/miner-index/#live-results","text":"Let's walk through each of the API endpoints while also reviewing some live results. MINER ASK-PRICE VERIFIED ASK-PRICE LOCATION MIN-PIECE-SIZE TEXTILE-LAST-DEAL All FIL columns (e.g., askPrice) are reported as attoFil .","title":"Live Results"},{"location":"filecoin/miner-index/#understanding-the-results","text":"The data shown here are the latest five miners to successfully store data for a request originating from Textile. The table only represents a small portion of the data available from the index. The default sorting of results is simply the latest miners that have successfully stored online deal requests from one of the many nodes we monitor. The default sort ensures that even this basic view should give most clients a reliable list of storage miners to use right away. Just pick the first couple! You can use the API or CLI to change how sorting, filtering, and limits happen. If you want to see the complete data that comes back from the API, check out this direct query: https://minerindex.hub.textile.io/v1/index/query?sort.ascending=false&sort.field=TEXTILE_DEALS_LAST_SUCCESSFUL&limit=5 The following is the full JSON result returned from the API for just the first miner in the table. { \"minerAddr\" : \"f09848\" , \"metadata\" : { \"location\" : \"US\" }, \"filecoin\" : { \"relativePower\" : 0.000020719814040295776 , \"askPrice\" : \"10000000000\" , \"askVerifiedPrice\" : \"0\" , \"minPieceSize\" : \"536870912\" , \"maxPieceSize\" : \"34359738368\" , \"sectorSize\" : \"34359738368\" , \"activeSectors\" : \"2314\" , \"faultySectors\" : \"0\" , \"updatedAt\" : \"2021-03-17T20:03:22.059Z\" }, \"textile\" : { \"regions\" : { \"021\" : { \"deals\" : { \"total\" : \"120\" , \"last\" : \"2021-03-17T14:56:51.360Z\" , \"failures\" : \"57\" , \"lastFailure\" : \"2021-03-17T19:41:28.922Z\" , \"tailTransfers\" : [ { \"transferedAt\" : \"2021-03-16T16:02:57Z\" , \"mibPerSec\" : 13.257300327974415 }, { \"transferedAt\" : \"2021-03-15T19:43:35Z\" , \"mibPerSec\" : 20.399272781121926 }, { \"transferedAt\" : \"2021-03-15T20:19:30Z\" , \"mibPerSec\" : 20.739260660807293 }, { \"transferedAt\" : \"2021-03-05T17:23:59Z\" , \"mibPerSec\" : 13.070962601349134 }, { \"transferedAt\" : \"2021-03-05T17:00:31Z\" , \"mibPerSec\" : 14.778570542142964 }, { \"transferedAt\" : \"2021-03-05T16:56:07Z\" , \"mibPerSec\" : 16.953074109651737 }, { \"transferedAt\" : \"2021-03-05T17:32:04Z\" , \"mibPerSec\" : 15.791315223964943 }, { \"transferedAt\" : \"2021-03-03T18:16:38Z\" , \"mibPerSec\" : 9.75200344552067 }, { \"transferedAt\" : \"2021-02-27T02:47:50Z\" , \"mibPerSec\" : 7.480152248979115 }, { \"transferedAt\" : \"2021-02-24T20:46:23Z\" , \"mibPerSec\" : 20.966012990699625 }, { \"transferedAt\" : \"2021-02-23T02:00:08Z\" , \"mibPerSec\" : 12.749545486246953 } ], \"tailSealed\" : [ { \"sealedAt\" : \"2021-03-17T14:56:51Z\" , \"durationSeconds\" : \"9440\" }, { \"sealedAt\" : \"2021-03-16T14:02:38Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-16T13:56:09Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-06T05:49:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:49:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:46:35Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:45:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-04T07:00:50Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-27T15:57:58Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-25T08:57:14Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-02-23T14:44:18Z\" , \"durationSeconds\" : \"9000\" } ] }, \"retrievals\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [] } } }, \"dealsSummary\" : { \"total\" : \"120\" , \"last\" : \"2021-03-17T14:56:51.360Z\" , \"failures\" : \"57\" , \"lastFailure\" : \"2021-03-17T19:41:28.922Z\" }, \"retrievalsSummary\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null }, \"updatedAt\" : \"2021-03-17T20:03:02.813Z\" }, \"updatedAt\" : \"2021-03-17T20:03:02.813Z\" }","title":"Understanding the results"},{"location":"filecoin/miner-index/#make-a-deal-with-one-of-the-results","text":"","title":"Make a deal with one of the results"},{"location":"filecoin/miner-index/#buckets","text":"If you are using bucket archives to store data, you can replicate your data with two miners as follows. hub buck archive set-default-config --fast-retrieval --trusted-miners { id1, id2 } Or, if you have your address verified on the network ( learn more here ), you can make a verified deal. hub buck archive set-default-config --fast-retrieval --verified-deal --trusted-miners { id1, id2 }","title":"Buckets"},{"location":"filecoin/miner-index/#lotus","text":"If you are using lotus, you can use the above miners the same way, but you'll need to specify each deal at a time. lotus client deal --fast-retrieval --verified-deal <data-cid> {id1} 66355200000000000 518400","title":"Lotus"},{"location":"filecoin/miner-index/#calculator","text":"You can use the calculator endpoint to determine the cost of storage with one or multiple miners at a time. You can play with that below. MINER NORMAL COST VERIFIED COST DURATION PADDED SIZE The calculator results are based on storing 1,000,000 bytes for 180 days. You can use the API directly to modify those parameters or which miners you are calculating. The following is the complete JSON result from the calculator API request. { \"results\" : [ { \"miner\" : \"f09848\" , \"totalCost\" : \"5060000000000\" , \"verifiedTotalCost\" : \"0\" , \"price\" : \"10000000000\" , \"verifiedPrice\" : \"0\" }, { \"miner\" : \"f066596\" , \"totalCost\" : \"10120000000000\" , \"verifiedTotalCost\" : \"0\" , \"price\" : \"20000000000\" , \"verifiedPrice\" : \"0\" }, { \"miner\" : \"f0156452\" , \"totalCost\" : \"253000000000\" , \"verifiedTotalCost\" : \"25300000000\" , \"price\" : \"500000000\" , \"verifiedPrice\" : \"50000000\" }, { \"miner\" : \"f0165539\" , \"totalCost\" : \"25300000000\" , \"verifiedTotalCost\" : \"2530000000\" , \"price\" : \"50000000\" , \"verifiedPrice\" : \"5000000\" }, { \"miner\" : \"f0230200\" , \"totalCost\" : \"253000000000\" , \"verifiedTotalCost\" : \"25300000000\" , \"price\" : \"500000000\" , \"verifiedPrice\" : \"50000000\" } ], \"paddedSize\" : \"1048576\" , \"durationEpochs\" : \"518400\" }","title":"Calculator"},{"location":"filecoin/miner-index/#miner-profiles","text":"The API also has an endpoint to retrieve the latest stats and profile information for a single miner. Here is the request for the profile of the first miner in our results above. The following is the full JSON result from the profile API request. { \"info\" : { \"minerAddr\" : \"f0221135\" , \"metadata\" : { \"location\" : \"US\" }, \"filecoin\" : { \"relativePower\" : 1.7012885147319677e-7 , \"askPrice\" : \"1000000000\" , \"askVerifiedPrice\" : \"500000000\" , \"minPieceSize\" : \"10485760\" , \"maxPieceSize\" : \"34359738368\" , \"sectorSize\" : \"34359738368\" , \"activeSectors\" : \"19\" , \"faultySectors\" : \"0\" , \"updatedAt\" : \"2021-03-17T20:03:17.390Z\" }, \"textile\" : { \"regions\" : { \"021\" : { \"deals\" : { \"total\" : \"2\" , \"last\" : \"2021-03-06T14:30:38.165Z\" , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [ { \"transferedAt\" : \"2021-03-05T17:25:41Z\" , \"mibPerSec\" : 12.671646024933173 }, { \"transferedAt\" : \"2021-03-03T18:16:38Z\" , \"mibPerSec\" : 9.75200344552067 } ], \"tailSealed\" : [ { \"sealedAt\" : \"2021-03-06T14:30:38Z\" , \"durationSeconds\" : \"9900\" }, { \"sealedAt\" : \"2021-03-04T13:59:13Z\" , \"durationSeconds\" : \"9900\" } ] }, \"retrievals\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [] } } }, \"dealsSummary\" : { \"total\" : \"2\" , \"last\" : \"2021-03-06T14:30:38.165Z\" , \"failures\" : \"0\" , \"lastFailure\" : null }, \"retrievalsSummary\" : { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null }, \"updatedAt\" : \"2021-03-17T20:03:01.056Z\" }, \"updatedAt\" : \"2021-03-17T20:03:01.056Z\" } }","title":"Miner profiles"},{"location":"filecoin/miner-index/#hub-cli","text":"We leverage the REST API above to provide simple command-line access to the miner index. Here are some interesting places to get started. Query the index Calculate deal costs Get miner profiles Expanded results You can access a full table of results for any query by using the --show-full-details flag. hub fil index query --show-full-details --limit 20 Scripting Each CLI methods for the index supports a --json flag to output results to JSON. hub fil index query --show-full-details --limit 1 --json | jq -r \".miners[]\"","title":"Hub CLI"},{"location":"filecoin/miner-index/#how-it-works","text":"Textile's miner index is different than most others you'll find on the network. The key distinction is that this index pulls real data from many Lotus and Powergate nodes connected to mainnet. The index collects both the on-chain information plus a suite of off-chain telemetry that can be very informative for advanced selection of miners. All telemetry is currently measured from clients based in North America (region 021 in the API), but will expand in the future. Some interesting features of the index you may wish to leverage include the following. We've populated the below from real-time index results for the first miner listed above.","title":"How it works"},{"location":"filecoin/miner-index/#deals-summary","text":"Calculated across all regions. { \"total\" : \"120\" , \"last\" : \"2021-03-17T14:56:51.360Z\" , \"failures\" : \"57\" , \"lastFailure\" : \"2021-03-17T19:41:28.922Z\" }","title":"Deals summary"},{"location":"filecoin/miner-index/#transfer-stats","text":"Tail of latest transfer stats from clients in North America. [ { \"transferedAt\" : \"2021-03-16T16:02:57Z\" , \"mibPerSec\" : 13.257300327974415 }, { \"transferedAt\" : \"2021-03-15T19:43:35Z\" , \"mibPerSec\" : 20.399272781121926 }, { \"transferedAt\" : \"2021-03-15T20:19:30Z\" , \"mibPerSec\" : 20.739260660807293 }, { \"transferedAt\" : \"2021-03-05T17:23:59Z\" , \"mibPerSec\" : 13.070962601349134 }, { \"transferedAt\" : \"2021-03-05T17:00:31Z\" , \"mibPerSec\" : 14.778570542142964 }, { \"transferedAt\" : \"2021-03-05T16:56:07Z\" , \"mibPerSec\" : 16.953074109651737 }, { \"transferedAt\" : \"2021-03-05T17:32:04Z\" , \"mibPerSec\" : 15.791315223964943 }, { \"transferedAt\" : \"2021-03-03T18:16:38Z\" , \"mibPerSec\" : 9.75200344552067 }, { \"transferedAt\" : \"2021-02-27T02:47:50Z\" , \"mibPerSec\" : 7.480152248979115 }, { \"transferedAt\" : \"2021-02-24T20:46:23Z\" , \"mibPerSec\" : 20.966012990699625 }, { \"transferedAt\" : \"2021-02-23T02:00:08Z\" , \"mibPerSec\" : 12.749545486246953 } ]","title":"Transfer stats"},{"location":"filecoin/miner-index/#sealing-stats","text":"Tail of latest sealing stats from clients in North America. [ { \"sealedAt\" : \"2021-03-17T14:56:51Z\" , \"durationSeconds\" : \"9440\" }, { \"sealedAt\" : \"2021-03-16T14:02:38Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-16T13:56:09Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-03-06T05:49:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:49:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:46:35Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-06T05:45:37Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-04T07:00:50Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-03-03T22:40:39Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-27T15:57:58Z\" , \"durationSeconds\" : \"9000\" }, { \"sealedAt\" : \"2021-02-25T08:57:14Z\" , \"durationSeconds\" : \"7200\" }, { \"sealedAt\" : \"2021-02-23T14:44:18Z\" , \"durationSeconds\" : \"9000\" } ]","title":"Sealing stats"},{"location":"filecoin/miner-index/#latest-retrievals","text":"Latest retrievals for clients in North America. { \"total\" : \"0\" , \"last\" : null , \"failures\" : \"0\" , \"lastFailure\" : null , \"tailTransfers\" : [] }","title":"Latest Retrievals"},{"location":"filecoin/miner-index/#javascript-examples","text":"The tables and JSON results above are all generated in real-time by using the miner index API endpoint. Here are a few examples you can use.","title":"JavaScript Examples"},{"location":"filecoin/miner-index/#query","text":"var table = document . getElementById ( \"miner-table\" ); fetch ( \"https://minerindex.hub.textile.io/v1/index/query?sort.ascending=false&sort.field=TEXTILE_DEALS_LAST_SUCCESSFUL&limit=5\" ) . then (( response ) => response . json ()) . then (( data ) => { var rct = 0 ; for ( var miner of data . miners ) { var row = table . insertRow ( rct ); var minerAddr = row . insertCell ( 0 ); minerAddr . innerHTML = miner . minerAddr ; rct += 1 ; } });","title":"Query"},{"location":"filecoin/miner-index/#calculate","text":"var table = document . getElementById ( \"miner-table\" ); fetch ( \"https://minerindex.hub.textile.io/v1/calculator/calculate?dataSizeBytes=1000000&durationDays=180&minerAddresses=f09848\" ) . then (( response ) => response . json ()) . then (( data ) => { console . log ( data ); });","title":"Calculate"},{"location":"filecoin/miner-index/#get-profile","text":"var table = document . getElementById ( \"miner-table\" ); fetch ( \"https://minerindex.hub.textile.io/v1/index/miner/f09848\" ) . then (( response ) => response . json ()) . then (( data ) => { console . log ( data ); }); Build on! function updateProfile(miner) { var url = \"https://minerindex.hub.textile.io/v1/index/miner/\" + miner var apiurl = document.getElementById(\"profile-api\"); apiurl.href = url; apiurl.text = url; var rct = 0; fetch(url) .then(response => response.json()) .then(data => { var res = document.querySelector(\"#profile-result pre code\") res.innerHTML = JSON.stringify(data, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); }) } function updateCalculator(miners) { var table = document.getElementById(\"calculator-results\"); var url = \"https://minerindex.hub.textile.io/v1/calculator/calculate?dataSizeBytes=1000000&durationDays=180&\" for (var miner of miners) { url += \"&minerAddresses=\" + miner } var apiurl = document.getElementById(\"calculator-api\"); apiurl.href = url; apiurl.text = url; var rct = 0; fetch(url) .then(response => response.json()) .then(data => { var res = document.querySelector(\"#calculator-result pre code\") res.innerHTML = JSON.stringify(data, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); for (var r of data.results) { var row = table.insertRow(rct); rct += 1; var minerAddr = row.insertCell(0); minerAddr.innerHTML = r.miner; var cost = row.insertCell(1); cost.innerHTML = r.totalCost; var verified = row.insertCell(2); verified.innerHTML = r.verifiedTotalCost; var duration = row.insertCell(3); duration.innerHTML = data.durationEpochs; var padded = row.insertCell(4); padded.innerHTML = data.paddedSize; } }) } var table = document.getElementById(\"miners-results\"); var rct = 0; var calc = [] fetch('https://minerindex.hub.textile.io/v1/index/query?sort.ascending=false&sort.field=TEXTILE_DEALS_LAST_SUCCESSFUL&limit=5') .then(response => response.json()) .then(data => { for (var row of data.miners) { var miner = row.miner; var row = table.insertRow(rct); if (rct === 0) { var res = document.querySelector(\"#first-result pre code\") res.innerHTML = JSON.stringify(miner, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); updateProfile(miner.minerAddr) res = document.querySelector(\"#deals-summary pre code\") res.innerHTML = JSON.stringify(miner.textile.dealsSummary, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); res = document.querySelector(\"#transfer-stats pre code\") res.innerHTML = JSON.stringify(miner.textile.regions[\"021\"].deals.tailTransfers, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); res = document.querySelector(\"#sealing-stats pre code\") res.innerHTML = JSON.stringify(miner.textile.regions[\"021\"].deals.tailSealed, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); res = document.querySelector(\"#latest-retrievals pre code\") res.innerHTML = JSON.stringify(miner.textile.regions[\"021\"].retrievals, undefined, 2); res.className = \"language-json\"; Prism.highlightElement(res); } calc.push(miner.minerAddr); rct += 1; var minerAddr = row.insertCell(0); minerAddr.innerHTML = miner.minerAddr; var price = row.insertCell(1); price.innerHTML = miner[\"filecoin\"].askPrice; var verified = row.insertCell(2); verified.innerHTML = miner.filecoin.askVerifiedPrice; var location = row.insertCell(3); location.innerHTML = miner.metadata.location; var minSize = row.insertCell(4); minSize.innerHTML = miner.filecoin.minPieceSize; var lastDeal = row.insertCell(5); lastDeal.innerHTML = miner.textile.dealsSummary.last; } updateCalculator(calc); });","title":"Get Profile"},{"location":"filecoin/storage-deals/","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Also note that archiving will be disabled and will no longer be possible via the hosted Hub infrastructure. You will be adding data to the Filecoin through your use of the buckets and bucket archives . However, it can also be helpful to monitor all deals you have created with your Hub wallet. For that, we have the following tools. Get all storage records \u00b6 This command will list all the storage records requests you've made across all of your buckets. hub fil storage Success > Success! { \"records\" : [ { \"rootCid\" : \"bafybeifimdtphhaqrh5zxyfixr52sjnopyae7oqjsvnqspsfvd2prmlb6a\" , \"address\" : \"t3wtnwtjwzwcdbfl24rzepbo3ytqzw2dif3ofwqituzo5v4k5fmguvp56mtq444ozukbbuvhe7zxcb6vhb2e4q\" , \"time\" : \"1600802782\" , \"pending\" : false, \"dealInfo\" : { \"proposalCid\" : \"bafyreib55eifkle5l5rtnhw3cuecd5kzcmlius4vvimaxm7gdiim4wwkjm\" , \"stateId\" : \"7\" , \"stateName\" : \"StorageDealActive\" , \"miner\" : \"t016309\" , \"pieceCid\" : \"baga6ea4seaqokoj6iw4ln7ybrbmsedkxttplz7cb3xaun2aqqhx7sfil6if62ka\" , \"size\" : \"508\" , \"pricePerEpoch\" : \"0\" , \"startEpoch\" : \"83794\" , \"duration\" : \"1039744\" , \"dealId\" : \"153141\" , \"activationEpoch\" : \"83205\" , \"message\" : \"\" } , \"transferSize\" : \"0\" , \"dataTransferStart\" : \"1970-01-01T00:00:00Z\" , \"dataTransferEnd\" : \"1970-01-01T00:00:00Z\" , \"sealingStart\" : \"1970-01-01T00:00:00Z\" , \"sealingEnd\" : \"1970-01-01T00:00:00Z\" , \"errMsg\" : \"\" , \"updatedAt\" : \"2020-09-22T19:26:22.000000090Z\" } ] } You can filter your array of storage requests by source CID ( --cids ) and filter the results by only finalized deals ( --include-final ) or pending deals ( --include-pending ).","title":"Storage Deals"},{"location":"filecoin/storage-deals/#get-all-storage-records","text":"This command will list all the storage records requests you've made across all of your buckets. hub fil storage Success > Success! { \"records\" : [ { \"rootCid\" : \"bafybeifimdtphhaqrh5zxyfixr52sjnopyae7oqjsvnqspsfvd2prmlb6a\" , \"address\" : \"t3wtnwtjwzwcdbfl24rzepbo3ytqzw2dif3ofwqituzo5v4k5fmguvp56mtq444ozukbbuvhe7zxcb6vhb2e4q\" , \"time\" : \"1600802782\" , \"pending\" : false, \"dealInfo\" : { \"proposalCid\" : \"bafyreib55eifkle5l5rtnhw3cuecd5kzcmlius4vvimaxm7gdiim4wwkjm\" , \"stateId\" : \"7\" , \"stateName\" : \"StorageDealActive\" , \"miner\" : \"t016309\" , \"pieceCid\" : \"baga6ea4seaqokoj6iw4ln7ybrbmsedkxttplz7cb3xaun2aqqhx7sfil6if62ka\" , \"size\" : \"508\" , \"pricePerEpoch\" : \"0\" , \"startEpoch\" : \"83794\" , \"duration\" : \"1039744\" , \"dealId\" : \"153141\" , \"activationEpoch\" : \"83205\" , \"message\" : \"\" } , \"transferSize\" : \"0\" , \"dataTransferStart\" : \"1970-01-01T00:00:00Z\" , \"dataTransferEnd\" : \"1970-01-01T00:00:00Z\" , \"sealingStart\" : \"1970-01-01T00:00:00Z\" , \"sealingEnd\" : \"1970-01-01T00:00:00Z\" , \"errMsg\" : \"\" , \"updatedAt\" : \"2020-09-22T19:26:22.000000090Z\" } ] } You can filter your array of storage requests by source CID ( --cids ) and filter the results by only finalized deals ( --include-final ) or pending deals ( --include-pending ).","title":"Get all storage records"},{"location":"hub/","text":"The Hub is a platform for building and experimenting with Textile technologies. It provides: Hosted Buckets and Threads with persistent IPFS endpoints. Developer accounts for individuals and organizations. API key integration into apps. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Security \u00b6 APIs and protocols may change rapidly. There may be coding mistakes, and the underlying protocols may contain design flaws. Please let us know immediately if you have discovered a security vulnerability. Please also read the security note for go-ipfs. Available commands \u00b6 To get started, you'll be using the Hub client. The layout of the Hub CLI mirrors the services available, for example: hub threads provide limited access to ThreadDB. hub buck provides access to Buckets. hub keys create and expire API keys. hub orgs lets you create multi-developer organizations for collaboration. Once you've set up an account on the Hub, you can start accessing those resources right away. Additionally, you can use the API keys to grant restricted access to your Hub resources to the end-users of your apps and services. Roles \u00b6 Developers \u00b6 Developers are the primary account owner. Using the CLI, developers can: Create new API keys. Create and join new Organizations and access admin APIs. Create your own Buckets and Threads. Organizations \u00b6 You and your collaborators. Members can: Share admin control of API keys. Share access to and synchronize Bucket state across all members. Referenced through docs as simply, Org . Users \u00b6 Accounts generated by your app using a User Group API key. Your app can create Threads and Buckets owned by these users. Users can then add or remove content from those assets based on their identity. Users cannot use the CLI and cannot create new API keys. Next steps \u00b6 Install & Create Account \u00b6 The Hub is API driven and available through the command-line tool and developer libraries. To use the Hub, you need to download the command-line interface and create an account. Create an Account Start using hosted services by creating your free account. Connect your Apps Learn how to use the Hub's APIs in your app. Hub CLI Read the full CLI documentation.","title":"Overview"},{"location":"hub/#security","text":"APIs and protocols may change rapidly. There may be coding mistakes, and the underlying protocols may contain design flaws. Please let us know immediately if you have discovered a security vulnerability. Please also read the security note for go-ipfs.","title":"Security"},{"location":"hub/#available-commands","text":"To get started, you'll be using the Hub client. The layout of the Hub CLI mirrors the services available, for example: hub threads provide limited access to ThreadDB. hub buck provides access to Buckets. hub keys create and expire API keys. hub orgs lets you create multi-developer organizations for collaboration. Once you've set up an account on the Hub, you can start accessing those resources right away. Additionally, you can use the API keys to grant restricted access to your Hub resources to the end-users of your apps and services.","title":"Available commands"},{"location":"hub/#roles","text":"","title":"Roles"},{"location":"hub/#developers","text":"Developers are the primary account owner. Using the CLI, developers can: Create new API keys. Create and join new Organizations and access admin APIs. Create your own Buckets and Threads.","title":"Developers"},{"location":"hub/#organizations","text":"You and your collaborators. Members can: Share admin control of API keys. Share access to and synchronize Bucket state across all members. Referenced through docs as simply, Org .","title":"Organizations"},{"location":"hub/#users","text":"Accounts generated by your app using a User Group API key. Your app can create Threads and Buckets owned by these users. Users can then add or remove content from those assets based on their identity. Users cannot use the CLI and cannot create new API keys.","title":"Users"},{"location":"hub/#next-steps","text":"","title":"Next steps"},{"location":"hub/#install-create-account","text":"The Hub is API driven and available through the command-line tool and developer libraries. To use the Hub, you need to download the command-line interface and create an account.","title":"Install &amp; Create Account"},{"location":"hub/accounts/","text":"Installation and Account Setup \u00b6 The Hub is no longer accepting new accounts. Take a look at one of these services: Tableland FileDrive Fleek Estuary Web3.Storage Pinata","title":"Installation & Setup"},{"location":"hub/accounts/#installation-and-account-setup","text":"The Hub is no longer accepting new accounts. Take a look at one of these services: Tableland FileDrive Fleek Estuary Web3.Storage Pinata","title":"Installation and Account Setup"},{"location":"hub/apis/","text":"APIs and API Keys \u00b6 Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Textile has three API categories for building an application: Threads, Buckets, and Mailboxes. To use any of these APIs, you need to use API keys. Read Google's API key best practices for an overview of how API keys will be used here. This section will cover the overview of the three APIs and how to work with the API keys. A Tour of Available APIs \u00b6 Buckets \u00b6 Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the CLI , you can create Buckets using JavaScript with js-textile . The js-textile library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key . ThreadDB \u00b6 ThreadDB is a mongo-like database that runs on IPFS. You can use js-textile to connect to the Hub's hosted thread server ( Client ) to push and persist encrypted data on an IPFS-backed database. Alternatively, you can embed local, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates ( Database ). Mailboxes \u00b6 The Users API provides tools for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Hub mailboxes are a unique inboxing and messaging system designed for modern apps where users hold private keys linked to their identity. With just their private and public key, a user can send and receive encrypted messages to other users in your app. API Access \u00b6 You can access the Hub APIs through the use of API keys. API Keys \u00b6 The Hub has two forms of an API key, an Account Key and a User Group Key . Account Keys \u00b6 Account keys grant access to the developer's resources (e.g. Buckets you create using the command-line interface). If Account Keys are generated with the -o (organization) flag, they will grant access to that organization's resources. Example uses include, integrating your Buckets into CI, dashboards, team messaging integration, etc. User Group Keys \u00b6 User group keys only grant access to new resources for new identities, not those of the developer. User group keys can be used in an application to allow app users to leverage Hub APIs (e.g. create and push new buckets). User group keys do not have permission to access the developer or organization resources, but threads and buckets created using these keys are counted against API limits . Key Use and Security \u00b6 API keys are project-centric credentials that you can use to provision your Hub resources to end-users (either within your organization or in a public app). We recommend reading this thorough overview of API key design and best practices . Access Summary \u00b6 Below is a summary of the Hub resources you may create and access with each key type. Resource example Owner CLI Required Key Developer Threads Hub Developer create, access Account Key Developer Buckets Hub Developer create, access Account Key Organization Threads Hub Developer(s) create, access Account Key Organization Buckets Hub Developer(s) create, access Account Key User Threads App User User Group Key User Buckets App User User Group Key Creating Keys \u00b6 Account Key \u00b6 Create a new Account Key by using hub key create with the account option: See CLI options User Group Key \u00b6 Create a new User Group Key by using hub key create with the user group option. If you're building an app in an organization, use: HUB_ORG = <org name> hub key create To link a new key to the organization, not your personal account. Currently, there are no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ). \u279c hub key create # select the 'user' option \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret Non-signing User Group keys \u00b6 You can use insecure keys with the API by creating non-signing keys. These keys are meant to be used during development only. Read the tutorial on development mode to use these keys. Updating User Group keys \u00b6 You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. See CLI commands API Libraries \u00b6 You can find all the remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Thread databases in your app. JS Hub Start threads, buckets, and user creation in any JavaScript app. Go Buckets Use the Buckets daemon or client from Go Hub CLI Use scripting and command-line tooling with the Hub CLI.","title":"API Usage & Keys"},{"location":"hub/apis/#apis-and-api-keys","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Textile has three API categories for building an application: Threads, Buckets, and Mailboxes. To use any of these APIs, you need to use API keys. Read Google's API key best practices for an overview of how API keys will be used here. This section will cover the overview of the three APIs and how to work with the API keys.","title":"APIs and API Keys"},{"location":"hub/apis/#a-tour-of-available-apis","text":"","title":"A Tour of Available APIs"},{"location":"hub/apis/#buckets","text":"Buckets provide S3-like data storage on IPFS. Just as you can create Buckets with the CLI , you can create Buckets using JavaScript with js-textile . The js-textile library allows you to create and edit Buckets owned by you or your organization using an account key . Alternatively, you can use Buckets to store your user's data using a user group key .","title":"Buckets"},{"location":"hub/apis/#threaddb","text":"ThreadDB is a mongo-like database that runs on IPFS. You can use js-textile to connect to the Hub's hosted thread server ( Client ) to push and persist encrypted data on an IPFS-backed database. Alternatively, you can embed local, p2p databases in your app that use remote IPFS peers for pinning and remote ThreadDB peers to relay updates ( Database ).","title":"ThreadDB"},{"location":"hub/apis/#mailboxes","text":"The Users API provides tools for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Hub mailboxes are a unique inboxing and messaging system designed for modern apps where users hold private keys linked to their identity. With just their private and public key, a user can send and receive encrypted messages to other users in your app.","title":"Mailboxes"},{"location":"hub/apis/#api-access","text":"You can access the Hub APIs through the use of API keys.","title":"API Access"},{"location":"hub/apis/#api-keys","text":"The Hub has two forms of an API key, an Account Key and a User Group Key .","title":"API Keys"},{"location":"hub/apis/#account-keys","text":"Account keys grant access to the developer's resources (e.g. Buckets you create using the command-line interface). If Account Keys are generated with the -o (organization) flag, they will grant access to that organization's resources. Example uses include, integrating your Buckets into CI, dashboards, team messaging integration, etc.","title":"Account Keys"},{"location":"hub/apis/#user-group-keys","text":"User group keys only grant access to new resources for new identities, not those of the developer. User group keys can be used in an application to allow app users to leverage Hub APIs (e.g. create and push new buckets). User group keys do not have permission to access the developer or organization resources, but threads and buckets created using these keys are counted against API limits .","title":"User Group Keys"},{"location":"hub/apis/#key-use-and-security","text":"API keys are project-centric credentials that you can use to provision your Hub resources to end-users (either within your organization or in a public app). We recommend reading this thorough overview of API key design and best practices .","title":"Key Use and Security"},{"location":"hub/apis/#access-summary","text":"Below is a summary of the Hub resources you may create and access with each key type. Resource example Owner CLI Required Key Developer Threads Hub Developer create, access Account Key Developer Buckets Hub Developer create, access Account Key Organization Threads Hub Developer(s) create, access Account Key Organization Buckets Hub Developer(s) create, access Account Key User Threads App User User Group Key User Buckets App User User Group Key","title":"Access Summary"},{"location":"hub/apis/#creating-keys","text":"","title":"Creating Keys"},{"location":"hub/apis/#account-key","text":"Create a new Account Key by using hub key create with the account option: See CLI options","title":"Account Key"},{"location":"hub/apis/#user-group-key","text":"Create a new User Group Key by using hub key create with the user group option. If you're building an app in an organization, use: HUB_ORG = <org name> hub key create To link a new key to the organization, not your personal account. Currently, there are no migration tools, so we recommend creating a new organization or using an existing organization when starting a new app (see Organizations ). \u279c hub key create # select the 'user' option \u2714 user KEY SECRET TYPE bqab5csdh...no6jjezox4 bm2tk476yivwlw...3a4cayll7ztha user > Success! Created new API key and secret","title":"User Group Key"},{"location":"hub/apis/#non-signing-user-group-keys","text":"You can use insecure keys with the API by creating non-signing keys. These keys are meant to be used during development only. Read the tutorial on development mode to use these keys.","title":"Non-signing User Group keys"},{"location":"hub/apis/#updating-user-group-keys","text":"You can replace your keys in your app at any time and the user will still have access to their Threads and Buckets as long as the key is connected to the same developer or organization. See CLI commands","title":"Updating User Group keys"},{"location":"hub/apis/#api-libraries","text":"You can find all the remote Thread and Bucket APIs in the textile libraries below. These libraries are meant to work in combination with the threads libraries when you want to create and manage Thread databases in your app.","title":"API Libraries"},{"location":"hub/pricing/","text":"Warning The Hub is no longer accepting new accounts. For those that already have an account setup, please contact us at support@textile.io , or check your email for deprecation details and account information. Prices \u00b6 Pay only for what you use. API Pricing Free Limit Cost Storage 5 GiB $0.03 per GiB per Month ThreadDB Reads 50,000 per Day $0.01 per 10,000 ThreadDB Writes 20,000 per Day $0.02 per 10,000 Network Egress 10 GiB per Month $0.1 per GiB Storage includes all data pinned to IPFS. It does not include archives you submit to Filecoin. Grace Period \u00b6 Billing starts on any account the first time they go over any Free Limit . When an account triggers billing for the first time, they enter a 30-day grace period in which they should complete the billing setup on their account. Billing can be set up on an account at any time by using the Hub CLI: hub billing --help Other Quotas \u00b6 Each entity above has its own quota no matter which role it is (Developer, Org, or User). Limits Max Threads Per Owner 100 Minimum Filecoin Deal Size 32 MiB","title":"Pricing"},{"location":"hub/pricing/#prices","text":"Pay only for what you use. API Pricing Free Limit Cost Storage 5 GiB $0.03 per GiB per Month ThreadDB Reads 50,000 per Day $0.01 per 10,000 ThreadDB Writes 20,000 per Day $0.02 per 10,000 Network Egress 10 GiB per Month $0.1 per GiB Storage includes all data pinned to IPFS. It does not include archives you submit to Filecoin.","title":"Prices"},{"location":"hub/pricing/#grace-period","text":"Billing starts on any account the first time they go over any Free Limit . When an account triggers billing for the first time, they enter a 30-day grace period in which they should complete the billing setup on their account. Billing can be set up on an account at any time by using the Hub CLI: hub billing --help","title":"Grace Period"},{"location":"hub/pricing/#other-quotas","text":"Each entity above has its own quota no matter which role it is (Developer, Org, or User). Limits Max Threads Per Owner 100 Minimum Filecoin Deal Size 32 MiB","title":"Other Quotas"},{"location":"hub/cli/hub/","text":"hub \u00b6 The Hub Client. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Options \u00b6 --api string API Hub target (default \"api.hub.textile.io:443\") --apiKey string User API key --apiMinerIndex string API MinerIndex target (default \"api.minerindex.hub.textile.io:443\") --apiSecret string User API secret -h, --help help for hub --identity string User identity --newIdentity Generate a new user identity -o, --org string Org username -s, --session string User session token --token string User identity token SEE ALSO \u00b6 hub billing - Billing management hub buck - Manage an object storage bucket hub destroy - Destroy your account hub fil - Interact with Filecoin related commands. hub init - Initialize account hub keys - API key management hub login - Login hub logout - Logout hub orgs - Org management hub threads - Thread management hub update - Update the hub CLI hub version - Show current version hub whoami - Show current user","title":"Overview"},{"location":"hub/cli/hub/#hub","text":"The Hub Client. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details.","title":"hub"},{"location":"hub/cli/hub/#options","text":"--api string API Hub target (default \"api.hub.textile.io:443\") --apiKey string User API key --apiMinerIndex string API MinerIndex target (default \"api.minerindex.hub.textile.io:443\") --apiSecret string User API secret -h, --help help for hub --identity string User identity --newIdentity Generate a new user identity -o, --org string Org username -s, --session string User session token --token string User identity token","title":"Options"},{"location":"hub/cli/hub/#see-also","text":"hub billing - Billing management hub buck - Manage an object storage bucket hub destroy - Destroy your account hub fil - Interact with Filecoin related commands. hub init - Initialize account hub keys - API key management hub login - Login hub logout - Logout hub orgs - Org management hub threads - Thread management hub update - Update the hub CLI hub version - Show current version hub whoami - Show current user","title":"SEE ALSO"},{"location":"hub/cli/hub_billing/","text":"hub billing \u00b6 Manages your billing preferences. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Options \u00b6 -h, --help help for billing SEE ALSO \u00b6 hub - Hub Client hub billing portal - Open billing web portal hub billing setup - Setup usage billing hub billing usage - Show usage and billing info hub billing users - list contributing users","title":"Overview"},{"location":"hub/cli/hub_billing/#hub-billing","text":"Manages your billing preferences. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details.","title":"hub billing"},{"location":"hub/cli/hub_billing/#options","text":"-h, --help help for billing","title":"Options"},{"location":"hub/cli/hub_billing/#see-also","text":"hub - Hub Client hub billing portal - Open billing web portal hub billing setup - Setup usage billing hub billing usage - Show usage and billing info hub billing users - list contributing users","title":"SEE ALSO"},{"location":"hub/cli/hub_billing_portal/","text":"hub billing portal \u00b6 Opens a web portal for managing billing preferences. hub billing portal [flags] Options \u00b6 -h, --help help for portal SEE ALSO \u00b6 hub billing - Billing management","title":"Portal"},{"location":"hub/cli/hub_billing_portal/#hub-billing-portal","text":"Opens a web portal for managing billing preferences. hub billing portal [flags]","title":"hub billing portal"},{"location":"hub/cli/hub_billing_portal/#options","text":"-h, --help help for portal","title":"Options"},{"location":"hub/cli/hub_billing_portal/#see-also","text":"hub billing - Billing management","title":"SEE ALSO"},{"location":"hub/cli/hub_billing_setup/","text":"hub billing setup \u00b6 Sets up metered usage billing. hub billing setup [flags] Options \u00b6 -h, --help help for setup SEE ALSO \u00b6 hub billing - Billing management","title":"Setup"},{"location":"hub/cli/hub_billing_setup/#hub-billing-setup","text":"Sets up metered usage billing. hub billing setup [flags]","title":"hub billing setup"},{"location":"hub/cli/hub_billing_setup/#options","text":"-h, --help help for setup","title":"Options"},{"location":"hub/cli/hub_billing_setup/#see-also","text":"hub billing - Billing management","title":"SEE ALSO"},{"location":"hub/cli/hub_billing_usage/","text":"hub billing usage \u00b6 Shows usage and billing information Usage is evaluated daily and invoiced monthly. Use the --user flag to get usage for a dependent user. hub billing usage [flags] Options \u00b6 -h, --help help for usage -u, --user string User multibase encoded public key SEE ALSO \u00b6 hub billing - Billing management","title":"Usage"},{"location":"hub/cli/hub_billing_usage/#hub-billing-usage","text":"Shows usage and billing information Usage is evaluated daily and invoiced monthly. Use the --user flag to get usage for a dependent user. hub billing usage [flags]","title":"hub billing usage"},{"location":"hub/cli/hub_billing_usage/#options","text":"-h, --help help for usage -u, --user string User multibase encoded public key","title":"Options"},{"location":"hub/cli/hub_billing_usage/#see-also","text":"hub billing - Billing management","title":"SEE ALSO"},{"location":"hub/cli/hub_billing_users/","text":"hub billing users \u00b6 Lists users contributing to billing usage. hub billing users [flags] Options \u00b6 -h, --help help for users --limit int Page size (max 1000) (default 25) --offset int Page offset (returned by each request) SEE ALSO \u00b6 hub billing - Billing management","title":"Users"},{"location":"hub/cli/hub_billing_users/#hub-billing-users","text":"Lists users contributing to billing usage. hub billing users [flags]","title":"hub billing users"},{"location":"hub/cli/hub_billing_users/#options","text":"-h, --help help for users --limit int Page size (max 1000) (default 25) --offset int Page offset (returned by each request)","title":"Options"},{"location":"hub/cli/hub_billing_users/#see-also","text":"hub billing - Billing management","title":"SEE ALSO"},{"location":"hub/cli/hub_buck/","text":"hub buck \u00b6 Manages files and folders in an object storage bucket. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. Options \u00b6 -h, --help help for buck --key string Bucket key --thread string Thread ID SEE ALSO \u00b6 hub - Hub Client hub buck add - Add adds a UnixFs DAG locally at path hub buck archive - Create a Filecoin archive hub buck cat - Cat bucket objects at path hub buck decrypt - Decrypt bucket objects at path with password hub buck destroy - Destroy bucket and all objects hub buck encrypt - Encrypt file with a password hub buck existing - List buckets hub buck get - Get a bucket hub buck init - Initialize a new or existing bucket hub buck links - Display URL links to a bucket object. hub buck ls - List top-level or nested bucket objects hub buck pull - Pull bucket object changes hub buck push - Push bucket object changes hub buck roles - Object access role management hub buck root - Show bucket root CIDs hub buck status - Show bucket object changes hub buck watch - Watch auto-pushes local changes to the remote","title":"Overview"},{"location":"hub/cli/hub_buck/#hub-buck","text":"Manages files and folders in an object storage bucket. Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details.","title":"hub buck"},{"location":"hub/cli/hub_buck/#options","text":"-h, --help help for buck --key string Bucket key --thread string Thread ID","title":"Options"},{"location":"hub/cli/hub_buck/#see-also","text":"hub - Hub Client hub buck add - Add adds a UnixFs DAG locally at path hub buck archive - Create a Filecoin archive hub buck cat - Cat bucket objects at path hub buck decrypt - Decrypt bucket objects at path with password hub buck destroy - Destroy bucket and all objects hub buck encrypt - Encrypt file with a password hub buck existing - List buckets hub buck get - Get a bucket hub buck init - Initialize a new or existing bucket hub buck links - Display URL links to a bucket object. hub buck ls - List top-level or nested bucket objects hub buck pull - Pull bucket object changes hub buck push - Push bucket object changes hub buck roles - Object access role management hub buck root - Show bucket root CIDs hub buck status - Show bucket object changes hub buck watch - Watch auto-pushes local changes to the remote","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_add/","text":"hub buck add \u00b6 Add adds a UnixFs DAG locally at path, merging with existing content. hub buck add [cid] [path] [flags] Options \u00b6 -h, --help help for add -y, --yes Skips confirmations prompts to always overwrite files and merge folders SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Add"},{"location":"hub/cli/hub_buck_add/#hub-buck-add","text":"Add adds a UnixFs DAG locally at path, merging with existing content. hub buck add [cid] [path] [flags]","title":"hub buck add"},{"location":"hub/cli/hub_buck_add/#options","text":"-h, --help help for add -y, --yes Skips confirmations prompts to always overwrite files and merge folders","title":"Options"},{"location":"hub/cli/hub_buck_add/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive/","text":"hub buck archive \u00b6 Creates a Filecoin archive from the remote bucket root. Pass in a custom archive storage config via the --file flag or stdin to override the default archive storage configuration. hub buck archive [flags] Options \u00b6 -f, --file string Optional path to a file containing archive config json that will override the default -h, --help help for archive -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket hub buck archive default-config - Print the default archive storage configuration for the specified Bucket. hub buck archive list - Shows information about current and historical archives. hub buck archive set-default-config - Set the default archive storage configuration for the specified Bucket. hub buck archive watch - Watch the status of the most recent bucket archive.","title":"Archive"},{"location":"hub/cli/hub_buck_archive/#hub-buck-archive","text":"Creates a Filecoin archive from the remote bucket root. Pass in a custom archive storage config via the --file flag or stdin to override the default archive storage configuration. hub buck archive [flags]","title":"hub buck archive"},{"location":"hub/cli/hub_buck_archive/#options","text":"-f, --file string Optional path to a file containing archive config json that will override the default -h, --help help for archive -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_archive/#see-also","text":"hub buck - Manage an object storage bucket hub buck archive default-config - Print the default archive storage configuration for the specified Bucket. hub buck archive list - Shows information about current and historical archives. hub buck archive set-default-config - Set the default archive storage configuration for the specified Bucket. hub buck archive watch - Watch the status of the most recent bucket archive.","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_default-config/","text":"hub buck archive default-config \u00b6 Print the default archive storage configuration for the specified Bucket. hub buck archive default-config [flags] Options \u00b6 -h, --help help for default-config SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive default-config"},{"location":"hub/cli/hub_buck_archive_default-config/#hub-buck-archive-default-config","text":"Print the default archive storage configuration for the specified Bucket. hub buck archive default-config [flags]","title":"hub buck archive default-config"},{"location":"hub/cli/hub_buck_archive_default-config/#options","text":"-h, --help help for default-config","title":"Options"},{"location":"hub/cli/hub_buck_archive_default-config/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_list/","text":"hub buck archive list \u00b6 Shows information about current and historical archives. hub buck archive list [flags] Options \u00b6 -h, --help help for list SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive list"},{"location":"hub/cli/hub_buck_archive_list/#hub-buck-archive-list","text":"Shows information about current and historical archives. hub buck archive list [flags]","title":"hub buck archive list"},{"location":"hub/cli/hub_buck_archive_list/#options","text":"-h, --help help for list","title":"Options"},{"location":"hub/cli/hub_buck_archive_list/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_set-default-config/","text":"hub buck archive set-default-config \u00b6 Set the default archive storage configuration for the specified Bucket from a file, stdin, or flags. If flags are specified, this command updates the current default storage-config with the explicitely set flags. Flags that aren't explicitely set won't set the default value, and thus keep the original value in the storage-config. If a file or stdin is used, the storage-config will be completely overriden by the provided one. hub buck archive set-default-config [(optional)file] [flags] Examples \u00b6 hub buck archive set-default-config --rep-factor=3 --fast-retrieval --verified-deal --trusted-miners=f08240,f023467,f09848 Options \u00b6 -c, --country-codes strings Select miners with specific countries -d, --deal-min-duration int Minimum duration for the deal -e, --deal-start-offset int Epochs in the future impose a deadline for deals to be on-chain -x, --excluded-miners strings Miner addresses that should not be used -f, --fast-retrieval Created deals should enable the fast retrieval feature (default true) -h, --help help for set-default-config -p, --max-price uint Maximum price that will be spent per RepFactor in AttoFIL/GiB per Epoch -r, --rep-factor int Target number of active deals (default 1) -i, --stdin Set config from stdin JSON -t, --trusted-miners strings Miner addresses that must be used -v, --verified-deal Deal is originating from a verified client with DataCap SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive set-default-config"},{"location":"hub/cli/hub_buck_archive_set-default-config/#hub-buck-archive-set-default-config","text":"Set the default archive storage configuration for the specified Bucket from a file, stdin, or flags. If flags are specified, this command updates the current default storage-config with the explicitely set flags. Flags that aren't explicitely set won't set the default value, and thus keep the original value in the storage-config. If a file or stdin is used, the storage-config will be completely overriden by the provided one. hub buck archive set-default-config [(optional)file] [flags]","title":"hub buck archive set-default-config"},{"location":"hub/cli/hub_buck_archive_set-default-config/#examples","text":"hub buck archive set-default-config --rep-factor=3 --fast-retrieval --verified-deal --trusted-miners=f08240,f023467,f09848","title":"Examples"},{"location":"hub/cli/hub_buck_archive_set-default-config/#options","text":"-c, --country-codes strings Select miners with specific countries -d, --deal-min-duration int Minimum duration for the deal -e, --deal-start-offset int Epochs in the future impose a deadline for deals to be on-chain -x, --excluded-miners strings Miner addresses that should not be used -f, --fast-retrieval Created deals should enable the fast retrieval feature (default true) -h, --help help for set-default-config -p, --max-price uint Maximum price that will be spent per RepFactor in AttoFIL/GiB per Epoch -r, --rep-factor int Target number of active deals (default 1) -i, --stdin Set config from stdin JSON -t, --trusted-miners strings Miner addresses that must be used -v, --verified-deal Deal is originating from a verified client with DataCap","title":"Options"},{"location":"hub/cli/hub_buck_archive_set-default-config/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_archive_watch/","text":"hub buck archive watch \u00b6 Watch the status of the most recent bucket archive. hub buck archive watch [flags] Options \u00b6 -h, --help help for watch SEE ALSO \u00b6 hub buck archive - Create a Filecoin archive","title":"hub buck archive watch"},{"location":"hub/cli/hub_buck_archive_watch/#hub-buck-archive-watch","text":"Watch the status of the most recent bucket archive. hub buck archive watch [flags]","title":"hub buck archive watch"},{"location":"hub/cli/hub_buck_archive_watch/#options","text":"-h, --help help for watch","title":"Options"},{"location":"hub/cli/hub_buck_archive_watch/#see-also","text":"hub buck archive - Create a Filecoin archive","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_cat/","text":"hub buck cat \u00b6 Cats bucket objects at path. hub buck cat [path] [flags] Options \u00b6 -h, --help help for cat SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Cat"},{"location":"hub/cli/hub_buck_cat/#hub-buck-cat","text":"Cats bucket objects at path. hub buck cat [path] [flags]","title":"hub buck cat"},{"location":"hub/cli/hub_buck_cat/#options","text":"-h, --help help for cat","title":"Options"},{"location":"hub/cli/hub_buck_cat/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_decrypt/","text":"hub buck decrypt \u00b6 Decrypts bucket objects at path with the given password and writes to stdout. hub buck decrypt [path] [password] [flags] Options \u00b6 -h, --help help for decrypt -p, --password string Decryption password SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Decrypt"},{"location":"hub/cli/hub_buck_decrypt/#hub-buck-decrypt","text":"Decrypts bucket objects at path with the given password and writes to stdout. hub buck decrypt [path] [password] [flags]","title":"hub buck decrypt"},{"location":"hub/cli/hub_buck_decrypt/#options","text":"-h, --help help for decrypt -p, --password string Decryption password","title":"Options"},{"location":"hub/cli/hub_buck_decrypt/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_destroy/","text":"hub buck destroy \u00b6 Destroys the bucket and all objects. hub buck destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Destroy"},{"location":"hub/cli/hub_buck_destroy/#hub-buck-destroy","text":"Destroys the bucket and all objects. hub buck destroy [flags]","title":"hub buck destroy"},{"location":"hub/cli/hub_buck_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_buck_destroy/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_encrypt/","text":"hub buck encrypt \u00b6 Encrypts file with a password (WARNING: Password is not recoverable). hub buck encrypt [file] [password] [flags] Options \u00b6 -h, --help help for encrypt -p, --password string Encryption password SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Encrypt"},{"location":"hub/cli/hub_buck_encrypt/#hub-buck-encrypt","text":"Encrypts file with a password (WARNING: Password is not recoverable). hub buck encrypt [file] [password] [flags]","title":"hub buck encrypt"},{"location":"hub/cli/hub_buck_encrypt/#options","text":"-h, --help help for encrypt -p, --password string Encryption password","title":"Options"},{"location":"hub/cli/hub_buck_encrypt/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_existing/","text":"hub buck existing \u00b6 Lists all buckets. hub buck existing [flags] Options \u00b6 -h, --help help for existing SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Existing"},{"location":"hub/cli/hub_buck_existing/#hub-buck-existing","text":"Lists all buckets. hub buck existing [flags]","title":"hub buck existing"},{"location":"hub/cli/hub_buck_existing/#options","text":"-h, --help help for existing","title":"Options"},{"location":"hub/cli/hub_buck_existing/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_get/","text":"hub buck get \u00b6 Gets bucket metadata. hub buck get [flags] Options \u00b6 -h, --help help for get SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Get"},{"location":"hub/cli/hub_buck_get/#hub-buck-get","text":"Gets bucket metadata. hub buck get [flags]","title":"hub buck get"},{"location":"hub/cli/hub_buck_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"hub/cli/hub_buck_get/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_init/","text":"hub buck init \u00b6 Initializes a new or existing bucket. A .textile config directory and a seed file will be created in the current working directory. Existing configs will not be overwritten. Use the '--existing' flag to interactively select an existing remote bucket. Use the '--cid' flag to initialize from an existing UnixFS DAG. Use the '--unfreeze' flag to retrieve '--cid' from known or imported deals. By default, if the remote bucket exists, remote objects are pulled and merged with local changes. Use the '--soft' flag to accept all local changes, including deletions. Use the '--hard' flag to discard all local changes. hub buck init [flags] Options \u00b6 --cid string Bootstrap the bucket with a UnixFS Cid from the IPFS network -e, --existing Interactively select an existing remote bucket if true --hard Discards all local changes if true -h, --help help for init -n, --name string Bucket name -p, --private Obfuscates files and folders with encryption -q, --quiet Write minimal output --soft Accepts all local changes, including deletions, if true -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Init"},{"location":"hub/cli/hub_buck_init/#hub-buck-init","text":"Initializes a new or existing bucket. A .textile config directory and a seed file will be created in the current working directory. Existing configs will not be overwritten. Use the '--existing' flag to interactively select an existing remote bucket. Use the '--cid' flag to initialize from an existing UnixFS DAG. Use the '--unfreeze' flag to retrieve '--cid' from known or imported deals. By default, if the remote bucket exists, remote objects are pulled and merged with local changes. Use the '--soft' flag to accept all local changes, including deletions. Use the '--hard' flag to discard all local changes. hub buck init [flags]","title":"hub buck init"},{"location":"hub/cli/hub_buck_init/#options","text":"--cid string Bootstrap the bucket with a UnixFS Cid from the IPFS network -e, --existing Interactively select an existing remote bucket if true --hard Discards all local changes if true -h, --help help for init -n, --name string Bucket name -p, --private Obfuscates files and folders with encryption -q, --quiet Write minimal output --soft Accepts all local changes, including deletions, if true -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_init/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_links/","text":"hub buck links \u00b6 Displays a thread, IPNS, and website link to a bucket object. Omit path to display the top-level links. hub buck links [path] [flags] Options \u00b6 --format string Display URL links in the provided format. Options: [default,json] (default \"default\") -h, --help help for links SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Links"},{"location":"hub/cli/hub_buck_links/#hub-buck-links","text":"Displays a thread, IPNS, and website link to a bucket object. Omit path to display the top-level links. hub buck links [path] [flags]","title":"hub buck links"},{"location":"hub/cli/hub_buck_links/#options","text":"--format string Display URL links in the provided format. Options: [default,json] (default \"default\") -h, --help help for links","title":"Options"},{"location":"hub/cli/hub_buck_links/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_ls/","text":"hub buck ls \u00b6 Lists top-level or nested bucket objects. hub buck ls [path] [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Ls"},{"location":"hub/cli/hub_buck_ls/#hub-buck-ls","text":"Lists top-level or nested bucket objects. hub buck ls [path] [flags]","title":"hub buck ls"},{"location":"hub/cli/hub_buck_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_buck_ls/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_pull/","text":"hub buck pull \u00b6 Pulls paths that have been added to and paths that have been removed or differ from the remote bucket root. Use the '--hard' flag to discard all local changes. Use the '--force' flag to pull all remote objects, even if they already exist locally. hub buck pull [flags] Options \u00b6 -f, --force Force pull all remote files if true --hard Discards local changes if true -h, --help help for pull -q, --quiet Write minimal output -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Pull"},{"location":"hub/cli/hub_buck_pull/#hub-buck-pull","text":"Pulls paths that have been added to and paths that have been removed or differ from the remote bucket root. Use the '--hard' flag to discard all local changes. Use the '--force' flag to pull all remote objects, even if they already exist locally. hub buck pull [flags]","title":"hub buck pull"},{"location":"hub/cli/hub_buck_pull/#options","text":"-f, --force Force pull all remote files if true --hard Discards local changes if true -h, --help help for pull -q, --quiet Write minimal output -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_pull/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_push/","text":"hub buck push \u00b6 Pushes paths that have been added to and paths that have been removed or differ from the local bucket root. Use the '--force' flag to allow a non-fast-forward update. hub buck push [flags] Options \u00b6 -f, --force Allows non-fast-forward updates if true -h, --help help for push -q, --quiet Write minimal output -y, --yes Skips the confirmation prompt if true SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Push"},{"location":"hub/cli/hub_buck_push/#hub-buck-push","text":"Pushes paths that have been added to and paths that have been removed or differ from the local bucket root. Use the '--force' flag to allow a non-fast-forward update. hub buck push [flags]","title":"hub buck push"},{"location":"hub/cli/hub_buck_push/#options","text":"-f, --force Allows non-fast-forward updates if true -h, --help help for push -q, --quiet Write minimal output -y, --yes Skips the confirmation prompt if true","title":"Options"},{"location":"hub/cli/hub_buck_push/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_roles/","text":"hub buck roles \u00b6 Manages remote bucket object access roles. Options \u00b6 -h, --help help for roles SEE ALSO \u00b6 hub buck - Manage an object storage bucket hub buck roles grant - Grant remote object access roles hub buck roles ls - List top-level or nested bucket object access roles","title":"hub buck roles"},{"location":"hub/cli/hub_buck_roles/#hub-buck-roles","text":"Manages remote bucket object access roles.","title":"hub buck roles"},{"location":"hub/cli/hub_buck_roles/#options","text":"-h, --help help for roles","title":"Options"},{"location":"hub/cli/hub_buck_roles/#see-also","text":"hub buck - Manage an object storage bucket hub buck roles grant - Grant remote object access roles hub buck roles ls - List top-level or nested bucket object access roles","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_roles_grant/","text":"hub buck roles grant \u00b6 Grants remote object access roles to an identity. Identity must be a multibase encoded public key. A \"*\" value will set the default access role for an object. Access roles: \"none\": Revokes all access. \"reader\": Grants read-only access. \"writer\": Grants read and write access. \"admin\": Grants read, write, delete and role editing access. hub buck roles grant [identity] [path] [flags] Options \u00b6 -h, --help help for grant -r, --role string Access role: none, reader, writer, admin SEE ALSO \u00b6 hub buck roles - Object access role management","title":"hub buck roles grant"},{"location":"hub/cli/hub_buck_roles_grant/#hub-buck-roles-grant","text":"Grants remote object access roles to an identity. Identity must be a multibase encoded public key. A \"*\" value will set the default access role for an object. Access roles: \"none\": Revokes all access. \"reader\": Grants read-only access. \"writer\": Grants read and write access. \"admin\": Grants read, write, delete and role editing access. hub buck roles grant [identity] [path] [flags]","title":"hub buck roles grant"},{"location":"hub/cli/hub_buck_roles_grant/#options","text":"-h, --help help for grant -r, --role string Access role: none, reader, writer, admin","title":"Options"},{"location":"hub/cli/hub_buck_roles_grant/#see-also","text":"hub buck roles - Object access role management","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_roles_ls/","text":"hub buck roles ls \u00b6 Lists top-level or nested bucket object access roles. hub buck roles ls [path] [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub buck roles - Object access role management","title":"hub buck roles ls"},{"location":"hub/cli/hub_buck_roles_ls/#hub-buck-roles-ls","text":"Lists top-level or nested bucket object access roles. hub buck roles ls [path] [flags]","title":"hub buck roles ls"},{"location":"hub/cli/hub_buck_roles_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_buck_roles_ls/#see-also","text":"hub buck roles - Object access role management","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_root/","text":"hub buck root \u00b6 Shows the local and remote bucket root CIDs (these will differ if the bucket is encrypted). hub buck root [flags] Options \u00b6 -h, --help help for root SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Root"},{"location":"hub/cli/hub_buck_root/#hub-buck-root","text":"Shows the local and remote bucket root CIDs (these will differ if the bucket is encrypted). hub buck root [flags]","title":"hub buck root"},{"location":"hub/cli/hub_buck_root/#options","text":"-h, --help help for root","title":"Options"},{"location":"hub/cli/hub_buck_root/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_status/","text":"hub buck status \u00b6 Displays paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck status [flags] Options \u00b6 -h, --help help for status SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Status"},{"location":"hub/cli/hub_buck_status/#hub-buck-status","text":"Displays paths that have been added to and paths that have been removed or differ from the local bucket root. hub buck status [flags]","title":"hub buck status"},{"location":"hub/cli/hub_buck_status/#options","text":"-h, --help help for status","title":"Options"},{"location":"hub/cli/hub_buck_status/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_buck_watch/","text":"hub buck watch \u00b6 Watch auto-pushes local changes to the remote. hub buck watch [flags] Options \u00b6 -h, --help help for watch SEE ALSO \u00b6 hub buck - Manage an object storage bucket","title":"Watch"},{"location":"hub/cli/hub_buck_watch/#hub-buck-watch","text":"Watch auto-pushes local changes to the remote. hub buck watch [flags]","title":"hub buck watch"},{"location":"hub/cli/hub_buck_watch/#options","text":"-h, --help help for watch","title":"Options"},{"location":"hub/cli/hub_buck_watch/#see-also","text":"hub buck - Manage an object storage bucket","title":"SEE ALSO"},{"location":"hub/cli/hub_destroy/","text":"hub destroy \u00b6 Destroys your Hub account and all associated data. hub destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub - Hub Client","title":"hub destroy"},{"location":"hub/cli/hub_destroy/#hub-destroy","text":"Destroys your Hub account and all associated data. hub destroy [flags]","title":"hub destroy"},{"location":"hub/cli/hub_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_destroy/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_fil/","text":"hub fil \u00b6 Interact with Filecoin related commands. Options \u00b6 -h, --help help for fil SEE ALSO \u00b6 hub - Hub Client hub fil addrs - List Filecoin wallet addresses associated with the current account or org hub fil balance - Display the FIL balance of a wallet address hub fil index - Interact with the Miner Index. hub fil info - Get information about the current storage state of a cid hub fil retrievals - List Filecoin retrieval deal records associated with the current account or org hub fil sign - Signs a message with user wallet addresses. hub fil storage - List Filecoin storage deal records associated with the current account or org hub fil verify - Verifies the signature of a message signed with a user wallet address.","title":"Powergate"},{"location":"hub/cli/hub_fil/#hub-fil","text":"Interact with Filecoin related commands.","title":"hub fil"},{"location":"hub/cli/hub_fil/#options","text":"-h, --help help for fil","title":"Options"},{"location":"hub/cli/hub_fil/#see-also","text":"hub - Hub Client hub fil addrs - List Filecoin wallet addresses associated with the current account or org hub fil balance - Display the FIL balance of a wallet address hub fil index - Interact with the Miner Index. hub fil info - Get information about the current storage state of a cid hub fil retrievals - List Filecoin retrieval deal records associated with the current account or org hub fil sign - Signs a message with user wallet addresses. hub fil storage - List Filecoin storage deal records associated with the current account or org hub fil verify - Verifies the signature of a message signed with a user wallet address.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_addrs/","text":"hub fil addrs \u00b6 List Filecoin wallet addresses associated with the current account or org. hub fil addrs [flags] Options \u00b6 -h, --help help for addrs SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil addrs"},{"location":"hub/cli/hub_fil_addrs/#hub-fil-addrs","text":"List Filecoin wallet addresses associated with the current account or org. hub fil addrs [flags]","title":"hub fil addrs"},{"location":"hub/cli/hub_fil_addrs/#options","text":"-h, --help help for addrs","title":"Options"},{"location":"hub/cli/hub_fil_addrs/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_balance/","text":"hub fil balance \u00b6 Display the FIL balance of a wallet address. hub fil balance [addr] [flags] Options \u00b6 -h, --help help for balance SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil balance"},{"location":"hub/cli/hub_fil_balance/#hub-fil-balance","text":"Display the FIL balance of a wallet address. hub fil balance [addr] [flags]","title":"hub fil balance"},{"location":"hub/cli/hub_fil_balance/#options","text":"-h, --help help for balance","title":"Options"},{"location":"hub/cli/hub_fil_balance/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_index/","text":"hub fil index \u00b6 Interact with the Miner Index. Options \u00b6 -h, --help help for index SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands. hub fil index calculate - Calculate deal prices for a list of miners. hub fil index get - Get miner information hub fil index query - Query miners in the index","title":"hub fil index"},{"location":"hub/cli/hub_fil_index/#hub-fil-index","text":"Interact with the Miner Index.","title":"hub fil index"},{"location":"hub/cli/hub_fil_index/#options","text":"-h, --help help for index","title":"Options"},{"location":"hub/cli/hub_fil_index/#see-also","text":"hub fil - Interact with Filecoin related commands. hub fil index calculate - Calculate deal prices for a list of miners. hub fil index get - Get miner information hub fil index query - Query miners in the index","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_index_calculate/","text":"hub fil index calculate \u00b6 Calculate deal prices for a list of miners. hub fil index calculate [dataSizeBytes] [durationDays] [minerAddr...] [flags] Options \u00b6 -h, --help help for calculate SEE ALSO \u00b6 hub fil index - Interact with the Miner Index.","title":"hub fil index calculate"},{"location":"hub/cli/hub_fil_index_calculate/#hub-fil-index-calculate","text":"Calculate deal prices for a list of miners. hub fil index calculate [dataSizeBytes] [durationDays] [minerAddr...] [flags]","title":"hub fil index calculate"},{"location":"hub/cli/hub_fil_index_calculate/#options","text":"-h, --help help for calculate","title":"Options"},{"location":"hub/cli/hub_fil_index_calculate/#see-also","text":"hub fil index - Interact with the Miner Index.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_index_get/","text":"hub fil index get \u00b6 Get miner information hub fil index get [minerAddr] [flags] Options \u00b6 -h, --help help for get --json indicates that output should be printed in JSON SEE ALSO \u00b6 hub fil index - Interact with the Miner Index.","title":"hub fil index get"},{"location":"hub/cli/hub_fil_index_get/#hub-fil-index-get","text":"Get miner information hub fil index get [minerAddr] [flags]","title":"hub fil index get"},{"location":"hub/cli/hub_fil_index_get/#options","text":"-h, --help help for get --json indicates that output should be printed in JSON","title":"Options"},{"location":"hub/cli/hub_fil_index_get/#see-also","text":"hub fil index - Interact with the Miner Index.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_index_query/","text":"hub fil index query \u00b6 Query miners in the index. The API allows to handle paging with filters and sorting. The sort-field flag can take the following values: - \"textile-deals-total-successful\": Total successful deals in Textile. - \"textile-deals-last-successful\": Last successful deal in Textile. - \"ask-price\": Raw ask-price. - \"verified-ask-price\": Verified ask-price. - \"active-sectors\": Total active sectors in the network. The default sorting field is \"textile-deals-last-successful\". The sort-textile-region allows to apply textile-deals-* flags to a specific textile region. An empty value would be interpreted to the aggregate of all regions (default). If the flag --show-full-details is set, an extra set of columns with more details is printed. If the flag --json is set, the output will be printed in JSON and it always contains full details. hub fil index query [flags] Options \u00b6 --ascending sort results ascending, default is sort descending --filter-miner-location string filter by miner's location -h, --help help for query --json indicates that the output should be printed in JSON --limit int maximum results per page (default 10) --offset int number of results to skip --show-full-details indicates that the results will contain extended data about miners --sort-field string sort field (default \"textile-deals-last-successful\") --sort-textile-region string make the sorting criteria in a specified region SEE ALSO \u00b6 hub fil index - Interact with the Miner Index.","title":"hub fil index query"},{"location":"hub/cli/hub_fil_index_query/#hub-fil-index-query","text":"Query miners in the index. The API allows to handle paging with filters and sorting. The sort-field flag can take the following values: - \"textile-deals-total-successful\": Total successful deals in Textile. - \"textile-deals-last-successful\": Last successful deal in Textile. - \"ask-price\": Raw ask-price. - \"verified-ask-price\": Verified ask-price. - \"active-sectors\": Total active sectors in the network. The default sorting field is \"textile-deals-last-successful\". The sort-textile-region allows to apply textile-deals-* flags to a specific textile region. An empty value would be interpreted to the aggregate of all regions (default). If the flag --show-full-details is set, an extra set of columns with more details is printed. If the flag --json is set, the output will be printed in JSON and it always contains full details. hub fil index query [flags]","title":"hub fil index query"},{"location":"hub/cli/hub_fil_index_query/#options","text":"--ascending sort results ascending, default is sort descending --filter-miner-location string filter by miner's location -h, --help help for query --json indicates that the output should be printed in JSON --limit int maximum results per page (default 10) --offset int number of results to skip --show-full-details indicates that the results will contain extended data about miners --sort-field string sort field (default \"textile-deals-last-successful\") --sort-textile-region string make the sorting criteria in a specified region","title":"Options"},{"location":"hub/cli/hub_fil_index_query/#see-also","text":"hub fil index - Interact with the Miner Index.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_info/","text":"hub fil info \u00b6 Get information about the current storage state of a cid hub fil info cid [flags] Options \u00b6 -h, --help help for info SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil info"},{"location":"hub/cli/hub_fil_info/#hub-fil-info","text":"Get information about the current storage state of a cid hub fil info cid [flags]","title":"hub fil info"},{"location":"hub/cli/hub_fil_info/#options","text":"-h, --help help for info","title":"Options"},{"location":"hub/cli/hub_fil_info/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_retrievals/","text":"hub fil retrievals \u00b6 List Filecoin retrieval deal records associated with the current account or org. hub fil retrievals [flags] Options \u00b6 --addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for retrievals SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil retrievals"},{"location":"hub/cli/hub_fil_retrievals/#hub-fil-retrievals","text":"List Filecoin retrieval deal records associated with the current account or org. hub fil retrievals [flags]","title":"hub fil retrievals"},{"location":"hub/cli/hub_fil_retrievals/#options","text":"--addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for retrievals","title":"Options"},{"location":"hub/cli/hub_fil_retrievals/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_sign/","text":"hub fil sign \u00b6 Signs a message using all wallet addresses associated with the user hub fil sign [hex-encoded-message] [flags] Options \u00b6 -h, --help help for sign SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil sign"},{"location":"hub/cli/hub_fil_sign/#hub-fil-sign","text":"Signs a message using all wallet addresses associated with the user hub fil sign [hex-encoded-message] [flags]","title":"hub fil sign"},{"location":"hub/cli/hub_fil_sign/#options","text":"-h, --help help for sign","title":"Options"},{"location":"hub/cli/hub_fil_sign/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_storage/","text":"hub fil storage \u00b6 List Filecoin storage deal records associated with the current account or org. hub fil storage [flags] Options \u00b6 --addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for storage -f, --include-final include final deals (default true) -p, --include-pending include pending deals SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil storage"},{"location":"hub/cli/hub_fil_storage/#hub-fil-storage","text":"List Filecoin storage deal records associated with the current account or org. hub fil storage [flags]","title":"hub fil storage"},{"location":"hub/cli/hub_fil_storage/#options","text":"--addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for storage -f, --include-final include final deals (default true) -p, --include-pending include pending deals","title":"Options"},{"location":"hub/cli/hub_fil_storage/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_fil_verify/","text":"hub fil verify \u00b6 Verifies the signature of a message signed with a user wallet address. hub fil verify [addr] [hex-encoded-message] [hex-encoded-signature] [flags] Options \u00b6 -h, --help help for verify SEE ALSO \u00b6 hub fil - Interact with Filecoin related commands.","title":"hub fil verify"},{"location":"hub/cli/hub_fil_verify/#hub-fil-verify","text":"Verifies the signature of a message signed with a user wallet address. hub fil verify [addr] [hex-encoded-message] [hex-encoded-signature] [flags]","title":"hub fil verify"},{"location":"hub/cli/hub_fil_verify/#options","text":"-h, --help help for verify","title":"Options"},{"location":"hub/cli/hub_fil_verify/#see-also","text":"hub fil - Interact with Filecoin related commands.","title":"SEE ALSO"},{"location":"hub/cli/hub_init/","text":"hub init \u00b6 Initializes a new Hub account. hub init [flags] Options \u00b6 -h, --help help for init SEE ALSO \u00b6 hub - Hub Client","title":"hub init"},{"location":"hub/cli/hub_init/#hub-init","text":"Initializes a new Hub account. hub init [flags]","title":"hub init"},{"location":"hub/cli/hub_init/#options","text":"-h, --help help for init","title":"Options"},{"location":"hub/cli/hub_init/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_keys/","text":"hub keys \u00b6 Manages your API keys. Options \u00b6 -h, --help help for keys SEE ALSO \u00b6 hub - Hub Client hub keys create - Create an API key and secret hub keys invalidate - Invalidate an API key hub keys ls - List your API keys","title":"API Keys"},{"location":"hub/cli/hub_keys/#hub-keys","text":"Manages your API keys.","title":"hub keys"},{"location":"hub/cli/hub_keys/#options","text":"-h, --help help for keys","title":"Options"},{"location":"hub/cli/hub_keys/#see-also","text":"hub - Hub Client hub keys create - Create an API key and secret hub keys invalidate - Invalidate an API key hub keys ls - List your API keys","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_create/","text":"hub keys create \u00b6 Creates a new API key and secret. Keys are used by apps and services that leverage buckets or threads. Using the '--org' flag will create a new key under the Organization's account. There are two types of API keys: 'Account' keys provide direct access to developer/org account buckets and threads. 'User Group' keys provide existing non-admin identities (e.g. app users) access to their own buckets and threads, using the resources of the parent account (i.e. the developer or organization). API secrets are used for Signature Authentication, which is a security measure that can prevent outsiders from using your API key. API secrets should be kept safely on a backend server, not in publicly readable client code. However, for development purposes, you may opt-out of Signature Authentication during key creation. hub keys create [flags] Options \u00b6 -h, --help help for create SEE ALSO \u00b6 hub keys - API key management","title":"hub keys create"},{"location":"hub/cli/hub_keys_create/#hub-keys-create","text":"Creates a new API key and secret. Keys are used by apps and services that leverage buckets or threads. Using the '--org' flag will create a new key under the Organization's account. There are two types of API keys: 'Account' keys provide direct access to developer/org account buckets and threads. 'User Group' keys provide existing non-admin identities (e.g. app users) access to their own buckets and threads, using the resources of the parent account (i.e. the developer or organization). API secrets are used for Signature Authentication, which is a security measure that can prevent outsiders from using your API key. API secrets should be kept safely on a backend server, not in publicly readable client code. However, for development purposes, you may opt-out of Signature Authentication during key creation. hub keys create [flags]","title":"hub keys create"},{"location":"hub/cli/hub_keys_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"hub/cli/hub_keys_create/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_invalidate/","text":"hub keys invalidate \u00b6 Invalidates an API key. Invalidated keys cannot be used to create new threads. hub keys invalidate [flags] Options \u00b6 -h, --help help for invalidate SEE ALSO \u00b6 hub keys - API key management","title":"hub keys invalidate"},{"location":"hub/cli/hub_keys_invalidate/#hub-keys-invalidate","text":"Invalidates an API key. Invalidated keys cannot be used to create new threads. hub keys invalidate [flags]","title":"hub keys invalidate"},{"location":"hub/cli/hub_keys_invalidate/#options","text":"-h, --help help for invalidate","title":"Options"},{"location":"hub/cli/hub_keys_invalidate/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_keys_ls/","text":"hub keys ls \u00b6 Lists all of your API keys. hub keys ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub keys - API key management","title":"hub keys ls"},{"location":"hub/cli/hub_keys_ls/#hub-keys-ls","text":"Lists all of your API keys. hub keys ls [flags]","title":"hub keys ls"},{"location":"hub/cli/hub_keys_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_keys_ls/#see-also","text":"hub keys - API key management","title":"SEE ALSO"},{"location":"hub/cli/hub_login/","text":"hub login \u00b6 Handles login to a Hub account. hub login [flags] Options \u00b6 -h, --help help for login SEE ALSO \u00b6 hub - Hub Client","title":"Login"},{"location":"hub/cli/hub_login/#hub-login","text":"Handles login to a Hub account. hub login [flags]","title":"hub login"},{"location":"hub/cli/hub_login/#options","text":"-h, --help help for login","title":"Options"},{"location":"hub/cli/hub_login/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_logout/","text":"hub logout \u00b6 Handles logout of a Hub account. hub logout [flags] Options \u00b6 -h, --help help for logout SEE ALSO \u00b6 hub - Hub Client","title":"Logout"},{"location":"hub/cli/hub_logout/#hub-logout","text":"Handles logout of a Hub account. hub logout [flags]","title":"hub logout"},{"location":"hub/cli/hub_logout/#options","text":"-h, --help help for logout","title":"Options"},{"location":"hub/cli/hub_logout/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs/","text":"hub orgs \u00b6 Manages your organizations. Options \u00b6 -h, --help help for orgs SEE ALSO \u00b6 hub - Hub Client hub orgs create - Create an org hub orgs destroy - Destroy an org hub orgs invite - Invite members to an org hub orgs leave - Leave an org hub orgs ls - List orgs you're a member of hub orgs members - List org members","title":"Orgs"},{"location":"hub/cli/hub_orgs/#hub-orgs","text":"Manages your organizations.","title":"hub orgs"},{"location":"hub/cli/hub_orgs/#options","text":"-h, --help help for orgs","title":"Options"},{"location":"hub/cli/hub_orgs/#see-also","text":"hub - Hub Client hub orgs create - Create an org hub orgs destroy - Destroy an org hub orgs invite - Invite members to an org hub orgs leave - Leave an org hub orgs ls - List orgs you're a member of hub orgs members - List org members","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_create/","text":"hub orgs create \u00b6 Creates a new organization. hub orgs create [flags] Options \u00b6 -h, --help help for create SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs create"},{"location":"hub/cli/hub_orgs_create/#hub-orgs-create","text":"Creates a new organization. hub orgs create [flags]","title":"hub orgs create"},{"location":"hub/cli/hub_orgs_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"hub/cli/hub_orgs_create/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_destroy/","text":"hub orgs destroy \u00b6 Destroys an organization and all associated data. You must be the org owner. hub orgs destroy [flags] Options \u00b6 -h, --help help for destroy SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs destroy"},{"location":"hub/cli/hub_orgs_destroy/#hub-orgs-destroy","text":"Destroys an organization and all associated data. You must be the org owner. hub orgs destroy [flags]","title":"hub orgs destroy"},{"location":"hub/cli/hub_orgs_destroy/#options","text":"-h, --help help for destroy","title":"Options"},{"location":"hub/cli/hub_orgs_destroy/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_invite/","text":"hub orgs invite \u00b6 Invites a new member to an organization. hub orgs invite [flags] Options \u00b6 -h, --help help for invite SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs invite"},{"location":"hub/cli/hub_orgs_invite/#hub-orgs-invite","text":"Invites a new member to an organization. hub orgs invite [flags]","title":"hub orgs invite"},{"location":"hub/cli/hub_orgs_invite/#options","text":"-h, --help help for invite","title":"Options"},{"location":"hub/cli/hub_orgs_invite/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_leave/","text":"hub orgs leave \u00b6 Leaves an organization. hub orgs leave [flags] Options \u00b6 -h, --help help for leave SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs leave"},{"location":"hub/cli/hub_orgs_leave/#hub-orgs-leave","text":"Leaves an organization. hub orgs leave [flags]","title":"hub orgs leave"},{"location":"hub/cli/hub_orgs_leave/#options","text":"-h, --help help for leave","title":"Options"},{"location":"hub/cli/hub_orgs_leave/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_ls/","text":"hub orgs ls \u00b6 Lists all the organizations that you're a member of. hub orgs ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs ls"},{"location":"hub/cli/hub_orgs_ls/#hub-orgs-ls","text":"Lists all the organizations that you're a member of. hub orgs ls [flags]","title":"hub orgs ls"},{"location":"hub/cli/hub_orgs_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_orgs_ls/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_orgs_members/","text":"hub orgs members \u00b6 Lists current organization members. hub orgs members [flags] Options \u00b6 -h, --help help for members SEE ALSO \u00b6 hub orgs - Org management","title":"hub orgs members"},{"location":"hub/cli/hub_orgs_members/#hub-orgs-members","text":"Lists current organization members. hub orgs members [flags]","title":"hub orgs members"},{"location":"hub/cli/hub_orgs_members/#options","text":"-h, --help help for members","title":"Options"},{"location":"hub/cli/hub_orgs_members/#see-also","text":"hub orgs - Org management","title":"SEE ALSO"},{"location":"hub/cli/hub_threads/","text":"hub threads \u00b6 Manages your threads. Options \u00b6 -h, --help help for threads SEE ALSO \u00b6 hub - Hub Client hub threads ls - List your threads","title":"ThreadDB"},{"location":"hub/cli/hub_threads/#hub-threads","text":"Manages your threads.","title":"hub threads"},{"location":"hub/cli/hub_threads/#options","text":"-h, --help help for threads","title":"Options"},{"location":"hub/cli/hub_threads/#see-also","text":"hub - Hub Client hub threads ls - List your threads","title":"SEE ALSO"},{"location":"hub/cli/hub_threads_ls/","text":"hub threads ls \u00b6 Lists all of your threads. hub threads ls [flags] Options \u00b6 -h, --help help for ls SEE ALSO \u00b6 hub threads - Thread management","title":"hub threads ls"},{"location":"hub/cli/hub_threads_ls/#hub-threads-ls","text":"Lists all of your threads. hub threads ls [flags]","title":"hub threads ls"},{"location":"hub/cli/hub_threads_ls/#options","text":"-h, --help help for ls","title":"Options"},{"location":"hub/cli/hub_threads_ls/#see-also","text":"hub threads - Thread management","title":"SEE ALSO"},{"location":"hub/cli/hub_update/","text":"hub update \u00b6 Update the installed hub CLI version to latest release. hub update [flags] Options \u00b6 -h, --help help for update SEE ALSO \u00b6 hub - Hub Client","title":"Update"},{"location":"hub/cli/hub_update/#hub-update","text":"Update the installed hub CLI version to latest release. hub update [flags]","title":"hub update"},{"location":"hub/cli/hub_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"hub/cli/hub_update/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_version/","text":"hub version \u00b6 Shows the installed CLI version. hub version [flags] Options \u00b6 -h, --help help for version SEE ALSO \u00b6 hub - Hub Client","title":"Version"},{"location":"hub/cli/hub_version/#hub-version","text":"Shows the installed CLI version. hub version [flags]","title":"hub version"},{"location":"hub/cli/hub_version/#options","text":"-h, --help help for version","title":"Options"},{"location":"hub/cli/hub_version/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"hub/cli/hub_whoami/","text":"hub whoami \u00b6 Shows the user for the current session. hub whoami [flags] Options \u00b6 -h, --help help for whoami SEE ALSO \u00b6 hub - Hub Client","title":"Whoami"},{"location":"hub/cli/hub_whoami/#hub-whoami","text":"Shows the user for the current session. hub whoami [flags]","title":"hub whoami"},{"location":"hub/cli/hub_whoami/#options","text":"-h, --help help for whoami","title":"Options"},{"location":"hub/cli/hub_whoami/#see-also","text":"hub - Hub Client","title":"SEE ALSO"},{"location":"policies/code-of-conduct/","text":"Our Pledge \u00b6 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00b6 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00b6 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00b6 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at contact@textile.io . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/\u00bc","title":"Code of conduct"},{"location":"policies/code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"policies/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"policies/code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"policies/code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"policies/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at contact@textile.io . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"policies/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/\u00bc","title":"Attribution"},{"location":"policies/license/","text":"Unless otherwise explicitly stated, all Textile code and software products are licensed under the following license: MIT License \u00b6 Copyright \u00a9 2018, 2019 Textile Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"policies/license/#mit-license","text":"Copyright \u00a9 2018, 2019 Textile Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"policies/privacy/","text":"Textile provides exchange and storage of data. Textile provides remote data storage for users on the IPFS network (see https://ipfs.io/ ). The IPFS protocol has no mechanisms for deletion of data hosted on multiple providers on the network. When a Textile user 'deletes' data, we will remove that data from all servers in the IPFS network run by Textile. Information We Have \u00b6 Certain information (e.g. a user email, public keys, encrypted data content address, decrypted data, etc.) are transmitted to us solely for the purpose of transmitting and storing data. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose. Information we store The identifier you register with. The email contact address of any developer you invite to an organization. Encrypted or decrypted contents of ThreadDB. Encrypted or decrypted contents of Buckets. Transient information IP addresses may be kept for up to 90 days for rate limiting and to prevent abuse. Textile is currently collecting performance metrics and critical issues detected in our software. This data may be kept for up to a year. Information We May Share \u00b6 We do not share your information with companies, organizations, and individuals outside of Textile unless one of the following circumstances applies: With your consent. The data is encrypted and stored on IPFS hosts. When legally required. We will share the information we have with entities outside of Textile if we have a good faith belief that access, use, preservation, or disclosure of the information is necessary to: meet any applicable law, regulation, legal process or enforceable governmental request. enforce applicable Terms of Service, including investigation of potential violations. detect, prevent, or otherwise address fraud, security, or technical issues. protect against harm to the rights, property, or safety of Textile, our users, or the public as required or permitted by law. We will update this privacy policy as needed so that it is current, accurate, and as clear as possible. Please contact us with any questions at contact@textile.io Changelog \u00b6 05.04.20: Finalize TOS for new Textile Hub, Buckets, and ThreadDB services. 05.15.20: Corrected ThreadsDB => ThreadDB","title":"Privacy"},{"location":"policies/privacy/#information-we-have","text":"Certain information (e.g. a user email, public keys, encrypted data content address, decrypted data, etc.) are transmitted to us solely for the purpose of transmitting and storing data. Unless otherwise stated below, this information is only kept as long as necessary to place each call or transmit each message, and is not used for any other purpose. Information we store The identifier you register with. The email contact address of any developer you invite to an organization. Encrypted or decrypted contents of ThreadDB. Encrypted or decrypted contents of Buckets. Transient information IP addresses may be kept for up to 90 days for rate limiting and to prevent abuse. Textile is currently collecting performance metrics and critical issues detected in our software. This data may be kept for up to a year.","title":"Information We Have"},{"location":"policies/privacy/#information-we-may-share","text":"We do not share your information with companies, organizations, and individuals outside of Textile unless one of the following circumstances applies: With your consent. The data is encrypted and stored on IPFS hosts. When legally required. We will share the information we have with entities outside of Textile if we have a good faith belief that access, use, preservation, or disclosure of the information is necessary to: meet any applicable law, regulation, legal process or enforceable governmental request. enforce applicable Terms of Service, including investigation of potential violations. detect, prevent, or otherwise address fraud, security, or technical issues. protect against harm to the rights, property, or safety of Textile, our users, or the public as required or permitted by law. We will update this privacy policy as needed so that it is current, accurate, and as clear as possible. Please contact us with any questions at contact@textile.io","title":"Information We May Share"},{"location":"policies/privacy/#changelog","text":"05.04.20: Finalize TOS for new Textile Hub, Buckets, and ThreadDB services. 05.15.20: Corrected ThreadsDB => ThreadDB","title":"Changelog"},{"location":"policies/terms/","text":"Last updated: 08/24/20 Textile's Hub (\" Textile ,\" \" we ,\" \" us ,\" or \" our \") serves as a gateway to the decentralized internet by providing scalable access to the Filecoin blockchain and IPFS infrastructure. Textile hosts a website that serves as a registration portal, product offering, and dashboard of Textile services through our website located on the Textile Site, which includes text, images, audio, code, and other materials or third party information. These Terms of Use (the \" Terms ,\" \" Terms of Use \" or \" Agreement \") contain the terms and conditions that govern your access to and use of the Service Offerings (as defined below) provided by us and is an agreement between us and you or the entity you represent (\" you \" or \" your \"). Please read these Terms of Use carefully before using the Service. By clicking a button or checkbox to accept or agree to these Terms where that option is made available or, if earlier, using or otherwise accessing the Services (the \" Effective Date \"), you (1) accept and agree to these Terms and any additional terms, rules, and conditions of participation issued by Textile from time to time and (2) consent to the collection, use, disclosure and other handling of information as described in our Privacy Policy. If you do not agree to the Terms, then you may not access or use the Services. You represent to us that you are lawfully able to enter into contracts. If you are entering into this Agreement for an entity, such as the company you work for, you represent to us that you have the legal authority to bind that entity. Please see Section 16 for definitions of certain capitalized terms used in this Agreement. In addition, you represent to us that you and your financial institutions, or any party that owns or controls you or your financial institutions, are (1) not subject to sanctions or otherwise designated on any list of prohibited or restricted parties, including but not limited to the lists maintained by the United Nations Security Council, the U.S. Government (e.g., the Specially Designated Nationals List and Foreign Sanctions Evaders List of the U.S. Department of Treasury and the Entity List of the U.S. Department of Commerce), the European Union or its Member States, or other applicable government authority and (2) not located in any country to which the United States has embargoed goods or has otherwise applied any sanctions. 1. The Service Offerings. \u00b6 1.1 Generally. You may access and use the Service Offerings in accordance with this Agreement. You agree to comply with the terms of this Agreement and all laws, rules, and regulations applicable to your use of the Service Offerings. 1.2 Account; Project ID. To access the Services, you must first create a Textile with a valid email address. If you intend to select a paid plan of Service, you must also add a valid payment form. Once you have created your account and logged in to the Textile Dashboard (the \"Dashboard\") or Textile Client (the \"Client\"), you can create a new project, and your Project ID (and associated Textile API endpoint URLs) will be generated. 1.3 Third-Party Content. You may use Third-Party Content at your election. This Agreement governs third-Party Content and, if applicable, separate terms and conditions accompanying such Third-Party Content, which terms and conditions may include separate fees and charges. 2. Changes. \u00b6 2.1 To the Service Offerings. We may change or discontinue any or all of the Service Offerings or change or remove functionality of any or all of the Service Offerings from time to time. We will notify you of any material change to or discontinuation of the Service Offerings. 2.2 To the APIs. We may change or discontinue any APIs for the Services from time to time. For any discontinuation of or material change to an API for a Service, we will use commercially reasonable efforts to continue supporting the previous version of such API for three months after the change or discontinuation (except if doing so (a) would pose a security or intellectual property issue, (b) is economically or technically burdensome, or \u00a9 would cause us to violate the law or requests of governmental entities). 3. Security and Data Privacy. \u00b6 3.1 Security Risks. You acknowledge that Your Content may be stored on or using Decentralized Storage Services. You understand there may be risks to storing Your Content on or using Decentralized Storage Services, including without limitation loss of Your Content, loss of access to, or ability to manage, Your Content and dependence on third party nodes running such Decentralized Storage Services. We are not responsible for any of Your Content stored on or using Decentralized Storage Services. We will exercise no control whatsoever over Your Content and the content of the information passing through the network provided that it adheres to all other conditions set forth herein and in our Policies. 3.2 Data Privacy. You consent to the storage of Your Content in, and transfer of Your Content into, the regions we operate in, regions in which our servers are located or regions in which servers relating to Decentralized Storage Services are located. We will not access or use Your Content except as necessary to maintain or provide the Service Offerings, or as necessary to comply with the law or a binding order of a governmental body. We will not disclose Your Content to any government or third party except as necessary to comply with the law or a binding order of a governmental body. Unless it would violate the law or a binding order of a governmental body, we will give you notice of any legal requirement or order referred to in this Section (3.2). We will only use your Account Information in accordance with the Privacy Policy, and you consent to such usage. The Privacy Policy does not apply to Your Content. 3.3 Service Attributes. To provide billing and administration services, we may process Service Attributes in the region(s) where you use the Service Offerings and the regions in the United States. To provide you with support services initiated by you and investigate fraud, abuse, or violations of this Agreement, we may process Service Attributes where we maintain our support and investigation personnel. 4. Your Responsibilities. \u00b6 4.1 Your Accounts. Except to the extent caused by our breach of this Agreement, (a) you are responsible for all activities that occur under your account, regardless of whether the activities are authorized by you or undertaken by you, your employees or a third party (including your contractors, agents or End Users), and (b) we and our affiliates are not responsible for unauthorized access to your account. 4.2 Your Content. You will ensure that Your Content and your and End Users' use of Your Content or the Service Offerings will not violate any of the Policies or any applicable law. You are solely responsible for the development, content, operation, maintenance, and use of Your Content. You will bear full risk of loss and damage to Your Content. You acknowledge and agree that you are solely responsible for all acts, omissions and use under and charges incurred with your account or any of Your Content displayed, linked, transmitted through or stored on Decentralized Storage Services. You shall be solely responsible for undertaking measures to: (i) prevent any loss or damage to Your Content; (ii) maintain independent archival and backup copies of Your Content; and (iii) ensure the security, confidentiality and integrity of Your Content transmitted through our Services or stored on Decentralized Storage Services. We shall have no liability to you or any other person for loss, damage or destruction of any of Your Content. 4.3 Your Security and Backup. You are responsible for properly configuring and using the Service Offerings and otherwise taking appropriate action to secure, protect and backup your accounts and Your Content in a manner that will provide appropriate security and protection, which might include use of encryption to protect Your Content from unauthorized access and routinely archiving Your Content. 4.4 Log-In Credentials and Account Keys. To the extent we provide you with Textile log-in credentials and API authentication generated by the Services, such log-in credentials and API authentication are only for your internal use. You will not sell, transfer or sublicense them to any other entity or person, except that you may disclose your private key to your agents and subcontractors performing work on your behalf. 4.5 End Users. You will be deemed to have taken any action that you permit, assist, or facilitate any person or entity to take related to this Agreement, Your Content, or use of the Service Offerings. You are responsible for End Users' use of Your Content and the Service Offerings. You will ensure that all End Users comply with your obligations under this Agreement and that the terms of your agreement with each End User are consistent with this Agreement. If you become aware of any violation of your obligations under this Agreement caused by an End User, you will immediately suspend access to Your Content and the Service Offerings by such End User. We do not provide any support or services to End Users unless we have a separate agreement with you or an End User obligating us to provide such support or services. 5. Fees and Payment. \u00b6 5.1. Service fees. You agree to pay all fees owed for your use of the Services, as calculated by our records based on our publicly available pricing. All charges are non-refundable unless expressly prohibited by applicable law. We may charge your credit card on a recurring basis for any amounts that you owe us, some of which may require advance payments. 5.2 Late payments. Late payments may bear interest at the rate of 1.5% per month (or the highest rate permitted by law, if less) from the payment due date until paid in full. You will be responsible for all reasonable expenses (including attorneys' fees) incurred by us in collecting such delinquent amounts. 5.3 Payment fees. We are not responsible for any bank fees, interest charges, finance charges, overdraft charges, or other fees resulting from charges billed by Textile. Currency exchange settlements will be based on agreements between you and the provider of your credit card. 5.4 Taxes. Our listed fees do not include taxes, and you agree to pay all sales/use, gross receipts, value-added, GST, personal property or other tax (including any interest and penalties) with respect to the transactions and payments under these Terms, other than taxes based on our net income, employees or real property. You agree to work with us to help us obtain any necessary withholding or royalty tax exemptions where applicable. 5.5 Withholdings. Notwithstanding the foregoing, all payments made by you to us under these Terms will be made free and clear of any deduction or withholding, as may be required by law. If any such deduction or withholding (including but not limited to cross-border withholding taxes) is required on any payment, you will pay such additional amounts as are necessary so that the net amount received by us after such deduction or withholding, will be equal to the full amount that we would have received if no deduction or withholding had been required. The payment of any taxes, charges or fees required to be deducted or withheld from payments due to us, and the filing of any information or tax returns with respect thereto, shall be your responsibility. Upon your reasonable request, we will provide you with any existing tax forms in our possession that would reduce or eliminate the amount of any such withholding or deduction for taxes. 6. Temporary Suspension; Limiting API Requests. \u00b6 6.1 Generally. We may suspend your or any End User's right to access or use any portion or all of the Service Offerings immediately upon notice to you if we determine: You or an End User's use of the Service Offerings (i) poses a security risk to the Service Offerings or any third party, (ii) could adversely impact our systems, the Service Offerings or the systems or Content of any other Textile user, (iii) could subject us, our affiliates, or any third party to liability, or (iv) could be fraudulent; You are, or any End User is, in breach of this Agreement; You are in breach of your payment obligations under Section 5, and such breach continues for 30 days or longer; or You have ceased to operate in the ordinary course, made an assignment for the benefit of creditors or similar disposition of your assets, or become the subject of any bankruptcy, reorganization, liquidation, dissolution or similar proceeding. 6.2 Effect of Suspension. If we suspend your right to access or use any portion or all of the Service Offerings: You remain responsible for all fees and charges you incur during the period of suspension; and You will not be entitled to any service credits for any period of suspension. 6.3 Limiting API Requests. We retain sole discretion to limit your usage of the Services (including without limitation by limiting the number of API requests you may submit to our gateways or nodes (\"API Requests\")) at any time if your usage of the Services exceeds the applicable Threshold for your Selected Plan of Service. 7. Term; Termination. \u00b6 7.1 Term. The term of this Agreement will commence on the Effective Date and remain in effect until terminated under this Section 7. Any notice of termination of this Agreement by either party to the other must include a Termination Date that complies with the notice periods in Section 7.2. 7.2 Termination. Termination for Convenience. You may terminate this Agreement for any reason by providing us at least 30 days' written notice, after which you will close your account for all Services. We may terminate this Agreement for any reason by providing you at least 30 days' written notice. Termination for Cause. _ By Either Party. Either party may terminate this Agreement for cause if the other party is in material breach of this Agreement and the material breach remains uncured for a period of 30 days from receipt of notice by the other party. No later than the Termination Date, you will close your account. _ By Us. We may also terminate this Agreement immediately upon notice to you (A) for cause if we have the right to suspend under Section 6, (B) if our relationship with a third-party partner who provides software or other technology we use to provide the Service Offerings expires, terminates or requires us to change the way we provide the software or other technology as part of the Services, or (C) in order to comply with the law or requests of governmental entities. 7.3 Effect of Termination. Upon the Termination Date: All your rights under this Agreement immediately terminate; Each party remains responsible for all fees and charges it has incurred through the Termination Date and is responsible for any fees and charges it incurs during the post-termination period; You will immediately return or, if instructed by us, destroy all Textile Content in your possession; Sections 4.1, 5, 7.3, 8 (except the license granted to you in Section 8.3), 9, 10, 11, 13, and 15 will continue to apply in accordance with their terms. For any use of the Services after the Termination Date, the terms of this Agreement will apply and you will pay the applicable fees at the rates under Section 5. Proprietary Rights. 8.1 Your Content. Except as provided in this Section 8, we obtain no rights under this Agreement from you (or your licensors) to Your Content. You consent to our use of Your Content to provide the Service Offerings to you and any End Users. 8.2 Adequate Rights. You represent and warrant to us that: (a) you or your licensors own all right, title, and interest in and to Your Content and Suggestions; (b) you have all rights in Your Content and Suggestions necessary to grant the rights contemplated by this Agreement; and \u00a9 none of Your Content or End Users' use of Your Content or the Service Offerings will violate the Acceptable Use Policy. 8.3 Service Offerings License. We or our licensors own all right, title, and interest in and to the Service Offerings, and all related technology and intellectual property rights. Subject to the terms of this Agreement, we grant you a limited, revocable, non-exclusive, non-sublicensable, non-transferable license to do the following: (a) access and use the Services solely in accordance with this Agreement; and (b) copy and use the Textile Content solely in connection with your permitted use of the Services. Except as provided in this Section 8.3, you obtain no rights under this Agreement from us, our affiliates or our licensors to the Service Offerings, including any related intellectual property rights. Some Textile Content and Third-Party Content may be provided to you under a separate license, such as the Apache License, Version 2.0, or other open-source licenses. In the event of a conflict between this Agreement and any separate license, the separate license will prevail with respect to the Textile Content or Third-Party Content that is the subject of such a separate license. 8.4 License Restrictions. Neither you nor any End User will use the Service Offerings in any manner or for any purpose other than as expressly permitted by this Agreement. Neither you nor any End User will, or will attempt to (a) modify, distribute, alter, tamper with, repair, or otherwise create derivative works of any Content included in the Service Offerings (except to the extent Content included in the Service Offerings is provided to you under a separate license that expressly permits the creation of derivative works), (b) reverse engineer, disassemble, or decompile the Service Offerings or apply any other process or procedure to derive the source code of any software included in the Service Offerings (except to the extent applicable law doesn't allow this restriction), \u00a9 access or use the Service Offerings in a way intended to avoid incurring fees or exceeding usage limits or quotas, or (d) resell or sublicense the Service Offerings. You will not use the Textile Marks unless you obtain our prior written consent. You will not misrepresent or embellish the relationship between us and you (including by expressing or implying that we support, sponsor, endorse, or contribute to you or your business endeavors). You will not imply any relationship or affiliation between us and you except as expressly permitted by this Agreement. 8.5 Suggestions. If you provide any Suggestions to us or our affiliates, we and our affiliates will be entitled to use the Suggestions without restriction. You hereby irrevocably assign to us all right, title, and interest in and to the Suggestions and agree to provide us any assistance we require to document, perfect, and maintain our rights in the Suggestions. 9. Indemnification. \u00b6 9.1 General. You will defend, indemnify, and hold harmless us, our affiliates and licensors, and each of their respective employees, officers, directors, and representatives from and against any Losses arising out of or relating to any claim concerning: (a) your or any End Users' use of the Service Offerings (including any use by your employees and personnel); (b) breach of this Agreement or violation of applicable law by you, End Users or Your Content; or \u00a9 a dispute between you and any End User. You will reimburse us for reasonable attorneys' fees and expenses, as well as our employees' and contractors' time and materials spent responding to any subpoena or other compulsory legal order or process associated with claims described in (a) through \u00a9 above at our then-current hourly rates. We will defend, indemnify, and hold harmless you and your employees, officers, directors, and representatives from and against any Losses arising out of or relating to any claim concerning breach of this Agreement or violation of applicable law by us. We will reimburse you for reasonable attorneys' fees and expenses, as well as your employees' and contractors' time and materials spent responding to any subpoena or other compulsory legal order or process associated with claims described in this paragraph at our then-current hourly rates. 9.2 Intellectual Property. Subject to the limitations in this Section 9, you will defend Textile, its affiliates, and their respective employees, officers, and directors against any third-party claim alleging that any of Your Content infringes or misappropriates that third party's intellectual property rights, and will pay the amount of any adverse final judgment or settlement. Subject to the limitations in this Section 9, we will defend you and your employees, officers, and directors against any third-party claim alleging that the Services infringe or misappropriate that third party's intellectual property rights, and will pay the amount of any adverse final judgment or settlement. Neither party will have obligations or liability under this Section 9.2 arising from infringement by combinations of the Services or Your Content, as applicable, with any other product, service, software, data, content or method. In addition, Textile will have no obligations or liability arising from your or any End User's use of the Services after Textile has notified you to discontinue such use. The remedies provided in this Section 9.2 are the sole and exclusive remedies for any third-party claims of infringement or misappropriation of intellectual property rights by the Services or by Your Content. 9.3 Process. In no event will a party agree to any settlement of any claim that involves any commitment, other than the payment of money, without the written consent of the other party. 10. Disclaimers; Risk. \u00b6 10.1 DISCLAIMER. THE SERVICE OFFERINGS ARE PROVIDED \"AS IS.\" EXCEPT TO THE EXTENT PROHIBITED BY LAW, OR TO THE EXTENT ANY STATUTORY RIGHTS APPLY THAT CANNOT BE EXCLUDED, LIMITED OR WAIVED, WE AND OUR AFFILIATES AND LICENSORS (A) MAKE NO REPRESENTATIONS OR WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE REGARDING THE SERVICE OFFERINGS OR THE THIRD-PARTY CONTENT, AND (B) DISCLAIM ALL WARRANTIES, INCLUDING ANY IMPLIED OR EXPRESS WARRANTIES (I) OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, OR QUIET ENJOYMENT, (II) ARISING OUT OF ANY COURSE OF DEALING OR USAGE OF TRADE, (III) THAT THE SERVICE OFFERINGS OR THIRD-PARTY CONTENT WILL BE UNINTERRUPTED, ERROR FREE OR FREE OF HARMFUL COMPONENTS, AND (IV) THAT ANY CONTENT WILL BE SECURE OR NOT OTHERWISE LOST OR ALTERED. 10.2 Sophistication and Risk of Cryptographic Systems. By utilizing the Services in any way, you represent that you understand the inherent risks associated with cryptographic systems and that you have an understanding of the usage and intricacies of cryptographic tokens, and blockchain-based software systems. 10.3 Platform Security. Textile is an early-stage platform. You acknowledge that IPFS and Filecoin applications are software subject to flaws and acknowledge that you are solely responsible for evaluating any available code provided by the Services. You further expressly acknowledge and represent that IPFS and Filecoin applications can be written maliciously or negligently, that Textile cannot be held liable for your interaction with such applications and that such applications may cause loss of property or identity. These warnings and others later provided by Textile in no way evidence or represent an on-going duty to alert you to all of the potential risks of utilizing the Services. 11. Limitations of Liability. \u00b6 YOU ACKNOWLEDGE AND AGREE THAT YOU ASSUME FULL RESPONSIBILITY FOR YOUR USE OF THE TEXTILE SITE AND THE SERVICES. YOU ACKNOWLEDGE AND AGREE THAT ANY INFORMATION YOU SEND OR RECEIVE DURING YOUR USE OF THE TEXTILE SITE AND THE SERVICES MAY NOT BE SECURE AND MAY BE INTERCEPTED OR LATER ACQUIRED BY UNAUTHORIZED PARTIES. YOU ACKNOWLEDGE AND AGREE THAT YOUR USE OF THE TEXTILE SITE AND THE SERVICES IS AT YOUR OWN RISK. RECOGNIZING SUCH, YOU UNDERSTAND AND AGREE THAT, TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW AND NOTWITHSTANDING ANYTHING HEREIN TO THE CONTRARY, WE AND OUR AFFILIATES AND LICENSORS WILL NOT BE LIABLE TO YOU FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL OR EXEMPLARY DAMAGES (INCLUDING DAMAGES FOR LOSS OF PROFITS, REVENUES, CUSTOMERS, OPPORTUNITIES, GOODWILL, USE, OR DATA), EVEN IF A PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. FURTHER, NEITHER WE NOR ANY OF OUR AFFILIATES OR LICENSORS WILL BE RESPONSIBLE FOR ANY COMPENSATION, REIMBURSEMENT, OR DAMAGES ARISING IN CONNECTION WITH: (A) YOUR INABILITY TO USE THE SERVICES, INCLUDING AS A RESULT OF ANY (I) TERMINATION OR SUSPENSION OF THIS AGREEMENT OR YOUR USE OF OR ACCESS TO THE SERVICE OFFERINGS, (II) OUR DISCONTINUATION OF ANY OR ALL OF THE SERVICE OFFERINGS, OR (III) ANY UNANTICIPATED OR UNSCHEDULED DOWNTIME OF ALL OR A PORTION OF THE SERVICES FOR ANY REASON; (B) THE COST OF PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; (C) ANY INVESTMENTS, EXPENDITURES, OR COMMITMENTS BY YOU IN CONNECTION WITH THIS AGREEMENT OR YOUR USE OF OR ACCESS TO THE SERVICE OFFERINGS; (D) ANY UNAUTHORIZED ACCESS TO, ALTERATION OF, FAILURE TO ACCESS, RETRIEVE, MANAGE OR DELETE, OR THE DELETION, DESTRUCTION, DAMAGE, LOSS OR FAILURE TO STORE ANY OF YOUR CONTENT OR OTHER DATA; (E) ANY ACTIONS WE TAKE OR FAIL TO TAKE AS A RESULT OF COMMUNICATIONS YOU SEND TO US; (F) HUMAN ERRORS; (G) TECHNICAL MALFUNCTIONS; (H) FAILURES, INCLUDING PUBLIC UTILITY OR TELEPHONE OUTAGES; (I) OMISSIONS, INTERRUPTIONS, LATENCY, DELETIONS OR DEFECTS OF ANY DEVICE OR NETWORK, PROVIDERS, OR SOFTWARE (INCLUDING, BUT NOT LIMITED TO, THOSE THAT DO NOT PERMIT PARTICIPATION IN THE SERVICES); (J) ANY INJURY OR DAMAGE TO COMPUTER EQUIPMENT; (K) INABILITY TO FULLY ACCESS THE TEXTILE SITE OR THE SERVICES OR ANY OTHER WEBSITE; (L) THEFT, TAMPERING, DESTRUCTION, OR UNAUTHORIZED ACCESS TO, IMAGES OR OTHER CONTENT OF ANY KIND; (M) DATA THAT IS PROCESSED LATE OR INCORRECTLY OR IS INCOMPLETE OR LOST; (N) TYPOGRAPHICAL, PRINTING OR OTHER ERRORS, OR ANY COMBINATION THEREOF; OR (O) ANY OTHER MATTER RELATING TO THE TEXTILE SITE OR THE SERVICES. IN ADDITION, NOTWITHSTANDING ANYTHING HEREIN TO THE CONTRARY, OUR AND OUR AFFILIATES' AND LICENSORS' AGGREGATE LIABILITY UNDER THIS AGREEMENT WILL NOT EXCEED THE AMOUNT YOU ACTUALLY PAY US UNDER THIS AGREEMENT FOR THE SERVICE THAT GAVE RISE TO THE CLAIM DURING THE 12 MONTHS BEFORE THE LIABILITY AROSE. THE LIMITATIONS IN THIS SECTION 11 APPLY ONLY TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW. 12. Modifications to the Agreement. \u00b6 We reserve the right, at our sole discretion, to modify or replace any part of this Agreement (including any Policies) at any time. It is your responsibility to check this Agreement periodically for changes. Your continued use of or access to the Textile Site or the Services following the posting of any changes to this Agreement constitutes acceptance of those changes. We may also, in the future, offer new services and/or features through the Textile Site (including, the release of new tools and resources). Such new features and/or services shall be subject to the terms and conditions of this Agreement. 13. Binding Arbitration and Class Action Waiver \u00b6 PLEASE READ THIS SECTION CAREFULLY \u2013 IT MAY SIGNIFICANTLY AFFECT YOUR LEGAL RIGHTS, INCLUDING YOUR RIGHT TO FILE A LAWSUIT IN COURT. 13.1 Binding Arbitration. Any dispute, claim, or controversy (\"Claim\") relating in any way to this Agreement, the Textile Site, your use of the Service Offerings, or to any products or services sold or distributed by Textile will be resolved by binding arbitration as provided in this Section 13, rather than in court, except that you may assert claims in small claims court if your claims qualify. The Federal Arbitration Act and federal arbitration law apply to this Agreement. There is no judge or jury in arbitration, and court review of an arbitration award is limited. However, an arbitrator can award on an individual basis the same damages and relief as a court (including injunctive and declaratory relief or statutory damages) and must follow the terms of this Agreement as a court would. The arbitration will be conducted in accordance with the expedited procedures set forth in the JAMS Comprehensive Arbitration Rules and Procedures (the \"Rules\") as those Rules exist on the effective date of this Agreement, including Rules 16.1 and 16.2 of those Rules. The arbitrator's decision shall be final, binding, and non-appealable. Judgment upon the award may be entered and enforced in any court having jurisdiction. Neither party shall sue the other party other than as provided herein or for enforcement of this clause or of the arbitrator's award; any such suit may be brought only in a Federal District Court or a California state court located in San Francisco County, California. The arbitrator, and not any federal, state, or local court, shall have exclusive authority to resolve any dispute relating to the interpretation, applicability, unconscionability, arbitrability, enforceability, or formation of this Agreement including any claim that all or any part of the Agreement is void or voidable. If a claim proceeds in court for any reason rather than in arbitration, we and you waive any right to a jury trial. Notwithstanding the foregoing, we and you both agree that you or we may bring suit in court to enjoin infringement or other misuse of intellectual property rights. 13.2 Class Action Waiver. YOU AND WE AGREE THAT EACH MAY BRING CLAIMS AGAINST THE OTHER ONLY ON AN INDIVIDUAL BASIS, AND NOT AS A PLAINTIFF OR CLASS MEMBER IN ANY PURPORTED CLASS OR REPRESENTATIVE PROCEEDING. YOU AND WE EXPRESSLY WAIVE ANY RIGHT TO FILE A CLASS ACTION OR SEEK RELIEF ON A CLASS BASIS. Unless both you and we agree, no arbitrator or judge may consolidate more than one person's claims or otherwise preside over any form of a representative or class proceeding. The arbitrator may award injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by that party's individual claim. If a court decides that applicable law precludes enforcement of any of this paragraph's limitations as to a particular claim for relief, then that claim (and only that claim) must be severed from the arbitration and may be brought in court. If any court or arbitrator determines that the class action waiver set forth in this paragraph is void or unenforceable for any reason or that an arbitration can proceed on a class basis, then the arbitration provision set forth above shall be deemed null and void in its entirety and the parties shall be deemed to have not agreed to arbitrate disputes. 13.3 30-Day Right to Opt Out. You have the right to opt-out and not be bound by the arbitration and class action waiver provisions set forth above by sending written notice of your decision to opt-out to the following address: Suite 100, 100 Shoreline Hwy, Bldg B, Mill Valley, CA 94941, United States and via email at contact@textile.io , with subject line TEXTILE LEGAL OPT OUT. The notice must be sent within 30 days of your first use of the Services, otherwise, you shall be bound to arbitrate disputes in accordance with the terms of those paragraphs. If you opt-out of these arbitration provisions, we will also not be bound by them. 14. Publicity. \u00b6 We're proud to have you as a customer. During the term of this agreement, you hereby grant us a worldwide, non-exclusive, royalty-free, fully paid-up, transferable and sublicensable license to use your trademarks, service marks, and logos for the purpose of identifying you as a Textile customer to promote and market our services. But if you prefer we not use your logo or name in a particular way, just let us know, and we will respect that. 15. Miscellaneous. \u00b6 15.1 Assignment. You will not assign or otherwise transfer this Agreement or any of your rights and obligations under this Agreement without our prior written consent. Any assignment or transfer in violation of this Section 14.1 will be void. We may assign this Agreement without your consent (a) in connection with a merger, acquisition or sale of all or substantially all of our assets, or (b) to any Affiliate or as part of a corporate reorganization; and effective upon such assignment, the assignee is deemed substituted for Textile as a party to this Agreement and Textile is fully released from all of its obligations and duties to perform under this Agreement. Subject to the foregoing, this Agreement will be binding upon and inure to the benefit of the parties and their respective permitted successors and assigns. 15.2 Entire Agreement. This Agreement incorporates the Policies by reference and is the entire agreement between you and us regarding the subject matter of this Agreement. This Agreement supersedes all prior or contemporaneous representations, understandings, agreements, or communications between you and us, whether written or verbal, regarding the subject matter of this Agreement. We will not be bound by, and specifically, object to, any term, condition or other provision that is different from or in addition to the provisions of this Agreement (whether or not it would materially alter this Agreement) including for example, any term, condition or other provision (a) submitted by you in any order, receipt, acceptance, confirmation, correspondence or other document, (b) related to any online registration, response to any Request for Bid, Request for Proposal, Request for Information, or other questionnaire, or \u00a9 related to any invoicing process that you submit or require us to complete. If the terms of this document are inconsistent with the terms contained in any Policy, the terms contained in this document will control. 15.3 Force Majeure. Neither party nor their respective affiliates will be liable for any delay or failure to perform any obligation under this Agreement where the delay or failure results from any cause beyond such party's reasonable control, including acts of God, labor disputes or other industrial disturbances, electrical or power outages, utilities or other telecommunications failures, cyber-attacks, earthquake, storms or other elements of nature, blockages, embargoes, riots, acts or orders of government, acts of terrorism, or war. 15.4 Governing Law. This Agreement and any dispute of any sort that might arise between you and us will be governed by the laws of the State of California, without giving effect to conflict of law rules. The United Nations Convention for the International Sale of Goods does not apply to this Agreement. 15.5 Trade Compliance. In addition to the representation and warranty above, in connection with this Agreement, you will comply with all applicable import, re-import, sanctions, anti-boycott, export, and re-export control laws and regulations, including all such laws and regulations that apply to a U.S. company, such as the Export Administration Regulations, the International Traffic in Arms Regulations, and economic sanctions programs implemented by the Office of Foreign Assets Control. Specifically, you agree that you shall not \u2013 directly or indirectly \u2013 sell, export, re-export, transfer, divert, or otherwise dispose of any products, software, or technology (including products derived from or based on such technology) received from us under the Agreement to any destination, entity, or person prohibited by any applicable laws or regulations of the United States or any other jurisdiction without obtaining prior authorization from the competent government authorities as required by those laws and regulations. For clarity, you are solely responsible for compliance related to the manner in which you choose to use the Service Offerings, including your transfer and processing of Your Content, the provision of Your Content to End Users, and the region in which any of the foregoing occur. 15.6 Independent Contractors; Non-Exclusive Rights. We and you are independent contractors, and this Agreement will not be construed to create a partnership, joint venture, agency, or employment relationship. Neither party, nor any of their respective affiliates, is an agent of the other for any purpose or has the authority to bind the other. Both parties reserve the right (a) to develop or have developed for it products, services, concepts, systems, or techniques that are similar to or compete with the products, services, concepts, systems, or techniques developed or contemplated by the other party, and (b) to assist third party developers or systems integrators who may offer products or services which compete with the other party's products or services. 15.7 Language. All communications and notices made or given pursuant to this Agreement must be in the English language. If we provide a translation of the English language version of this Agreement, the English language version of the Agreement will control if there is any conflict. 15.8 Confidentiality and Publicity. Each party may use Confidential Information only in connection with its use or provision, as applicable, of the Service Offerings as permitted under this Agreement. Neither party will disclose Confidential Information during the Term or at any time during the 5-year period following the end of the Term. Each party will take all reasonable measures to avoid disclosure, dissemination or unauthorized use of Confidential Information, including, at a minimum, those measures the Disclosing Party take to protect its own confidential information of a similar nature. Neither party will issue any press release nor make any other public communication with respect to this Agreement or its use or provision, as applicable, of the Service Offerings in connection with this Agreement. 15.9 Notice. To You. We may provide any notice to you under this Agreement by: (i) posting a notice on the Textile Site; or (ii) sending a message to the email address then associated with your account. Notices we provide by posting on the Textile Site will be effective upon posting and notices we provide by email will be effective when we send the email. It is your responsibility to keep your email address current. You will be deemed to have received any email sent to the email address then associated with your account when we send the email, whether or not you actually receive the email. To Us. To give us notice under this Agreement, you must contact Textile by email at contact@textile.io or personal delivery, overnight courier or registered or certified mail to the following mailing address: Suite 100, 100 Shoreline Hwy, Bldg B, Mill Valley, CA 94941, United States. We may update the email or address for notices to us by posting a notice on the textile Site. Notices provided by personal delivery will be effective immediately. Notices provided by overnight courier will be effective one business day after they are sent. Notices provided by registered or certified mail will be effective three business days after they are sent. 14.10 No Third-Party Beneficiaries. Except as set forth in Section 9, this Agreement does not create any third-party beneficiary rights in any individual or entity that is not a party to this Agreement. 14.11 U.S. Government Rights. The Service Offerings are provided to the U.S. Government as \"commercial items,\" \"commercial computer software,\" \"commercial computer software documentation,\" and \"technical data\" with the same rights and restrictions generally applicable to the Service Offerings. If you are using the Service Offerings on behalf of the U.S. Government and these terms fail to meet the U.S. Government's needs or are inconsistent in any respect with federal law, you will immediately discontinue your use of the Service Offerings. The terms \"commercial item\" \"commercial computer software,\" \"commercial computer software documentation,\" and \"technical data\" are defined in the Federal Acquisition Regulation and the Defense Federal Acquisition Regulation Supplement. 14.12 No Waivers. The failure by us to enforce any provision of this Agreement will not constitute a present or future waiver of such provision nor limit our right to enforce such provision at a later time. All waivers by us must be in writing to be effective. 14.13 Severability. If any portion of this Agreement is held to be invalid or unenforceable, the remaining portions of this Agreement will remain in full force and effect. Any invalid or unenforceable portions will be interpreted to the effect and intent of the original portion. If such construction is not possible, the invalid or unenforceable portion will be severed from this Agreement but the rest of the Agreement will remain in full force and effect. 14.14 Notice and Procedure for Making Claims of Copyright Infringement. If you are a copyright owner or agent of the owner, and you believe that your copyright or the copyright of a person on whose behalf you are authorized to act has been infringed, please provide us a written notice at the address below with the following information: an electronic or physical signature of the person authorized to act on behalf of the owner of the copyright or other intellectual property interest; a description of the copyrighted work or other intellectual property that you claim has been infringed; a description of where the material that you claim is infringing is located on the Services; your address, telephone number, and email address; a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; a statement by you, made under penalty of perjury, that the above information in your notice is accurate and that you are the copyright or intellectual property owner or authorized to act on the copyright or intellectual property owner's behalf. You can reach us at email: contact@textile.io Subject Line: Copyright Notification. Mail Attention: Textile Copyright \u2105 Suite 100, 100 Shoreline Hwy, Bldg B, Mill Valley, CA 94941, United States 16. Definitions. \u00b6 \"Acceptable Use Policy\" means the policy set forth below, as it may be updated by us from time to time. You agree not to, and not to allow third parties to, use the Services: To violate, or encourage the violation of, the legal rights of others (for example, this may include allowing End Users to infringe or misappropriate the intellectual property rights of others in violation of the Digital Millennium Copyright Act); To engage in, promote or encourage any illegal or harmful activity or infringing, offensive or harmful content; For any unlawful, invasive, infringing, defamatory or fraudulent purpose (for example, this may include phishing, creating a pyramid scheme or mirroring a website); To intentionally distribute viruses, worms, Trojan horses, corrupted files, hoaxes, or other items of a destructive or deceptive nature; To interfere with the use of the Services, or the equipment used to provide the Services, by customers, authorized resellers, or other authorized users; To disable, interfere with or circumvent any aspect of the Services; To generate, distribute, publish or facilitate unsolicited mass email, promotions, advertising or other solicitations (\"spam\"); or To use the Services, or any interfaces provided with the Services, to access any other Textile product or service in a manner that violates the terms of service of such other Textile product or service. \"Account Information\" means information about you that you provide to us in connection with the creation or administration of your Textile account. For example, Account Information includes names, usernames, phone numbers, email addresses, and billing information associated with your Textile account. \"API\" means an application program interface. \"API Request\" has the meaning set forth in Section 6.3. \"Client\" has the meaning set forth in Section 1.2. \"Confidential Information\" means all nonpublic information disclosed by one party its affiliates, business partners or its or their respective employees, contractors or agents (collectively, the \"Disclosing Party\") to the other party (the * \"Receiving Party\") that is designated as confidential or that, given the nature of the information or circumstances surrounding its disclosure, reasonably should be understood to be confidential. Confidential Information includes: (a) nonpublic information relating to the Disclosing Party's or its affiliates or business partners' technology, customers, business plans, promotional and marketing activities, finances and other business affairs; (b) third-party information that the Disclosing Party is obligated to keep confidential; and \u00a9 the nature, content and existence of any discussions or negotiations between you and us or our affiliates. Confidential Information does not include any information that: (i) is or becomes publicly available without breach of this Agreement; (ii) can be shown by documentation to have been known to the Receiving Party at the time of its receipt from the Disclosing Party; (iii) is received from a third party who did not acquire or disclose the same by a wrongful or tortious act; or (iv) can be shown by documentation to have been independently developed by the Receiving Party without reference to the Confidential Information. \"Content\" means software (including machine images), data, text, audio, video, or images. \"Dashboard\" has the meaning set forth in Section 1.2. \"Decentralized Storage Services\" means any distributed or decentralized file storage service, including without limitation IPFS and Filecoin. \"Documentation\" means the user guides and admin guides (in each case exclusive of content referenced via hyperlink) for the Services located at https://docs.textile.io/ (and any successor or related locations designated by us), as such user guides and admin guides may be updated by us from time to time. \"End User\" means any individual or entity that directly or indirectly through another user: (a) accesses or uses Your Content; or (b) otherwise accesses or uses the Service Offerings under your account. \"Governing Laws\" mean the laws of the State of California, without giving effect to any conflict of law rules. \"Indirect Taxes\" means applicable taxes and duties, including, without limitation, VAT, Service Tax, GST, excise taxes, sales and transactions taxes, and gross receipts tax. \"Textile Content\" means Content we or any of our affiliates make available in connection with the Services or on the Textile Site to allow access to and use of the Services, including APIs; WSDLs; Documentation; sample code; software libraries; command line tools; proofs of concept; templates; and other related technology (including any of the foregoing that are provided by our personnel). Textile Content does not include the Services or Third-Party Content. \"Textile Marks\" means any trademarks, service marks, service or trade names, logos, and other designations of Textile and their affiliates that we may make available to you in connection with this Agreement. \"Textile Site\" means https://textile.io/ (and any successor or related site designated by us), as may be updated by us from time to time. \"Losses\" means any claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees).' \"Node\" means an IPFS or Filecoin node run or hosted by Textile. \"Policies\" means this Agreement, the Acceptable Use Policy, Privacy Policy, all restrictions described in the Textile Content and on the Textile Site, and any other policy or terms referenced in or incorporated into this Agreement, each as may be updated by us from time to time, but does not include whitepapers or other marketing materials referenced on the Textile Site. \"Privacy Policy\" means the privacy policy located at https://docs.textile.io/policies/privacy (and any successor or related locations designated by us), as it may be updated by us from time to time. \"Service\" means each of the services, including the Textile Site and any other features, tools, materials, or services offered from time to time, including our network infrastructure, by us or our affiliates. Services do not include Third-Party Content. \"Service Attributes\" means Service usage data related to your account, such as resource identifiers, metadata tags, security and access roles, rules, usage policies, permissions, usage statistics, and analytics. \"Service Offerings\" means the Services (including associated APIs), the Textile Content, the Textile Marks, and any other product or service provided by us under this Agreement. Service Offerings do not include Third-Party Content. \"Suggestions\" means all suggested improvements to the Service Offerings that you provide to us. \"Technical Support Services\" means the technical support services relating to the Services provided by us to you in accordance with the terms of your Selected Plan. \"Term\" means the term of this Agreement described in Section 7.1. \"Termination Date\" means the effective date of termination provided in accordance with Section 7, in a notice from one party to the other. \"Third-Party Content\" means Content made available to you by any third party on the Textile Site or in conjunction with the Services. \"Your Content\" means Content that you or any End User transfers to us for processing, storage, or hosting by the Services in connection with your Textile account and any computational results that you or any End User derive from the foregoing through their use of the Services. Your Content does not include Account Information.","title":"Terms"},{"location":"policies/terms/#1-the-service-offerings","text":"1.1 Generally. You may access and use the Service Offerings in accordance with this Agreement. You agree to comply with the terms of this Agreement and all laws, rules, and regulations applicable to your use of the Service Offerings. 1.2 Account; Project ID. To access the Services, you must first create a Textile with a valid email address. If you intend to select a paid plan of Service, you must also add a valid payment form. Once you have created your account and logged in to the Textile Dashboard (the \"Dashboard\") or Textile Client (the \"Client\"), you can create a new project, and your Project ID (and associated Textile API endpoint URLs) will be generated. 1.3 Third-Party Content. You may use Third-Party Content at your election. This Agreement governs third-Party Content and, if applicable, separate terms and conditions accompanying such Third-Party Content, which terms and conditions may include separate fees and charges.","title":"1. The Service Offerings."},{"location":"policies/terms/#2-changes","text":"2.1 To the Service Offerings. We may change or discontinue any or all of the Service Offerings or change or remove functionality of any or all of the Service Offerings from time to time. We will notify you of any material change to or discontinuation of the Service Offerings. 2.2 To the APIs. We may change or discontinue any APIs for the Services from time to time. For any discontinuation of or material change to an API for a Service, we will use commercially reasonable efforts to continue supporting the previous version of such API for three months after the change or discontinuation (except if doing so (a) would pose a security or intellectual property issue, (b) is economically or technically burdensome, or \u00a9 would cause us to violate the law or requests of governmental entities).","title":"2. Changes."},{"location":"policies/terms/#3-security-and-data-privacy","text":"3.1 Security Risks. You acknowledge that Your Content may be stored on or using Decentralized Storage Services. You understand there may be risks to storing Your Content on or using Decentralized Storage Services, including without limitation loss of Your Content, loss of access to, or ability to manage, Your Content and dependence on third party nodes running such Decentralized Storage Services. We are not responsible for any of Your Content stored on or using Decentralized Storage Services. We will exercise no control whatsoever over Your Content and the content of the information passing through the network provided that it adheres to all other conditions set forth herein and in our Policies. 3.2 Data Privacy. You consent to the storage of Your Content in, and transfer of Your Content into, the regions we operate in, regions in which our servers are located or regions in which servers relating to Decentralized Storage Services are located. We will not access or use Your Content except as necessary to maintain or provide the Service Offerings, or as necessary to comply with the law or a binding order of a governmental body. We will not disclose Your Content to any government or third party except as necessary to comply with the law or a binding order of a governmental body. Unless it would violate the law or a binding order of a governmental body, we will give you notice of any legal requirement or order referred to in this Section (3.2). We will only use your Account Information in accordance with the Privacy Policy, and you consent to such usage. The Privacy Policy does not apply to Your Content. 3.3 Service Attributes. To provide billing and administration services, we may process Service Attributes in the region(s) where you use the Service Offerings and the regions in the United States. To provide you with support services initiated by you and investigate fraud, abuse, or violations of this Agreement, we may process Service Attributes where we maintain our support and investigation personnel.","title":"3. Security and Data Privacy."},{"location":"policies/terms/#4-your-responsibilities","text":"4.1 Your Accounts. Except to the extent caused by our breach of this Agreement, (a) you are responsible for all activities that occur under your account, regardless of whether the activities are authorized by you or undertaken by you, your employees or a third party (including your contractors, agents or End Users), and (b) we and our affiliates are not responsible for unauthorized access to your account. 4.2 Your Content. You will ensure that Your Content and your and End Users' use of Your Content or the Service Offerings will not violate any of the Policies or any applicable law. You are solely responsible for the development, content, operation, maintenance, and use of Your Content. You will bear full risk of loss and damage to Your Content. You acknowledge and agree that you are solely responsible for all acts, omissions and use under and charges incurred with your account or any of Your Content displayed, linked, transmitted through or stored on Decentralized Storage Services. You shall be solely responsible for undertaking measures to: (i) prevent any loss or damage to Your Content; (ii) maintain independent archival and backup copies of Your Content; and (iii) ensure the security, confidentiality and integrity of Your Content transmitted through our Services or stored on Decentralized Storage Services. We shall have no liability to you or any other person for loss, damage or destruction of any of Your Content. 4.3 Your Security and Backup. You are responsible for properly configuring and using the Service Offerings and otherwise taking appropriate action to secure, protect and backup your accounts and Your Content in a manner that will provide appropriate security and protection, which might include use of encryption to protect Your Content from unauthorized access and routinely archiving Your Content. 4.4 Log-In Credentials and Account Keys. To the extent we provide you with Textile log-in credentials and API authentication generated by the Services, such log-in credentials and API authentication are only for your internal use. You will not sell, transfer or sublicense them to any other entity or person, except that you may disclose your private key to your agents and subcontractors performing work on your behalf. 4.5 End Users. You will be deemed to have taken any action that you permit, assist, or facilitate any person or entity to take related to this Agreement, Your Content, or use of the Service Offerings. You are responsible for End Users' use of Your Content and the Service Offerings. You will ensure that all End Users comply with your obligations under this Agreement and that the terms of your agreement with each End User are consistent with this Agreement. If you become aware of any violation of your obligations under this Agreement caused by an End User, you will immediately suspend access to Your Content and the Service Offerings by such End User. We do not provide any support or services to End Users unless we have a separate agreement with you or an End User obligating us to provide such support or services.","title":"4. Your Responsibilities."},{"location":"policies/terms/#5-fees-and-payment","text":"5.1. Service fees. You agree to pay all fees owed for your use of the Services, as calculated by our records based on our publicly available pricing. All charges are non-refundable unless expressly prohibited by applicable law. We may charge your credit card on a recurring basis for any amounts that you owe us, some of which may require advance payments. 5.2 Late payments. Late payments may bear interest at the rate of 1.5% per month (or the highest rate permitted by law, if less) from the payment due date until paid in full. You will be responsible for all reasonable expenses (including attorneys' fees) incurred by us in collecting such delinquent amounts. 5.3 Payment fees. We are not responsible for any bank fees, interest charges, finance charges, overdraft charges, or other fees resulting from charges billed by Textile. Currency exchange settlements will be based on agreements between you and the provider of your credit card. 5.4 Taxes. Our listed fees do not include taxes, and you agree to pay all sales/use, gross receipts, value-added, GST, personal property or other tax (including any interest and penalties) with respect to the transactions and payments under these Terms, other than taxes based on our net income, employees or real property. You agree to work with us to help us obtain any necessary withholding or royalty tax exemptions where applicable. 5.5 Withholdings. Notwithstanding the foregoing, all payments made by you to us under these Terms will be made free and clear of any deduction or withholding, as may be required by law. If any such deduction or withholding (including but not limited to cross-border withholding taxes) is required on any payment, you will pay such additional amounts as are necessary so that the net amount received by us after such deduction or withholding, will be equal to the full amount that we would have received if no deduction or withholding had been required. The payment of any taxes, charges or fees required to be deducted or withheld from payments due to us, and the filing of any information or tax returns with respect thereto, shall be your responsibility. Upon your reasonable request, we will provide you with any existing tax forms in our possession that would reduce or eliminate the amount of any such withholding or deduction for taxes.","title":"5. Fees and Payment."},{"location":"policies/terms/#6-temporary-suspension-limiting-api-requests","text":"6.1 Generally. We may suspend your or any End User's right to access or use any portion or all of the Service Offerings immediately upon notice to you if we determine: You or an End User's use of the Service Offerings (i) poses a security risk to the Service Offerings or any third party, (ii) could adversely impact our systems, the Service Offerings or the systems or Content of any other Textile user, (iii) could subject us, our affiliates, or any third party to liability, or (iv) could be fraudulent; You are, or any End User is, in breach of this Agreement; You are in breach of your payment obligations under Section 5, and such breach continues for 30 days or longer; or You have ceased to operate in the ordinary course, made an assignment for the benefit of creditors or similar disposition of your assets, or become the subject of any bankruptcy, reorganization, liquidation, dissolution or similar proceeding. 6.2 Effect of Suspension. If we suspend your right to access or use any portion or all of the Service Offerings: You remain responsible for all fees and charges you incur during the period of suspension; and You will not be entitled to any service credits for any period of suspension. 6.3 Limiting API Requests. We retain sole discretion to limit your usage of the Services (including without limitation by limiting the number of API requests you may submit to our gateways or nodes (\"API Requests\")) at any time if your usage of the Services exceeds the applicable Threshold for your Selected Plan of Service.","title":"6. Temporary Suspension; Limiting API Requests."},{"location":"policies/terms/#7-term-termination","text":"7.1 Term. The term of this Agreement will commence on the Effective Date and remain in effect until terminated under this Section 7. Any notice of termination of this Agreement by either party to the other must include a Termination Date that complies with the notice periods in Section 7.2. 7.2 Termination. Termination for Convenience. You may terminate this Agreement for any reason by providing us at least 30 days' written notice, after which you will close your account for all Services. We may terminate this Agreement for any reason by providing you at least 30 days' written notice. Termination for Cause. _ By Either Party. Either party may terminate this Agreement for cause if the other party is in material breach of this Agreement and the material breach remains uncured for a period of 30 days from receipt of notice by the other party. No later than the Termination Date, you will close your account. _ By Us. We may also terminate this Agreement immediately upon notice to you (A) for cause if we have the right to suspend under Section 6, (B) if our relationship with a third-party partner who provides software or other technology we use to provide the Service Offerings expires, terminates or requires us to change the way we provide the software or other technology as part of the Services, or (C) in order to comply with the law or requests of governmental entities. 7.3 Effect of Termination. Upon the Termination Date: All your rights under this Agreement immediately terminate; Each party remains responsible for all fees and charges it has incurred through the Termination Date and is responsible for any fees and charges it incurs during the post-termination period; You will immediately return or, if instructed by us, destroy all Textile Content in your possession; Sections 4.1, 5, 7.3, 8 (except the license granted to you in Section 8.3), 9, 10, 11, 13, and 15 will continue to apply in accordance with their terms. For any use of the Services after the Termination Date, the terms of this Agreement will apply and you will pay the applicable fees at the rates under Section 5. Proprietary Rights. 8.1 Your Content. Except as provided in this Section 8, we obtain no rights under this Agreement from you (or your licensors) to Your Content. You consent to our use of Your Content to provide the Service Offerings to you and any End Users. 8.2 Adequate Rights. You represent and warrant to us that: (a) you or your licensors own all right, title, and interest in and to Your Content and Suggestions; (b) you have all rights in Your Content and Suggestions necessary to grant the rights contemplated by this Agreement; and \u00a9 none of Your Content or End Users' use of Your Content or the Service Offerings will violate the Acceptable Use Policy. 8.3 Service Offerings License. We or our licensors own all right, title, and interest in and to the Service Offerings, and all related technology and intellectual property rights. Subject to the terms of this Agreement, we grant you a limited, revocable, non-exclusive, non-sublicensable, non-transferable license to do the following: (a) access and use the Services solely in accordance with this Agreement; and (b) copy and use the Textile Content solely in connection with your permitted use of the Services. Except as provided in this Section 8.3, you obtain no rights under this Agreement from us, our affiliates or our licensors to the Service Offerings, including any related intellectual property rights. Some Textile Content and Third-Party Content may be provided to you under a separate license, such as the Apache License, Version 2.0, or other open-source licenses. In the event of a conflict between this Agreement and any separate license, the separate license will prevail with respect to the Textile Content or Third-Party Content that is the subject of such a separate license. 8.4 License Restrictions. Neither you nor any End User will use the Service Offerings in any manner or for any purpose other than as expressly permitted by this Agreement. Neither you nor any End User will, or will attempt to (a) modify, distribute, alter, tamper with, repair, or otherwise create derivative works of any Content included in the Service Offerings (except to the extent Content included in the Service Offerings is provided to you under a separate license that expressly permits the creation of derivative works), (b) reverse engineer, disassemble, or decompile the Service Offerings or apply any other process or procedure to derive the source code of any software included in the Service Offerings (except to the extent applicable law doesn't allow this restriction), \u00a9 access or use the Service Offerings in a way intended to avoid incurring fees or exceeding usage limits or quotas, or (d) resell or sublicense the Service Offerings. You will not use the Textile Marks unless you obtain our prior written consent. You will not misrepresent or embellish the relationship between us and you (including by expressing or implying that we support, sponsor, endorse, or contribute to you or your business endeavors). You will not imply any relationship or affiliation between us and you except as expressly permitted by this Agreement. 8.5 Suggestions. If you provide any Suggestions to us or our affiliates, we and our affiliates will be entitled to use the Suggestions without restriction. You hereby irrevocably assign to us all right, title, and interest in and to the Suggestions and agree to provide us any assistance we require to document, perfect, and maintain our rights in the Suggestions.","title":"7. Term; Termination."},{"location":"policies/terms/#9-indemnification","text":"9.1 General. You will defend, indemnify, and hold harmless us, our affiliates and licensors, and each of their respective employees, officers, directors, and representatives from and against any Losses arising out of or relating to any claim concerning: (a) your or any End Users' use of the Service Offerings (including any use by your employees and personnel); (b) breach of this Agreement or violation of applicable law by you, End Users or Your Content; or \u00a9 a dispute between you and any End User. You will reimburse us for reasonable attorneys' fees and expenses, as well as our employees' and contractors' time and materials spent responding to any subpoena or other compulsory legal order or process associated with claims described in (a) through \u00a9 above at our then-current hourly rates. We will defend, indemnify, and hold harmless you and your employees, officers, directors, and representatives from and against any Losses arising out of or relating to any claim concerning breach of this Agreement or violation of applicable law by us. We will reimburse you for reasonable attorneys' fees and expenses, as well as your employees' and contractors' time and materials spent responding to any subpoena or other compulsory legal order or process associated with claims described in this paragraph at our then-current hourly rates. 9.2 Intellectual Property. Subject to the limitations in this Section 9, you will defend Textile, its affiliates, and their respective employees, officers, and directors against any third-party claim alleging that any of Your Content infringes or misappropriates that third party's intellectual property rights, and will pay the amount of any adverse final judgment or settlement. Subject to the limitations in this Section 9, we will defend you and your employees, officers, and directors against any third-party claim alleging that the Services infringe or misappropriate that third party's intellectual property rights, and will pay the amount of any adverse final judgment or settlement. Neither party will have obligations or liability under this Section 9.2 arising from infringement by combinations of the Services or Your Content, as applicable, with any other product, service, software, data, content or method. In addition, Textile will have no obligations or liability arising from your or any End User's use of the Services after Textile has notified you to discontinue such use. The remedies provided in this Section 9.2 are the sole and exclusive remedies for any third-party claims of infringement or misappropriation of intellectual property rights by the Services or by Your Content. 9.3 Process. In no event will a party agree to any settlement of any claim that involves any commitment, other than the payment of money, without the written consent of the other party.","title":"9. Indemnification."},{"location":"policies/terms/#10-disclaimers-risk","text":"10.1 DISCLAIMER. THE SERVICE OFFERINGS ARE PROVIDED \"AS IS.\" EXCEPT TO THE EXTENT PROHIBITED BY LAW, OR TO THE EXTENT ANY STATUTORY RIGHTS APPLY THAT CANNOT BE EXCLUDED, LIMITED OR WAIVED, WE AND OUR AFFILIATES AND LICENSORS (A) MAKE NO REPRESENTATIONS OR WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE REGARDING THE SERVICE OFFERINGS OR THE THIRD-PARTY CONTENT, AND (B) DISCLAIM ALL WARRANTIES, INCLUDING ANY IMPLIED OR EXPRESS WARRANTIES (I) OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, OR QUIET ENJOYMENT, (II) ARISING OUT OF ANY COURSE OF DEALING OR USAGE OF TRADE, (III) THAT THE SERVICE OFFERINGS OR THIRD-PARTY CONTENT WILL BE UNINTERRUPTED, ERROR FREE OR FREE OF HARMFUL COMPONENTS, AND (IV) THAT ANY CONTENT WILL BE SECURE OR NOT OTHERWISE LOST OR ALTERED. 10.2 Sophistication and Risk of Cryptographic Systems. By utilizing the Services in any way, you represent that you understand the inherent risks associated with cryptographic systems and that you have an understanding of the usage and intricacies of cryptographic tokens, and blockchain-based software systems. 10.3 Platform Security. Textile is an early-stage platform. You acknowledge that IPFS and Filecoin applications are software subject to flaws and acknowledge that you are solely responsible for evaluating any available code provided by the Services. You further expressly acknowledge and represent that IPFS and Filecoin applications can be written maliciously or negligently, that Textile cannot be held liable for your interaction with such applications and that such applications may cause loss of property or identity. These warnings and others later provided by Textile in no way evidence or represent an on-going duty to alert you to all of the potential risks of utilizing the Services.","title":"10. Disclaimers; Risk."},{"location":"policies/terms/#11-limitations-of-liability","text":"YOU ACKNOWLEDGE AND AGREE THAT YOU ASSUME FULL RESPONSIBILITY FOR YOUR USE OF THE TEXTILE SITE AND THE SERVICES. YOU ACKNOWLEDGE AND AGREE THAT ANY INFORMATION YOU SEND OR RECEIVE DURING YOUR USE OF THE TEXTILE SITE AND THE SERVICES MAY NOT BE SECURE AND MAY BE INTERCEPTED OR LATER ACQUIRED BY UNAUTHORIZED PARTIES. YOU ACKNOWLEDGE AND AGREE THAT YOUR USE OF THE TEXTILE SITE AND THE SERVICES IS AT YOUR OWN RISK. RECOGNIZING SUCH, YOU UNDERSTAND AND AGREE THAT, TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW AND NOTWITHSTANDING ANYTHING HEREIN TO THE CONTRARY, WE AND OUR AFFILIATES AND LICENSORS WILL NOT BE LIABLE TO YOU FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL OR EXEMPLARY DAMAGES (INCLUDING DAMAGES FOR LOSS OF PROFITS, REVENUES, CUSTOMERS, OPPORTUNITIES, GOODWILL, USE, OR DATA), EVEN IF A PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. FURTHER, NEITHER WE NOR ANY OF OUR AFFILIATES OR LICENSORS WILL BE RESPONSIBLE FOR ANY COMPENSATION, REIMBURSEMENT, OR DAMAGES ARISING IN CONNECTION WITH: (A) YOUR INABILITY TO USE THE SERVICES, INCLUDING AS A RESULT OF ANY (I) TERMINATION OR SUSPENSION OF THIS AGREEMENT OR YOUR USE OF OR ACCESS TO THE SERVICE OFFERINGS, (II) OUR DISCONTINUATION OF ANY OR ALL OF THE SERVICE OFFERINGS, OR (III) ANY UNANTICIPATED OR UNSCHEDULED DOWNTIME OF ALL OR A PORTION OF THE SERVICES FOR ANY REASON; (B) THE COST OF PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; (C) ANY INVESTMENTS, EXPENDITURES, OR COMMITMENTS BY YOU IN CONNECTION WITH THIS AGREEMENT OR YOUR USE OF OR ACCESS TO THE SERVICE OFFERINGS; (D) ANY UNAUTHORIZED ACCESS TO, ALTERATION OF, FAILURE TO ACCESS, RETRIEVE, MANAGE OR DELETE, OR THE DELETION, DESTRUCTION, DAMAGE, LOSS OR FAILURE TO STORE ANY OF YOUR CONTENT OR OTHER DATA; (E) ANY ACTIONS WE TAKE OR FAIL TO TAKE AS A RESULT OF COMMUNICATIONS YOU SEND TO US; (F) HUMAN ERRORS; (G) TECHNICAL MALFUNCTIONS; (H) FAILURES, INCLUDING PUBLIC UTILITY OR TELEPHONE OUTAGES; (I) OMISSIONS, INTERRUPTIONS, LATENCY, DELETIONS OR DEFECTS OF ANY DEVICE OR NETWORK, PROVIDERS, OR SOFTWARE (INCLUDING, BUT NOT LIMITED TO, THOSE THAT DO NOT PERMIT PARTICIPATION IN THE SERVICES); (J) ANY INJURY OR DAMAGE TO COMPUTER EQUIPMENT; (K) INABILITY TO FULLY ACCESS THE TEXTILE SITE OR THE SERVICES OR ANY OTHER WEBSITE; (L) THEFT, TAMPERING, DESTRUCTION, OR UNAUTHORIZED ACCESS TO, IMAGES OR OTHER CONTENT OF ANY KIND; (M) DATA THAT IS PROCESSED LATE OR INCORRECTLY OR IS INCOMPLETE OR LOST; (N) TYPOGRAPHICAL, PRINTING OR OTHER ERRORS, OR ANY COMBINATION THEREOF; OR (O) ANY OTHER MATTER RELATING TO THE TEXTILE SITE OR THE SERVICES. IN ADDITION, NOTWITHSTANDING ANYTHING HEREIN TO THE CONTRARY, OUR AND OUR AFFILIATES' AND LICENSORS' AGGREGATE LIABILITY UNDER THIS AGREEMENT WILL NOT EXCEED THE AMOUNT YOU ACTUALLY PAY US UNDER THIS AGREEMENT FOR THE SERVICE THAT GAVE RISE TO THE CLAIM DURING THE 12 MONTHS BEFORE THE LIABILITY AROSE. THE LIMITATIONS IN THIS SECTION 11 APPLY ONLY TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW.","title":"11. Limitations of Liability."},{"location":"policies/terms/#12-modifications-to-the-agreement","text":"We reserve the right, at our sole discretion, to modify or replace any part of this Agreement (including any Policies) at any time. It is your responsibility to check this Agreement periodically for changes. Your continued use of or access to the Textile Site or the Services following the posting of any changes to this Agreement constitutes acceptance of those changes. We may also, in the future, offer new services and/or features through the Textile Site (including, the release of new tools and resources). Such new features and/or services shall be subject to the terms and conditions of this Agreement.","title":"12. Modifications to the Agreement."},{"location":"policies/terms/#13-binding-arbitration-and-class-action-waiver","text":"PLEASE READ THIS SECTION CAREFULLY \u2013 IT MAY SIGNIFICANTLY AFFECT YOUR LEGAL RIGHTS, INCLUDING YOUR RIGHT TO FILE A LAWSUIT IN COURT. 13.1 Binding Arbitration. Any dispute, claim, or controversy (\"Claim\") relating in any way to this Agreement, the Textile Site, your use of the Service Offerings, or to any products or services sold or distributed by Textile will be resolved by binding arbitration as provided in this Section 13, rather than in court, except that you may assert claims in small claims court if your claims qualify. The Federal Arbitration Act and federal arbitration law apply to this Agreement. There is no judge or jury in arbitration, and court review of an arbitration award is limited. However, an arbitrator can award on an individual basis the same damages and relief as a court (including injunctive and declaratory relief or statutory damages) and must follow the terms of this Agreement as a court would. The arbitration will be conducted in accordance with the expedited procedures set forth in the JAMS Comprehensive Arbitration Rules and Procedures (the \"Rules\") as those Rules exist on the effective date of this Agreement, including Rules 16.1 and 16.2 of those Rules. The arbitrator's decision shall be final, binding, and non-appealable. Judgment upon the award may be entered and enforced in any court having jurisdiction. Neither party shall sue the other party other than as provided herein or for enforcement of this clause or of the arbitrator's award; any such suit may be brought only in a Federal District Court or a California state court located in San Francisco County, California. The arbitrator, and not any federal, state, or local court, shall have exclusive authority to resolve any dispute relating to the interpretation, applicability, unconscionability, arbitrability, enforceability, or formation of this Agreement including any claim that all or any part of the Agreement is void or voidable. If a claim proceeds in court for any reason rather than in arbitration, we and you waive any right to a jury trial. Notwithstanding the foregoing, we and you both agree that you or we may bring suit in court to enjoin infringement or other misuse of intellectual property rights. 13.2 Class Action Waiver. YOU AND WE AGREE THAT EACH MAY BRING CLAIMS AGAINST THE OTHER ONLY ON AN INDIVIDUAL BASIS, AND NOT AS A PLAINTIFF OR CLASS MEMBER IN ANY PURPORTED CLASS OR REPRESENTATIVE PROCEEDING. YOU AND WE EXPRESSLY WAIVE ANY RIGHT TO FILE A CLASS ACTION OR SEEK RELIEF ON A CLASS BASIS. Unless both you and we agree, no arbitrator or judge may consolidate more than one person's claims or otherwise preside over any form of a representative or class proceeding. The arbitrator may award injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by that party's individual claim. If a court decides that applicable law precludes enforcement of any of this paragraph's limitations as to a particular claim for relief, then that claim (and only that claim) must be severed from the arbitration and may be brought in court. If any court or arbitrator determines that the class action waiver set forth in this paragraph is void or unenforceable for any reason or that an arbitration can proceed on a class basis, then the arbitration provision set forth above shall be deemed null and void in its entirety and the parties shall be deemed to have not agreed to arbitrate disputes. 13.3 30-Day Right to Opt Out. You have the right to opt-out and not be bound by the arbitration and class action waiver provisions set forth above by sending written notice of your decision to opt-out to the following address: Suite 100, 100 Shoreline Hwy, Bldg B, Mill Valley, CA 94941, United States and via email at contact@textile.io , with subject line TEXTILE LEGAL OPT OUT. The notice must be sent within 30 days of your first use of the Services, otherwise, you shall be bound to arbitrate disputes in accordance with the terms of those paragraphs. If you opt-out of these arbitration provisions, we will also not be bound by them.","title":"13. Binding Arbitration and Class Action Waiver"},{"location":"policies/terms/#14-publicity","text":"We're proud to have you as a customer. During the term of this agreement, you hereby grant us a worldwide, non-exclusive, royalty-free, fully paid-up, transferable and sublicensable license to use your trademarks, service marks, and logos for the purpose of identifying you as a Textile customer to promote and market our services. But if you prefer we not use your logo or name in a particular way, just let us know, and we will respect that.","title":"14. Publicity."},{"location":"policies/terms/#15-miscellaneous","text":"15.1 Assignment. You will not assign or otherwise transfer this Agreement or any of your rights and obligations under this Agreement without our prior written consent. Any assignment or transfer in violation of this Section 14.1 will be void. We may assign this Agreement without your consent (a) in connection with a merger, acquisition or sale of all or substantially all of our assets, or (b) to any Affiliate or as part of a corporate reorganization; and effective upon such assignment, the assignee is deemed substituted for Textile as a party to this Agreement and Textile is fully released from all of its obligations and duties to perform under this Agreement. Subject to the foregoing, this Agreement will be binding upon and inure to the benefit of the parties and their respective permitted successors and assigns. 15.2 Entire Agreement. This Agreement incorporates the Policies by reference and is the entire agreement between you and us regarding the subject matter of this Agreement. This Agreement supersedes all prior or contemporaneous representations, understandings, agreements, or communications between you and us, whether written or verbal, regarding the subject matter of this Agreement. We will not be bound by, and specifically, object to, any term, condition or other provision that is different from or in addition to the provisions of this Agreement (whether or not it would materially alter this Agreement) including for example, any term, condition or other provision (a) submitted by you in any order, receipt, acceptance, confirmation, correspondence or other document, (b) related to any online registration, response to any Request for Bid, Request for Proposal, Request for Information, or other questionnaire, or \u00a9 related to any invoicing process that you submit or require us to complete. If the terms of this document are inconsistent with the terms contained in any Policy, the terms contained in this document will control. 15.3 Force Majeure. Neither party nor their respective affiliates will be liable for any delay or failure to perform any obligation under this Agreement where the delay or failure results from any cause beyond such party's reasonable control, including acts of God, labor disputes or other industrial disturbances, electrical or power outages, utilities or other telecommunications failures, cyber-attacks, earthquake, storms or other elements of nature, blockages, embargoes, riots, acts or orders of government, acts of terrorism, or war. 15.4 Governing Law. This Agreement and any dispute of any sort that might arise between you and us will be governed by the laws of the State of California, without giving effect to conflict of law rules. The United Nations Convention for the International Sale of Goods does not apply to this Agreement. 15.5 Trade Compliance. In addition to the representation and warranty above, in connection with this Agreement, you will comply with all applicable import, re-import, sanctions, anti-boycott, export, and re-export control laws and regulations, including all such laws and regulations that apply to a U.S. company, such as the Export Administration Regulations, the International Traffic in Arms Regulations, and economic sanctions programs implemented by the Office of Foreign Assets Control. Specifically, you agree that you shall not \u2013 directly or indirectly \u2013 sell, export, re-export, transfer, divert, or otherwise dispose of any products, software, or technology (including products derived from or based on such technology) received from us under the Agreement to any destination, entity, or person prohibited by any applicable laws or regulations of the United States or any other jurisdiction without obtaining prior authorization from the competent government authorities as required by those laws and regulations. For clarity, you are solely responsible for compliance related to the manner in which you choose to use the Service Offerings, including your transfer and processing of Your Content, the provision of Your Content to End Users, and the region in which any of the foregoing occur. 15.6 Independent Contractors; Non-Exclusive Rights. We and you are independent contractors, and this Agreement will not be construed to create a partnership, joint venture, agency, or employment relationship. Neither party, nor any of their respective affiliates, is an agent of the other for any purpose or has the authority to bind the other. Both parties reserve the right (a) to develop or have developed for it products, services, concepts, systems, or techniques that are similar to or compete with the products, services, concepts, systems, or techniques developed or contemplated by the other party, and (b) to assist third party developers or systems integrators who may offer products or services which compete with the other party's products or services. 15.7 Language. All communications and notices made or given pursuant to this Agreement must be in the English language. If we provide a translation of the English language version of this Agreement, the English language version of the Agreement will control if there is any conflict. 15.8 Confidentiality and Publicity. Each party may use Confidential Information only in connection with its use or provision, as applicable, of the Service Offerings as permitted under this Agreement. Neither party will disclose Confidential Information during the Term or at any time during the 5-year period following the end of the Term. Each party will take all reasonable measures to avoid disclosure, dissemination or unauthorized use of Confidential Information, including, at a minimum, those measures the Disclosing Party take to protect its own confidential information of a similar nature. Neither party will issue any press release nor make any other public communication with respect to this Agreement or its use or provision, as applicable, of the Service Offerings in connection with this Agreement. 15.9 Notice. To You. We may provide any notice to you under this Agreement by: (i) posting a notice on the Textile Site; or (ii) sending a message to the email address then associated with your account. Notices we provide by posting on the Textile Site will be effective upon posting and notices we provide by email will be effective when we send the email. It is your responsibility to keep your email address current. You will be deemed to have received any email sent to the email address then associated with your account when we send the email, whether or not you actually receive the email. To Us. To give us notice under this Agreement, you must contact Textile by email at contact@textile.io or personal delivery, overnight courier or registered or certified mail to the following mailing address: Suite 100, 100 Shoreline Hwy, Bldg B, Mill Valley, CA 94941, United States. We may update the email or address for notices to us by posting a notice on the textile Site. Notices provided by personal delivery will be effective immediately. Notices provided by overnight courier will be effective one business day after they are sent. Notices provided by registered or certified mail will be effective three business days after they are sent. 14.10 No Third-Party Beneficiaries. Except as set forth in Section 9, this Agreement does not create any third-party beneficiary rights in any individual or entity that is not a party to this Agreement. 14.11 U.S. Government Rights. The Service Offerings are provided to the U.S. Government as \"commercial items,\" \"commercial computer software,\" \"commercial computer software documentation,\" and \"technical data\" with the same rights and restrictions generally applicable to the Service Offerings. If you are using the Service Offerings on behalf of the U.S. Government and these terms fail to meet the U.S. Government's needs or are inconsistent in any respect with federal law, you will immediately discontinue your use of the Service Offerings. The terms \"commercial item\" \"commercial computer software,\" \"commercial computer software documentation,\" and \"technical data\" are defined in the Federal Acquisition Regulation and the Defense Federal Acquisition Regulation Supplement. 14.12 No Waivers. The failure by us to enforce any provision of this Agreement will not constitute a present or future waiver of such provision nor limit our right to enforce such provision at a later time. All waivers by us must be in writing to be effective. 14.13 Severability. If any portion of this Agreement is held to be invalid or unenforceable, the remaining portions of this Agreement will remain in full force and effect. Any invalid or unenforceable portions will be interpreted to the effect and intent of the original portion. If such construction is not possible, the invalid or unenforceable portion will be severed from this Agreement but the rest of the Agreement will remain in full force and effect. 14.14 Notice and Procedure for Making Claims of Copyright Infringement. If you are a copyright owner or agent of the owner, and you believe that your copyright or the copyright of a person on whose behalf you are authorized to act has been infringed, please provide us a written notice at the address below with the following information: an electronic or physical signature of the person authorized to act on behalf of the owner of the copyright or other intellectual property interest; a description of the copyrighted work or other intellectual property that you claim has been infringed; a description of where the material that you claim is infringing is located on the Services; your address, telephone number, and email address; a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; a statement by you, made under penalty of perjury, that the above information in your notice is accurate and that you are the copyright or intellectual property owner or authorized to act on the copyright or intellectual property owner's behalf. You can reach us at email: contact@textile.io Subject Line: Copyright Notification. Mail Attention: Textile Copyright \u2105 Suite 100, 100 Shoreline Hwy, Bldg B, Mill Valley, CA 94941, United States","title":"15. Miscellaneous."},{"location":"policies/terms/#16-definitions","text":"\"Acceptable Use Policy\" means the policy set forth below, as it may be updated by us from time to time. You agree not to, and not to allow third parties to, use the Services: To violate, or encourage the violation of, the legal rights of others (for example, this may include allowing End Users to infringe or misappropriate the intellectual property rights of others in violation of the Digital Millennium Copyright Act); To engage in, promote or encourage any illegal or harmful activity or infringing, offensive or harmful content; For any unlawful, invasive, infringing, defamatory or fraudulent purpose (for example, this may include phishing, creating a pyramid scheme or mirroring a website); To intentionally distribute viruses, worms, Trojan horses, corrupted files, hoaxes, or other items of a destructive or deceptive nature; To interfere with the use of the Services, or the equipment used to provide the Services, by customers, authorized resellers, or other authorized users; To disable, interfere with or circumvent any aspect of the Services; To generate, distribute, publish or facilitate unsolicited mass email, promotions, advertising or other solicitations (\"spam\"); or To use the Services, or any interfaces provided with the Services, to access any other Textile product or service in a manner that violates the terms of service of such other Textile product or service. \"Account Information\" means information about you that you provide to us in connection with the creation or administration of your Textile account. For example, Account Information includes names, usernames, phone numbers, email addresses, and billing information associated with your Textile account. \"API\" means an application program interface. \"API Request\" has the meaning set forth in Section 6.3. \"Client\" has the meaning set forth in Section 1.2. \"Confidential Information\" means all nonpublic information disclosed by one party its affiliates, business partners or its or their respective employees, contractors or agents (collectively, the \"Disclosing Party\") to the other party (the * \"Receiving Party\") that is designated as confidential or that, given the nature of the information or circumstances surrounding its disclosure, reasonably should be understood to be confidential. Confidential Information includes: (a) nonpublic information relating to the Disclosing Party's or its affiliates or business partners' technology, customers, business plans, promotional and marketing activities, finances and other business affairs; (b) third-party information that the Disclosing Party is obligated to keep confidential; and \u00a9 the nature, content and existence of any discussions or negotiations between you and us or our affiliates. Confidential Information does not include any information that: (i) is or becomes publicly available without breach of this Agreement; (ii) can be shown by documentation to have been known to the Receiving Party at the time of its receipt from the Disclosing Party; (iii) is received from a third party who did not acquire or disclose the same by a wrongful or tortious act; or (iv) can be shown by documentation to have been independently developed by the Receiving Party without reference to the Confidential Information. \"Content\" means software (including machine images), data, text, audio, video, or images. \"Dashboard\" has the meaning set forth in Section 1.2. \"Decentralized Storage Services\" means any distributed or decentralized file storage service, including without limitation IPFS and Filecoin. \"Documentation\" means the user guides and admin guides (in each case exclusive of content referenced via hyperlink) for the Services located at https://docs.textile.io/ (and any successor or related locations designated by us), as such user guides and admin guides may be updated by us from time to time. \"End User\" means any individual or entity that directly or indirectly through another user: (a) accesses or uses Your Content; or (b) otherwise accesses or uses the Service Offerings under your account. \"Governing Laws\" mean the laws of the State of California, without giving effect to any conflict of law rules. \"Indirect Taxes\" means applicable taxes and duties, including, without limitation, VAT, Service Tax, GST, excise taxes, sales and transactions taxes, and gross receipts tax. \"Textile Content\" means Content we or any of our affiliates make available in connection with the Services or on the Textile Site to allow access to and use of the Services, including APIs; WSDLs; Documentation; sample code; software libraries; command line tools; proofs of concept; templates; and other related technology (including any of the foregoing that are provided by our personnel). Textile Content does not include the Services or Third-Party Content. \"Textile Marks\" means any trademarks, service marks, service or trade names, logos, and other designations of Textile and their affiliates that we may make available to you in connection with this Agreement. \"Textile Site\" means https://textile.io/ (and any successor or related site designated by us), as may be updated by us from time to time. \"Losses\" means any claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees).' \"Node\" means an IPFS or Filecoin node run or hosted by Textile. \"Policies\" means this Agreement, the Acceptable Use Policy, Privacy Policy, all restrictions described in the Textile Content and on the Textile Site, and any other policy or terms referenced in or incorporated into this Agreement, each as may be updated by us from time to time, but does not include whitepapers or other marketing materials referenced on the Textile Site. \"Privacy Policy\" means the privacy policy located at https://docs.textile.io/policies/privacy (and any successor or related locations designated by us), as it may be updated by us from time to time. \"Service\" means each of the services, including the Textile Site and any other features, tools, materials, or services offered from time to time, including our network infrastructure, by us or our affiliates. Services do not include Third-Party Content. \"Service Attributes\" means Service usage data related to your account, such as resource identifiers, metadata tags, security and access roles, rules, usage policies, permissions, usage statistics, and analytics. \"Service Offerings\" means the Services (including associated APIs), the Textile Content, the Textile Marks, and any other product or service provided by us under this Agreement. Service Offerings do not include Third-Party Content. \"Suggestions\" means all suggested improvements to the Service Offerings that you provide to us. \"Technical Support Services\" means the technical support services relating to the Services provided by us to you in accordance with the terms of your Selected Plan. \"Term\" means the term of this Agreement described in Section 7.1. \"Termination Date\" means the effective date of termination provided in accordance with Section 7, in a notice from one party to the other. \"Third-Party Content\" means Content made available to you by any third party on the Textile Site or in conjunction with the Services. \"Your Content\" means Content that you or any End User transfers to us for processing, storage, or hosting by the Services in connection with your Textile account and any computational results that you or any End User derive from the foregoing through their use of the Services. Your Content does not include Account Information.","title":"16. Definitions."},{"location":"powergate/","text":"UPDATE \u00b6 Since the release of Powergate v2 many of the features and benefits of Powergate have been improved upon by three other technologies. Estuary - seamlessly bridge data between IPFS and Filecoin. Glif - easily host and manage Filecoin nodes. Deal Auctions - migrate large datasets to Filecoin. Legacy Powergate Info \u00b6 The Powergate is an API-driven solution for deploying multi-tiered storage across Filecoin and IPFS . By using the Powergate to persist your data on Filecoin, you gain access to rich storage configuration options such as: Replication factor Miner selection Deal renewal Repair Configurable storage is provided through a connected IPFS peer or pinning network. Warning Do not run the Powergate in production systems and please join the powergate-users channel in the Filecoin community Slack for announcements and support. The Powergate will remain in rapid development until a formal release. During this time, you're likely to encounter bugs and unannounced API changes. Overview \u00b6 Powergate is a collection of libraries, modules, and configuration options, that can be used independently or together, to integrate Filecoin in your application or storage system. It is designed to manage one or many Filecoin wallet addresses, and each address and its associated configuration and data storage is scoped by user. Most Powergate APIs function within the context of single user. Some benefits of using the Powergate include: Ensure storing data on Filecoin is easily available on the IPFS network. Handle long-term storage deal management, including automated renewal and repair. Make use of network indices to improve miner selection and deal creation. Manage Filecoin wallet addresses for one or many users. Easily configure, connect, and deploy Powergate, Lotus , and IPFS together. Much more! Libraries \u00b6 Powergate Repo Open source multi-tiered file storage API built on Filecoin and IPFS. POW JS Client Typescript/Javascript client for Textile's Powergate. POW Golang Client Golang client for the Powergate. POW CLI A command-line interface for working directly with a running Powergate. Filecoin Local Localnet A fast development node for working with Filecoin APIs. Getting started \u00b6 Command-line Interface \u00b6 The full set of Powergate features are available through the binary command-line interface. Install the CLI You can build and install the Powergate CLI from the Powergate Repo . git clone git@github.com:textileio/powergate.git cd powergate make install-pow Info Go 1.14 or newer is required to compile from source. All make commands install binaries in $GOPATH/bin , which usually is in $PATH , so you can run them right away from any folder in your terminal. Using the CLI You can view all the commands by running pow --help . \u279c pow --help A client for storage and retreival of powergate data Usage: pow [ flags ] pow [ command ] Available Commands: admin Provides admin commands config Provides commands to interact with cid storage configs data Provides commands to interact with general data APIs deals Provides commands to view Filecoin deal information help Help about any command id Returns the user id storage-info Provides commands to get and query cid storage info. storage-jobs Provides commands to query for storage jobs in various states version Display version information for pow and the connected server wallet Provides commands about filecoin wallets Flags: -h, --help help for pow --serverAddress string address of the powergate service api ( default \"127.0.0.1:5002\" ) -t, --token string user auth token -v, --version display version information for pow and the connected server Use \"pow [command] --help\" for more information about a command. Multi-tiered storage \u00b6 Powergate provides a multi-tiered file storage API built on Filecoin and IPFS. Storing data on IPFS and Filecoin is as easy as expressing your desired configuration for storing a Cid. Powergate handles Filecoin wallet addresses, long-term deal management, and connecting Filecoin to IPFS on a per user basis. Use of a user is enabled through a basic token, allowing you to create many Powergate users, and map Powergate API access to users in your own system. Read about data storage here . Powergate APIs \u00b6 The Powergate APIs are available as gRPC endpoints. There are four ways to familiarize yourself with the APIs: Explore the CLI . The CLI runs on the Powergate API so, in general, anything you can do in the CLI you can also do over the API. Use the JS Client . We have provided an easy-to-use JavaScript client for the Powergate APIs. Use the Go Client . You can use the Powergate APIs from your Go app by building on the Powergate Go Client . Browse the Proto Files . The API is typed with Protocol Buffers and you can quickly view all capabilities by looking at the .proto files in the Powergate repo . The best place to start is the Powergate user API . Additional Tools \u00b6 The Powergate comes packed with several additional tools: Lotus . A Lotus node running on the Filecoin network. IPFS . A full IPFS node running to back Powergate. Prometheus . The backend for metrics processing. Grafana . Provides metrics dashboard. cAdvisor . Provides container metrics. Running the Powergate \u00b6 You can run the Powergate on the Filecoin mainnet or by using an embedded localnet we make available as part of the Powergate stack. We recommend starting with the localnet as you'll have access to the full set of APIs and capabilities without having to sync to the network right away. When you're ready, you can update your Powergate to connect to the live mainnet . Localnet \u00b6 The localnet provides a fast, fully-functional, embedded Filecoin network that can be used for testing, building, or running continuous integration. Read more about running the Powergate on localnet or running the localnet to use the Lotus client directly. Mainnet \u00b6 Once you're ready to start using the Powergate with the Filecoin Mainnet, it's just a single line. git clone git@github.com:textileio/powergate.git cd powergate/docker make up Read the latest setup instructions . Learn more \u00b6 Walk-through Video \u00b6 In the above presentation, you'll see a high-level overview of how the Powergate fits into the Filecoin and IPFS networks and a detailed walk-through of system components. Running System Video \u00b6 The above video shows the Powergate startup, including IPFS and Lotus nodes, and the admin using the Powergate CLI to create a deal on the Filecoin network. Keep up-to-date \u00b6 Follow the project on our blog and GitHub repo and give us your feedback.","title":"Introduction"},{"location":"powergate/#update","text":"Since the release of Powergate v2 many of the features and benefits of Powergate have been improved upon by three other technologies. Estuary - seamlessly bridge data between IPFS and Filecoin. Glif - easily host and manage Filecoin nodes. Deal Auctions - migrate large datasets to Filecoin.","title":"UPDATE"},{"location":"powergate/#legacy-powergate-info","text":"The Powergate is an API-driven solution for deploying multi-tiered storage across Filecoin and IPFS . By using the Powergate to persist your data on Filecoin, you gain access to rich storage configuration options such as: Replication factor Miner selection Deal renewal Repair Configurable storage is provided through a connected IPFS peer or pinning network. Warning Do not run the Powergate in production systems and please join the powergate-users channel in the Filecoin community Slack for announcements and support. The Powergate will remain in rapid development until a formal release. During this time, you're likely to encounter bugs and unannounced API changes.","title":"Legacy Powergate Info"},{"location":"powergate/#overview","text":"Powergate is a collection of libraries, modules, and configuration options, that can be used independently or together, to integrate Filecoin in your application or storage system. It is designed to manage one or many Filecoin wallet addresses, and each address and its associated configuration and data storage is scoped by user. Most Powergate APIs function within the context of single user. Some benefits of using the Powergate include: Ensure storing data on Filecoin is easily available on the IPFS network. Handle long-term storage deal management, including automated renewal and repair. Make use of network indices to improve miner selection and deal creation. Manage Filecoin wallet addresses for one or many users. Easily configure, connect, and deploy Powergate, Lotus , and IPFS together. Much more!","title":"Overview"},{"location":"powergate/#libraries","text":"","title":"Libraries"},{"location":"powergate/#getting-started","text":"","title":"Getting started"},{"location":"powergate/#command-line-interface","text":"The full set of Powergate features are available through the binary command-line interface. Install the CLI You can build and install the Powergate CLI from the Powergate Repo . git clone git@github.com:textileio/powergate.git cd powergate make install-pow Info Go 1.14 or newer is required to compile from source. All make commands install binaries in $GOPATH/bin , which usually is in $PATH , so you can run them right away from any folder in your terminal. Using the CLI You can view all the commands by running pow --help . \u279c pow --help A client for storage and retreival of powergate data Usage: pow [ flags ] pow [ command ] Available Commands: admin Provides admin commands config Provides commands to interact with cid storage configs data Provides commands to interact with general data APIs deals Provides commands to view Filecoin deal information help Help about any command id Returns the user id storage-info Provides commands to get and query cid storage info. storage-jobs Provides commands to query for storage jobs in various states version Display version information for pow and the connected server wallet Provides commands about filecoin wallets Flags: -h, --help help for pow --serverAddress string address of the powergate service api ( default \"127.0.0.1:5002\" ) -t, --token string user auth token -v, --version display version information for pow and the connected server Use \"pow [command] --help\" for more information about a command.","title":"Command-line Interface"},{"location":"powergate/#multi-tiered-storage","text":"Powergate provides a multi-tiered file storage API built on Filecoin and IPFS. Storing data on IPFS and Filecoin is as easy as expressing your desired configuration for storing a Cid. Powergate handles Filecoin wallet addresses, long-term deal management, and connecting Filecoin to IPFS on a per user basis. Use of a user is enabled through a basic token, allowing you to create many Powergate users, and map Powergate API access to users in your own system. Read about data storage here .","title":"Multi-tiered storage"},{"location":"powergate/#powergate-apis","text":"The Powergate APIs are available as gRPC endpoints. There are four ways to familiarize yourself with the APIs: Explore the CLI . The CLI runs on the Powergate API so, in general, anything you can do in the CLI you can also do over the API. Use the JS Client . We have provided an easy-to-use JavaScript client for the Powergate APIs. Use the Go Client . You can use the Powergate APIs from your Go app by building on the Powergate Go Client . Browse the Proto Files . The API is typed with Protocol Buffers and you can quickly view all capabilities by looking at the .proto files in the Powergate repo . The best place to start is the Powergate user API .","title":"Powergate APIs"},{"location":"powergate/#additional-tools","text":"The Powergate comes packed with several additional tools: Lotus . A Lotus node running on the Filecoin network. IPFS . A full IPFS node running to back Powergate. Prometheus . The backend for metrics processing. Grafana . Provides metrics dashboard. cAdvisor . Provides container metrics.","title":"Additional Tools"},{"location":"powergate/#running-the-powergate","text":"You can run the Powergate on the Filecoin mainnet or by using an embedded localnet we make available as part of the Powergate stack. We recommend starting with the localnet as you'll have access to the full set of APIs and capabilities without having to sync to the network right away. When you're ready, you can update your Powergate to connect to the live mainnet .","title":"Running the Powergate"},{"location":"powergate/#localnet","text":"The localnet provides a fast, fully-functional, embedded Filecoin network that can be used for testing, building, or running continuous integration. Read more about running the Powergate on localnet or running the localnet to use the Lotus client directly.","title":"Localnet"},{"location":"powergate/#mainnet","text":"Once you're ready to start using the Powergate with the Filecoin Mainnet, it's just a single line. git clone git@github.com:textileio/powergate.git cd powergate/docker make up Read the latest setup instructions .","title":"Mainnet"},{"location":"powergate/#learn-more","text":"","title":"Learn more"},{"location":"powergate/#walk-through-video","text":"In the above presentation, you'll see a high-level overview of how the Powergate fits into the Filecoin and IPFS networks and a detailed walk-through of system components.","title":"Walk-through Video"},{"location":"powergate/#running-system-video","text":"The above video shows the Powergate startup, including IPFS and Lotus nodes, and the admin using the Powergate CLI to create a deal on the Filecoin network.","title":"Running System Video"},{"location":"powergate/#keep-up-to-date","text":"Follow the project on our blog and GitHub repo and give us your feedback.","title":"Keep up-to-date"},{"location":"powergate/admin/","text":"Admin APIs \u00b6 Powergate includes some administrative APIs. They allow the caller to: Create and list users View wallet addresses Send FIL Show information about jobs and data across all users managed by the Powergate node. Admin Auth Token \u00b6 Powergate's backend server may be configured with an admin auth token to restrict access only to clients that provide the token with their requests. Info Be sure to set the admin token correctly in your client of choice . Info Note that if you're running Powergate using a local dev net , there is no admin auth token set by default, so you don't have to provide it. In the case of the Powergate CLI, pow , the admin token can be provided with the --admin-token flag, or by setting the POW_ADMIN_TOKEN environment variable. CLI Usage \u00b6 We can get a quick overview of the pow admin API below: \u279c pow admin --help Provides admin commands Usage: pow admin [ command ] Available Commands: data Provides admin data commands storage-info Provides admin storage info commands storage-jobs Provides admin jobs commands users Provides admin users commands wallet Provides admin wallet commands Flags: --admin-token string admin auth token -h, --help help for admin Global Flags: --serverAddress string address of the powergate service api ( default \"127.0.0.1:5002\" ) -t, --token string user auth token Use \"pow admin [command] --help\" for more information about a command. As an example, you can create a new user by running: \u279c export POW_ADMIN_TOKEN = <admin token value> \u279c pow admin user create { \"user\" : { \"id\" : \"57b2f476-cc6f-4063-a8cb-d07652742722\" , \"token\" : \"2ddab280-8ba7-4579-8026-04573fc8d0f5\" } }","title":"Admin APIs"},{"location":"powergate/admin/#admin-apis","text":"Powergate includes some administrative APIs. They allow the caller to: Create and list users View wallet addresses Send FIL Show information about jobs and data across all users managed by the Powergate node.","title":"Admin APIs"},{"location":"powergate/admin/#admin-auth-token","text":"Powergate's backend server may be configured with an admin auth token to restrict access only to clients that provide the token with their requests. Info Be sure to set the admin token correctly in your client of choice . Info Note that if you're running Powergate using a local dev net , there is no admin auth token set by default, so you don't have to provide it. In the case of the Powergate CLI, pow , the admin token can be provided with the --admin-token flag, or by setting the POW_ADMIN_TOKEN environment variable.","title":"Admin Auth Token"},{"location":"powergate/admin/#cli-usage","text":"We can get a quick overview of the pow admin API below: \u279c pow admin --help Provides admin commands Usage: pow admin [ command ] Available Commands: data Provides admin data commands storage-info Provides admin storage info commands storage-jobs Provides admin jobs commands users Provides admin users commands wallet Provides admin wallet commands Flags: --admin-token string admin auth token -h, --help help for admin Global Flags: --serverAddress string address of the powergate service api ( default \"127.0.0.1:5002\" ) -t, --token string user auth token Use \"pow admin [command] --help\" for more information about a command. As an example, you can create a new user by running: \u279c export POW_ADMIN_TOKEN = <admin token value> \u279c pow admin user create { \"user\" : { \"id\" : \"57b2f476-cc6f-4063-a8cb-d07652742722\" , \"token\" : \"2ddab280-8ba7-4579-8026-04573fc8d0f5\" } }","title":"CLI Usage"},{"location":"powergate/faq/","text":"Filecoin Frequently Ased Questions \u00b6 What is a minimal test of localnet using the Powergate CLI? \u00b6 $ <generate or use a ~10MB \u201cnew\u201d file> $ pow -t 9d9f2fb8-c559-4394-98c9-12b2144124fc data stage new { \"cid\": \"QmSKfdYojdncCkq7FCnhATvzPrtS4HSdQno7TxTKTgegFt\" } $ pow -t 9d9f2fb8-c559-4394-98c9-12b2144124fc config apply QmSKfdYojdncCkq7FCnhATvzPrtS4HSdQno7TxTKTg { \"jobId\": \"e27f1366-f3d0-484d-a0b3-b3abe71c150c\" } $ pow -t 9d9f2fb8-c559-4394-98c9-12b2144124fc data log QmSKfdYojdncCkq7FCnhATvzPrtS4HSdQno7TxTKTgegFt > 2020-09-28T09:12:15 - Pushing new configuration... > 2020-09-28T09:12:15 - Configuration saved successfully > 2020-09-28T09:12:15 - Executing job e27f1366-f3d0-484d-a0b3-b3abe71c150c... > 2020-09-28T09:12:15 - Ensuring Hot-Storage satisfies the configuration... > 2020-09-28T09:12:15 - Hot-Storage execution ran successfully. > 2020-09-28T09:12:15 - Ensuring Cold-Storage satisfies the configuration... > 2020-09-28T09:12:15 - Current replication factor is lower than desired, making 1 new deals... > 2020-09-28T09:12:15 - Calculating piece size... > 2020-09-28T09:12:16 - Estimated piece size is 16777216 bytes. > 2020-09-28T09:12:16 - Proposing deal to miner t01000 with 500000000 attoFIL per epoch... > 2020-09-28T09:12:17 - Watching deals unfold... > 2020-09-28T09:12:47 - Deal with miner t01000 changed state to StorageDealSealing > 2020-09-28T09:14:47 - Deal 2 with miner t01000 is active on-chain > 2020-09-28T09:14:47 - Cold-Storage execution ran successfully. > 2020-09-28T09:14:47 - Job e27f1366-f3d0-484d-a0b3-b3abe71c150c execution finished with status Success. Why is my custom StorageConfig being ignored? \u00b6 In SR2, we're using a custom miner-selector strategy by default: SR2-MinerSelector. Every time Powergate needs to create a deal, it fetches this JSON file and takes amount miners at random from each region and make deals with them. The list from the JSON file includes miners who should be reasonably reliable to increase the odds of a successful deal. The list is maintained by the Slingshot team. Powergate fetches this file every time it needs to do a deal so it will always select the most recent miners. If you set TrustedMiners or RepFactor in your storage config, those will be ignored by Powergate. If you want full control using your StorageConfig , you can run powd with --ffsminerselector=\"reputation\" (or env POWD_FFSMINERSELECTOR) which switches to the previous unopinionated miner selector strategy used before SR2. I see a log error miner XXX not in ask-cache and query-ask errored: , what does this mean? \u00b6 This usually means two possible problems: The targeted miners don't exist in the network, or your Lotus node is not completely synced. Your Lotus node doesn't have connectivity with them to query ask their storage price. In most cases, if the miner or your Lotus node are in China, there might be reachability challenges related to the second bullet point. If you're not using any custom config and just the SR2 miner selector using the remote JSON file, and experiencing problems reaching some of those miners, please report this in a support channel since we should understand why that particular miner might have problems for your Lotus node. When I start Powergate, I see a fatal error: verifying sr2 url content: getting miners list from url: Get https://xxxxx , what does this mean? \u00b6 Since Powergate uses SR2 miner selection by default, it checks if the miners JSON file is reachable. This file is located in Github so it should be readily available. Some Powergate community members running Powergate from China had experienced these exact problems since there might be constraints in fetching this file from Github. You can override this URL by specifying the flag/env --ffsminerselectorparams / POWD_FFSMINERSELECTORPARAMS with any URL that might be reachable from your location. I see a log error computing commP failed: generating CommP: blockstore: block not found , what does this mean? \u00b6 This is a sign that your Lotus node is not properly configured to use go-ipfs from Powergate as the underlying blockstore to find and store data. You should configure the following in your Lotus config.toml file: [Client] UseIpfs = true IpfsMAddr = \"/ip4/127.0.0.1/tcp/5001\" IpfsUseForRetrieval = true Note that if you are running the Powergate stack with make up , this is already wired automatically . The pow data log commands mention an error ... adding markets funds failed: , how can I fix this? \u00b6 You should check that your user wallet address used for making deals has enough funds. What does the following log error mean: rpc go-jsonrpc: xxxx ? \u00b6 Usually, this is related to a reported issue. As a solution, Powergate switched to another style of connecting to Lotus which is more reliable and avoids that problem. You could ignore those errors since Powergate is not relying on the Lotus client to have stable connections. If the errors don't impact other logs related to Powergate, you should be fine. If that isn't the case please report the issue in a support channel. We decided to not hide errors from this external package just in case we discover new problems. I've made a deal in Mainnet/Testnet/SR2, how can I know everything is working okay? \u00b6 We recommend using the pow -t <token> data log <pushed-cid> which provides a human-friendy output. Creating deals on any Filecoin network can take over 10hrs and many things can go wrong since Powergate is relatively open to miners that provide storage in the network. They might go offline at any time, be unreliable, or have network problems. I see a log error already tracking identifier: <cid> , what should I do? \u00b6 Please refer to this Slack thread.","title":"FAQ"},{"location":"powergate/faq/#filecoin-frequently-ased-questions","text":"","title":"Filecoin Frequently Ased Questions"},{"location":"powergate/faq/#what-is-a-minimal-test-of-localnet-using-the-powergate-cli","text":"$ <generate or use a ~10MB \u201cnew\u201d file> $ pow -t 9d9f2fb8-c559-4394-98c9-12b2144124fc data stage new { \"cid\": \"QmSKfdYojdncCkq7FCnhATvzPrtS4HSdQno7TxTKTgegFt\" } $ pow -t 9d9f2fb8-c559-4394-98c9-12b2144124fc config apply QmSKfdYojdncCkq7FCnhATvzPrtS4HSdQno7TxTKTg { \"jobId\": \"e27f1366-f3d0-484d-a0b3-b3abe71c150c\" } $ pow -t 9d9f2fb8-c559-4394-98c9-12b2144124fc data log QmSKfdYojdncCkq7FCnhATvzPrtS4HSdQno7TxTKTgegFt > 2020-09-28T09:12:15 - Pushing new configuration... > 2020-09-28T09:12:15 - Configuration saved successfully > 2020-09-28T09:12:15 - Executing job e27f1366-f3d0-484d-a0b3-b3abe71c150c... > 2020-09-28T09:12:15 - Ensuring Hot-Storage satisfies the configuration... > 2020-09-28T09:12:15 - Hot-Storage execution ran successfully. > 2020-09-28T09:12:15 - Ensuring Cold-Storage satisfies the configuration... > 2020-09-28T09:12:15 - Current replication factor is lower than desired, making 1 new deals... > 2020-09-28T09:12:15 - Calculating piece size... > 2020-09-28T09:12:16 - Estimated piece size is 16777216 bytes. > 2020-09-28T09:12:16 - Proposing deal to miner t01000 with 500000000 attoFIL per epoch... > 2020-09-28T09:12:17 - Watching deals unfold... > 2020-09-28T09:12:47 - Deal with miner t01000 changed state to StorageDealSealing > 2020-09-28T09:14:47 - Deal 2 with miner t01000 is active on-chain > 2020-09-28T09:14:47 - Cold-Storage execution ran successfully. > 2020-09-28T09:14:47 - Job e27f1366-f3d0-484d-a0b3-b3abe71c150c execution finished with status Success.","title":"What is a minimal test of localnet using the Powergate CLI?"},{"location":"powergate/faq/#why-is-my-custom-storageconfig-being-ignored","text":"In SR2, we're using a custom miner-selector strategy by default: SR2-MinerSelector. Every time Powergate needs to create a deal, it fetches this JSON file and takes amount miners at random from each region and make deals with them. The list from the JSON file includes miners who should be reasonably reliable to increase the odds of a successful deal. The list is maintained by the Slingshot team. Powergate fetches this file every time it needs to do a deal so it will always select the most recent miners. If you set TrustedMiners or RepFactor in your storage config, those will be ignored by Powergate. If you want full control using your StorageConfig , you can run powd with --ffsminerselector=\"reputation\" (or env POWD_FFSMINERSELECTOR) which switches to the previous unopinionated miner selector strategy used before SR2.","title":"Why is my custom StorageConfig being ignored?"},{"location":"powergate/faq/#i-see-a-log-error-miner-xxx-not-in-ask-cache-and-query-ask-errored-what-does-this-mean","text":"This usually means two possible problems: The targeted miners don't exist in the network, or your Lotus node is not completely synced. Your Lotus node doesn't have connectivity with them to query ask their storage price. In most cases, if the miner or your Lotus node are in China, there might be reachability challenges related to the second bullet point. If you're not using any custom config and just the SR2 miner selector using the remote JSON file, and experiencing problems reaching some of those miners, please report this in a support channel since we should understand why that particular miner might have problems for your Lotus node.","title":"I see a log error miner XXX not in ask-cache and query-ask errored:, what does this mean?"},{"location":"powergate/faq/#when-i-start-powergate-i-see-a-fatal-error-verifying-sr2-url-content-getting-miners-list-from-url-get-httpsxxxxx-what-does-this-mean","text":"Since Powergate uses SR2 miner selection by default, it checks if the miners JSON file is reachable. This file is located in Github so it should be readily available. Some Powergate community members running Powergate from China had experienced these exact problems since there might be constraints in fetching this file from Github. You can override this URL by specifying the flag/env --ffsminerselectorparams / POWD_FFSMINERSELECTORPARAMS with any URL that might be reachable from your location.","title":"When I start Powergate, I see a fatal error: verifying sr2 url content: getting miners list from url: Get https://xxxxx, what does this mean?"},{"location":"powergate/faq/#i-see-a-log-error-computing-commp-failed-generating-commp-blockstore-block-not-found-what-does-this-mean","text":"This is a sign that your Lotus node is not properly configured to use go-ipfs from Powergate as the underlying blockstore to find and store data. You should configure the following in your Lotus config.toml file: [Client] UseIpfs = true IpfsMAddr = \"/ip4/127.0.0.1/tcp/5001\" IpfsUseForRetrieval = true Note that if you are running the Powergate stack with make up , this is already wired automatically .","title":"I see a log error computing commP failed: generating CommP: blockstore: block not found, what does this mean?"},{"location":"powergate/faq/#the-pow-data-log-commands-mention-an-error-adding-markets-funds-failed-how-can-i-fix-this","text":"You should check that your user wallet address used for making deals has enough funds.","title":"The pow data log commands mention an error ... adding markets funds failed:, how can I fix this?"},{"location":"powergate/faq/#what-does-the-following-log-error-mean-rpc-go-jsonrpc-xxxx","text":"Usually, this is related to a reported issue. As a solution, Powergate switched to another style of connecting to Lotus which is more reliable and avoids that problem. You could ignore those errors since Powergate is not relying on the Lotus client to have stable connections. If the errors don't impact other logs related to Powergate, you should be fine. If that isn't the case please report the issue in a support channel. We decided to not hide errors from this external package just in case we discover new problems.","title":"What does the following log error mean: rpc go-jsonrpc: xxxx?"},{"location":"powergate/faq/#ive-made-a-deal-in-mainnettestnetsr2-how-can-i-know-everything-is-working-okay","text":"We recommend using the pow -t <token> data log <pushed-cid> which provides a human-friendy output. Creating deals on any Filecoin network can take over 10hrs and many things can go wrong since Powergate is relatively open to miners that provide storage in the network. They might go offline at any time, be unreliable, or have network problems.","title":"I've made a deal in Mainnet/Testnet/SR2, how can I know everything is working okay?"},{"location":"powergate/faq/#i-see-a-log-error-already-tracking-identifier-cid-what-should-i-do","text":"Please refer to this Slack thread.","title":"I see a log error already tracking identifier: &lt;cid&gt;, what should I do?"},{"location":"powergate/localnet/","text":"Filecoin Localnet \u00b6 Having a fully synced Lotus node can take considerable time and effort to maintain. Thats why we built a localnet to enhance app development, testing, and continuous integration scenarios. The required effort is normal on live blockchain networks but isn't ideal in some scenarios. Localnet Features \u00b6 Quick start up Starting the localnet should take under a minute after the docker instances have been installed. Storing a file in a new deal should take about a minute with the default settings and faster with custom settings. The localnet runs a local localnet with a mock sector-builder. This enables fast deployment of a development Filecoin network containing miners with mocked sealing but the rest of the network logic remains the same as the production Filecoin network. The miners are configured to accept and store all incoming deals. Configurable You can change settings such as block generation speed and sector sizes. For CI environments, you may set block production speeds to the order of ~100ms and disable --bigsectors . This localnet setup would be optimized for minimum CPU usage and very fast chain progress, which can confirm deals in seconds. If you require more realistic scenarios (e.g. during product demos), you can change to block production speed to ~1s and enable --bigsectors . This would progress deals slow enough that you can observe updates in the status of confirmed deals at the rate of ~1 minute and also store larger files if required. Warning Not using --bigsectors will limit you to storing files of around 700 bytes and deals will complete in 30-60 seconds. Using --bigsectors will allow you to store files anywhere from 1Mb to 400Mb, but deals will complete in 3-4 minutes. Be sure to choose the value that makes sense for your development scenario. Production compatible storage The localnet is designed to function the same way as the production Filecoin network, except faster and entirely local. The localnet supports both 2KiB and 512MiB sectors and the speed of block production is configurable. For advanced features, refer to the localnet Readme . Localnet Miners \u00b6 Localnet generates miners deterministically when it's started. If you run the localnet with a single miner, the miner's address will be t01000 . If you start the localnet with two miners, the addresses will be t01000 and t01001 . And so on. When running the localnet in Powergate, you can also fetch miner details from the miner API or CLI. Getting Started \u00b6 There are a few resources you'll need before you start running any nodes: Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker-enabled system but to get started, we recommend Docker Desktop and the default configurations provided. Powergate . If you run the localnet as part of the Powergate, you should get the latest version of the Powergate source code. Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't require Go. Localnet with Powergate \u00b6 The fastest way to experiment with the Powergate CLI or API is to replace the Lotus client dependency with a running localnet. This will run the Powergate on a Lotus client connected to an embedded network of miners. Installation \u00b6 You can run localnet with a Powergate release or Powergate source code. Download a release \u00b6 Visit the latest Powergate release page and download the powergate-docker-<version>.zip release artifact. Unzip it and cd into the resulting directory: unzip powergate-docker-<version>.zip cd powergate-docker-<version> Use Powergate source code \u00b6 Clone the Powergate and cd into the project's docker directory: git clone git@github.com:textileio/powergate.git cd powergate/docker Setup \u00b6 You can now use the provided docker-compose configuration with whichever option you chose. The default setup runs Powergate connected to a localnet with 512Mib sectors. The gRPC API and CLI are available and don't need any extra config flags. \ud83c\udf8a Run the docker-compose Docker files for the Powergate are contained in the folder, /docker . make localnet Info You can set BIGSECTORS according to your needs. See the description above for more information. If you don't specify a BIGSECTORS environment variable, the default is true . On initial setup, Docker will download the required instances before any Powergate setup begins. Downloads may take a few minutes and only happen on the first run. Once running, you'll begin to see log outputs, including those of the embedded miner. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you'll have a fully functional Powergate ( powd ), a Lotus localnet, and an IPFS node wired together to start using. Create a deal and store a file \u00b6 The CLI and API are the same in localnet and production except that your deals will store faster and disappear when you delete the localnet. Install the CLI \u00b6 You can install the CLI from a Powergate release or the source code. Download a release \u00b6 Visit the latest Powergate release page and download the pow_<version>_<platform>.tar.gz file appropriate for your system. Unzip and install pow (the following example is for Unix-like systems): tar -xzvf pow_v0.1.0_darwin-amd64.tar.gz ./install Moved ./pow to /usr/local/bin Info If you're installing on macOS, there are some system permissions issue you'll have to deal with. Please follow the hub installation instructions to work around the issue. Build from source code \u00b6 From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build-pow Test your installation. pow --help Start storing data \u00b6 You're now ready to start storing and retrieving data using the Powergate. Read more on Storing Data . Localnet with Lotus Client \u00b6 You can run the localnet to make use of the Lotus Client with all the benefits described in the introduction but with no Powergate or IPFS components. Run from Docker image \u00b6 You can run localnet with the Docker image we maintain. Running the image is just a single line. docker run --name texlocalnet -e TEXLOTUSDEVNET_SPEED = 1500 \\ -e TEXLOTUSDEVNET_BIGSECTORS = true -p 1234 :7777 \\ -v /tmp/import:/tmp/import textile/lotus-devnet After running the container, the Lotus API endpoint is available at the default port which lets you use the Lotus CLI without any extra configuration. Remember, localnets should be used as ephemeral networks, so be sure to stop and remove the texlocalnet container if you re-rerun the above command again. If you plan to use the ClientImport API or lotus client import command, your target file to import should be in the /tmp/import path on your host machine. This folder is bound to the docker image and the localnet, so the Lotus node can find it under the same path. Finally, notice that the above command doesn't specify the textile/lotus-devnet tag, so it's recommended that you consider updating your cached latest tag. Configuration parameters Above, we used the environmental variables to set the speed and bigsectors flags. The complete mapping of options are: TEXLOTUSDEVNET_SPEED : Time in milliseconds of blocks/tipset generation. TEXLOTUSDEVNET_BIGSECTORS : If true, the localnet will run on 512Mib sectors, but 2Kib otherwise. TEXLOTUSDEVNET_NUMMINERS : The number of miners in the localnet. This is an experimental feature, stable for <=3 miners. TEXLOTUSDEVNET_IPFSADDR : Optional multiaddr of an IPFS node to enable the Lotus node to be connected to an IPFS node to avoid importing deals data, and storing retrievals. Run from source code \u00b6 Requirements Devnet . If you run the localnet with a stand-alone Lotus node, you should get the latest version of the localnet source code. Installation \u00b6 Clone the lotus-devnet repo and cd into the project git clone git@github.com:textileio/lotus-devnet.git cd lotus-devnet Setup \u00b6 Install the dependencies: make build Run the devnet with: go run main.go If you compiled a prior version of lotus-devnet , running make clean is recommended before building again. For full configuration options, see the project Readme","title":"Localnet"},{"location":"powergate/localnet/#filecoin-localnet","text":"Having a fully synced Lotus node can take considerable time and effort to maintain. Thats why we built a localnet to enhance app development, testing, and continuous integration scenarios. The required effort is normal on live blockchain networks but isn't ideal in some scenarios.","title":"Filecoin Localnet"},{"location":"powergate/localnet/#localnet-features","text":"Quick start up Starting the localnet should take under a minute after the docker instances have been installed. Storing a file in a new deal should take about a minute with the default settings and faster with custom settings. The localnet runs a local localnet with a mock sector-builder. This enables fast deployment of a development Filecoin network containing miners with mocked sealing but the rest of the network logic remains the same as the production Filecoin network. The miners are configured to accept and store all incoming deals. Configurable You can change settings such as block generation speed and sector sizes. For CI environments, you may set block production speeds to the order of ~100ms and disable --bigsectors . This localnet setup would be optimized for minimum CPU usage and very fast chain progress, which can confirm deals in seconds. If you require more realistic scenarios (e.g. during product demos), you can change to block production speed to ~1s and enable --bigsectors . This would progress deals slow enough that you can observe updates in the status of confirmed deals at the rate of ~1 minute and also store larger files if required. Warning Not using --bigsectors will limit you to storing files of around 700 bytes and deals will complete in 30-60 seconds. Using --bigsectors will allow you to store files anywhere from 1Mb to 400Mb, but deals will complete in 3-4 minutes. Be sure to choose the value that makes sense for your development scenario. Production compatible storage The localnet is designed to function the same way as the production Filecoin network, except faster and entirely local. The localnet supports both 2KiB and 512MiB sectors and the speed of block production is configurable. For advanced features, refer to the localnet Readme .","title":"Localnet Features"},{"location":"powergate/localnet/#localnet-miners","text":"Localnet generates miners deterministically when it's started. If you run the localnet with a single miner, the miner's address will be t01000 . If you start the localnet with two miners, the addresses will be t01000 and t01001 . And so on. When running the localnet in Powergate, you can also fetch miner details from the miner API or CLI.","title":"Localnet Miners"},{"location":"powergate/localnet/#getting-started","text":"There are a few resources you'll need before you start running any nodes: Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker-enabled system but to get started, we recommend Docker Desktop and the default configurations provided. Powergate . If you run the localnet as part of the Powergate, you should get the latest version of the Powergate source code. Golang . Building the Powergate CLI from code requires that you can run commands with Go. Other sections of the tutorials below don't require Go.","title":"Getting Started"},{"location":"powergate/localnet/#localnet-with-powergate","text":"The fastest way to experiment with the Powergate CLI or API is to replace the Lotus client dependency with a running localnet. This will run the Powergate on a Lotus client connected to an embedded network of miners.","title":"Localnet with Powergate"},{"location":"powergate/localnet/#installation","text":"You can run localnet with a Powergate release or Powergate source code.","title":"Installation"},{"location":"powergate/localnet/#download-a-release","text":"Visit the latest Powergate release page and download the powergate-docker-<version>.zip release artifact. Unzip it and cd into the resulting directory: unzip powergate-docker-<version>.zip cd powergate-docker-<version>","title":"Download a release"},{"location":"powergate/localnet/#use-powergate-source-code","text":"Clone the Powergate and cd into the project's docker directory: git clone git@github.com:textileio/powergate.git cd powergate/docker","title":"Use Powergate source code"},{"location":"powergate/localnet/#setup","text":"You can now use the provided docker-compose configuration with whichever option you chose. The default setup runs Powergate connected to a localnet with 512Mib sectors. The gRPC API and CLI are available and don't need any extra config flags. \ud83c\udf8a Run the docker-compose Docker files for the Powergate are contained in the folder, /docker . make localnet Info You can set BIGSECTORS according to your needs. See the description above for more information. If you don't specify a BIGSECTORS environment variable, the default is true . On initial setup, Docker will download the required instances before any Powergate setup begins. Downloads may take a few minutes and only happen on the first run. Once running, you'll begin to see log outputs, including those of the embedded miner. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you'll have a fully functional Powergate ( powd ), a Lotus localnet, and an IPFS node wired together to start using.","title":"Setup"},{"location":"powergate/localnet/#create-a-deal-and-store-a-file","text":"The CLI and API are the same in localnet and production except that your deals will store faster and disappear when you delete the localnet.","title":"Create a deal and store a file"},{"location":"powergate/localnet/#install-the-cli","text":"You can install the CLI from a Powergate release or the source code.","title":"Install the CLI"},{"location":"powergate/localnet/#download-a-release_1","text":"Visit the latest Powergate release page and download the pow_<version>_<platform>.tar.gz file appropriate for your system. Unzip and install pow (the following example is for Unix-like systems): tar -xzvf pow_v0.1.0_darwin-amd64.tar.gz ./install Moved ./pow to /usr/local/bin Info If you're installing on macOS, there are some system permissions issue you'll have to deal with. Please follow the hub installation instructions to work around the issue.","title":"Download a release"},{"location":"powergate/localnet/#build-from-source-code","text":"From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build-pow Test your installation. pow --help","title":"Build from source code"},{"location":"powergate/localnet/#start-storing-data","text":"You're now ready to start storing and retrieving data using the Powergate. Read more on Storing Data .","title":"Start storing data"},{"location":"powergate/localnet/#localnet-with-lotus-client","text":"You can run the localnet to make use of the Lotus Client with all the benefits described in the introduction but with no Powergate or IPFS components.","title":"Localnet with Lotus Client"},{"location":"powergate/localnet/#run-from-docker-image","text":"You can run localnet with the Docker image we maintain. Running the image is just a single line. docker run --name texlocalnet -e TEXLOTUSDEVNET_SPEED = 1500 \\ -e TEXLOTUSDEVNET_BIGSECTORS = true -p 1234 :7777 \\ -v /tmp/import:/tmp/import textile/lotus-devnet After running the container, the Lotus API endpoint is available at the default port which lets you use the Lotus CLI without any extra configuration. Remember, localnets should be used as ephemeral networks, so be sure to stop and remove the texlocalnet container if you re-rerun the above command again. If you plan to use the ClientImport API or lotus client import command, your target file to import should be in the /tmp/import path on your host machine. This folder is bound to the docker image and the localnet, so the Lotus node can find it under the same path. Finally, notice that the above command doesn't specify the textile/lotus-devnet tag, so it's recommended that you consider updating your cached latest tag. Configuration parameters Above, we used the environmental variables to set the speed and bigsectors flags. The complete mapping of options are: TEXLOTUSDEVNET_SPEED : Time in milliseconds of blocks/tipset generation. TEXLOTUSDEVNET_BIGSECTORS : If true, the localnet will run on 512Mib sectors, but 2Kib otherwise. TEXLOTUSDEVNET_NUMMINERS : The number of miners in the localnet. This is an experimental feature, stable for <=3 miners. TEXLOTUSDEVNET_IPFSADDR : Optional multiaddr of an IPFS node to enable the Lotus node to be connected to an IPFS node to avoid importing deals data, and storing retrievals.","title":"Run from Docker image"},{"location":"powergate/localnet/#run-from-source-code","text":"Requirements Devnet . If you run the localnet with a stand-alone Lotus node, you should get the latest version of the localnet source code.","title":"Run from source code"},{"location":"powergate/localnet/#installation_1","text":"Clone the lotus-devnet repo and cd into the project git clone git@github.com:textileio/lotus-devnet.git cd lotus-devnet","title":"Installation"},{"location":"powergate/localnet/#setup_1","text":"Install the dependencies: make build Run the devnet with: go run main.go If you compiled a prior version of lotus-devnet , running make clean is recommended before building again. For full configuration options, see the project Readme","title":"Setup"},{"location":"powergate/mainnet/","text":"Filecoin Mainnet \u00b6 The Powergate makes it easy to run on Mainnet. Info Running a fully-synced Lotus node can take a considerable amount of time and resources. It may take over a day to sync the current chain the first time you run the Powergate. This effort is normal on live blockchain networks. Getting Started \u00b6 There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . Golang . Building the Powergate CLI from code requires Go. Other sections of the tutorials below don't need Go. Mainnet with Powergate \u00b6 Installation \u00b6 Clone the Powergate and cd into the project git clone git@github.com:textileio/powergate.git cd powergate Setup \u00b6 A default setup is available in the docker-compose configuration shipped with the Powergate. With the default setup, you'll run Powergate connected to live Filecoin Mainnet. Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . cd docker make up On initial setup, Docker will download the required instances before any Powergate setup begins. Downloads may take a few minutes and only happen on the first run. If this is the first time you're running the Powergate on the mainnet, or if you have been offline for any amount of time, you'll need to wait for the chain to properly sync. This can take over a day. Once running, you will begin to see log outputs. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you'll have a fully functional Powergate ( powd ), a Lotus node, and an IPFS node wired together to start using on the Mainnet! Bootstrap a clean Lotus node from a snapshot \u00b6 Syncing a new Lotus node from genesis can take a long time. The current mainnet network provides snapshots of the VM state every hour, which means having to sync less than 250 blocks from the tip of the chain in the worst case. Warning Bootstrapping the Lotus node from a snapshot implies complete trust in the party who generated it. This is a pragmatic solution for getting up to speed fast. Depending on your use case, you should consider the security risks of accepting snapshots from trusted parties. The snapshot described in this section is generated by Protocol Labs, the founders of Filecoin. To bootstrap a clean Lotus node from a mainnet snapshot, you should edit the docker/docker-compose.yaml in the following way: image After doing that you should: Run make up . If you inspect the Lotus node with docker logs mainnet_lotus_1 , you'll see messages describing that a snapshot is being imported with other Badger compaction messages interleaved. After the importing is done, the Lotus node will continue to sync, as usual, showing the typical logs. At this point, you should make down (you don't need to wait to full syncing), revert or comment out the added line in docker/docker-compose.yaml . And make up again. Congratulations! You're now syncing from a trusted checkpoint. Recover or prune your existing Lotus node with a snapshot \u00b6 If you run a Lotus node for a long time, its underlying chain datastore will become bigger, affecting the syncing process and possibly producing other problems. Also, if your node falls behind syncing and stays far away from the tip, it's sometimes faster to re-import a snapshot again than waiting for the syncing process to catch up. In any case, you should perform the following steps: Execute make down to shutdown your Lotus node. Execute docker run --rm -v mainnet_powergate-lotus:/data ubuntu rm -rf /data/.lotus/datastore/chain Execute the steps described in Boostrap a clean Lotus node from a snapshot . This only deletes chain data and not your wallet address and other important metadata information. Using the Powergate CLI and API on Mainnet \u00b6 All the CLI and API commands are the same as localnet. Install the CLI \u00b6 From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build Test your installation. pow --help Start storing data \u00b6 You're now ready to start storing and retrieving data using the Powergate. Read more on Storing Data .","title":"Mainnet"},{"location":"powergate/mainnet/#filecoin-mainnet","text":"The Powergate makes it easy to run on Mainnet. Info Running a fully-synced Lotus node can take a considerable amount of time and resources. It may take over a day to sync the current chain the first time you run the Powergate. This effort is normal on live blockchain networks.","title":"Filecoin Mainnet"},{"location":"powergate/mainnet/#getting-started","text":"There are a few resources you'll need before you start running any nodes. Docker Desktop . In the examples below, you'll run node instances using local Docker containers. You can do the same with any Docker enabled system, but to get started we recommend Docker Desktop and the default configurations we provide. Powergate . Golang . Building the Powergate CLI from code requires Go. Other sections of the tutorials below don't need Go.","title":"Getting Started"},{"location":"powergate/mainnet/#mainnet-with-powergate","text":"","title":"Mainnet with Powergate"},{"location":"powergate/mainnet/#installation","text":"Clone the Powergate and cd into the project git clone git@github.com:textileio/powergate.git cd powergate","title":"Installation"},{"location":"powergate/mainnet/#setup","text":"A default setup is available in the docker-compose configuration shipped with the Powergate. With the default setup, you'll run Powergate connected to live Filecoin Mainnet. Run the docker-compose Docker files for the Powergate are all contained in the folder, /docker . cd docker make up On initial setup, Docker will download the required instances before any Powergate setup begins. Downloads may take a few minutes and only happen on the first run. If this is the first time you're running the Powergate on the mainnet, or if you have been offline for any amount of time, you'll need to wait for the chain to properly sync. This can take over a day. Once running, you will begin to see log outputs. lotus_1 | 2020 -05-29T20:35:08.644Z WARN miner miner/miner.go:177 \\ mined block in the past { \"block-time\" : \"2009-01-01T04:44:30.000Z\" , \\ \"time\" : \"2020-05-29T20:35:08.644Z\" , \"duration\" : 359999438 .64444387 } When complete, you'll have a fully functional Powergate ( powd ), a Lotus node, and an IPFS node wired together to start using on the Mainnet!","title":"Setup"},{"location":"powergate/mainnet/#bootstrap-a-clean-lotus-node-from-a-snapshot","text":"Syncing a new Lotus node from genesis can take a long time. The current mainnet network provides snapshots of the VM state every hour, which means having to sync less than 250 blocks from the tip of the chain in the worst case. Warning Bootstrapping the Lotus node from a snapshot implies complete trust in the party who generated it. This is a pragmatic solution for getting up to speed fast. Depending on your use case, you should consider the security risks of accepting snapshots from trusted parties. The snapshot described in this section is generated by Protocol Labs, the founders of Filecoin. To bootstrap a clean Lotus node from a mainnet snapshot, you should edit the docker/docker-compose.yaml in the following way: image After doing that you should: Run make up . If you inspect the Lotus node with docker logs mainnet_lotus_1 , you'll see messages describing that a snapshot is being imported with other Badger compaction messages interleaved. After the importing is done, the Lotus node will continue to sync, as usual, showing the typical logs. At this point, you should make down (you don't need to wait to full syncing), revert or comment out the added line in docker/docker-compose.yaml . And make up again. Congratulations! You're now syncing from a trusted checkpoint.","title":"Bootstrap a clean Lotus node from a snapshot"},{"location":"powergate/mainnet/#recover-or-prune-your-existing-lotus-node-with-a-snapshot","text":"If you run a Lotus node for a long time, its underlying chain datastore will become bigger, affecting the syncing process and possibly producing other problems. Also, if your node falls behind syncing and stays far away from the tip, it's sometimes faster to re-import a snapshot again than waiting for the syncing process to catch up. In any case, you should perform the following steps: Execute make down to shutdown your Lotus node. Execute docker run --rm -v mainnet_powergate-lotus:/data ubuntu rm -rf /data/.lotus/datastore/chain Execute the steps described in Boostrap a clean Lotus node from a snapshot . This only deletes chain data and not your wallet address and other important metadata information.","title":"Recover or prune your existing Lotus node with a snapshot"},{"location":"powergate/mainnet/#using-the-powergate-cli-and-api-on-mainnet","text":"All the CLI and API commands are the same as localnet.","title":"Using the Powergate CLI and API on Mainnet"},{"location":"powergate/mainnet/#install-the-cli","text":"From the root of the powergate repo, you can build the CLI from the latest code. This will install the Powergate CLI, pow , on your machine. make build Test your installation. pow --help","title":"Install the CLI"},{"location":"powergate/mainnet/#start-storing-data","text":"You're now ready to start storing and retrieving data using the Powergate. Read more on Storing Data .","title":"Start storing data"},{"location":"powergate/offline/","text":"Offline deals \u00b6 The Filecoin network allows clients to create offline deals. Offline deals are the same as online deals, but they skip the data-transfer stage of the data between clients and miners. Once an offline deal is active on-chain, it would be indistinguishable from online deals regarding its data, security, or another dimension. The purpose of offline deals is to have a way between clients and miners to coordinate other data transfer mediums apart from sending the data while negotiating the deal. If you have petabytes of storage that you want to onboard in Filecoin, it might become too slow or expensive to send it through the Internet to the miners. Similarly, you might prefer to send it still using an Internet connection but coordinating in some other way or days before making the deals on-chain. If you're interested in some more in-depth explanation of offline-deals, you can read this blog post . Preparing data \u00b6 If you want to make a deal with a miner, it's necessary to prepare your data. The source of data can be: A file path to a file. A file path to a folder. A Cid which data is stored in a go-ipfs node (use --ipfs-api flag). Despite your data source, the data preparation result consist of: A CAR file: This file is the one that should be sent to miners. Piece-Size and PieceCID: these two fields are needed to propose the deal to the miner. You can use pow to do the data preparation. The relevant commands are sub-commands under pow offline : pow offline prepare pow offline car pow offline commp In most cases, only pow offline prepare will be relevant for preparing data since it does all that's needed to prepare a file/folder/Cid. The pow offline car and pow offline commp might help power-users that might want to produce only the CAR file, or calculate piece-size and piece-cid from an existing CAR file. Using pow offline prepare does the job more efficiently than pow offline car + pow offline commp . It already starts calculating piece-size and piece-cid concurrently with the CAR file generation. All commands under pow offline are 100% local and don't require talking to a Powergate daemon ( powd ), or run an go-ipfs node. Enough talking, how this works? Let's try with an example: $ pow offline prepare foo.bin foo.car > Creating data DAG... 1 .00 GiB / 1 .00 GiB [ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ] 100 .00% 423 .84 MiB p/s > DAG created in 2 .62s. > Creating CAR and calculating piece-size and PieceCID... > Created CAR file, and piece digest in 9 .82s. > Piece size: 2147483648 ( 2 .0 GiB ) > Piece CID: baga6ea4seaqgfjuol7jhui7q6onijcese57vk4slqbgqck7vleifoxdoyqrl4fy > Lotus offline-deal command: > lotus client deal --manual-piece-cid = baga6ea4seaqgfjuol7jhui7q6onijcese57vk4slqbgqck7vleifoxdoyqrl4fy --manual-piece-size = 2147483648 QmTEsmWrxvzEhhPoiMkU2tMAfhwAsVpKQ8otCuHsFtTpmM <miner> <price> <duration> $ ls -lh foo.car -rwxr-xr-x 1 ignacio ignacio 1 ,1G abr 7 10 :41 foo.car In this single command run the following happened: The file was transformed to a UnixFS DAG. This DAG gets serialized to a CAR format, and saved in out.car . We calculate the final piece-size and piece-cid for this CAR file, which is data that's needed to make the offline deal. If you would like to use this tool for scripting, the --json flag is very convenient: \u279c code pow offline prepare --json foo.bin foo.car { \"piece_size\" :2147483648, \"piece_cid\" : \"baga6ea4seaqgfjuol7jhui7q6onijcese57vk4slqbgqck7vleifoxdoyqrl4fy\" } If you want to prepare a Cid which data is already in a running go-ipfs node: \u279c pow offline prepare --ipfs-api /ip4/127.0.0.1/tcp/5001 QmdTUqgQwDgEfQee7Qwi49iXp3McDUMwh7de3wQ4Kna84t foo.car > Creating CAR and calculating piece-size and PieceCID... > Created CAR file, and piece digest in 0 .03s. > Piece size: 1048576 ( 1 .0 MiB ) > Piece CID: baga6ea4seaqj622e4qcigzdwyog3w6oqeeptjeaih5nsv55v4w72wzvh24nkefy > Lotus offline-deal command: > lotus client deal --manual-piece-cid = baga6ea4seaqj622e4qcigzdwyog3w6oqeeptjeaih5nsv55v4w72wzvh24nkefy --manual-piece-size = 1048576 QmdTUqgQwDgEfQee7Qwi49iXp3McDUMwh7de3wQ4Kna84t <miner> <price> <duration> Note that in the pow offline prepare output we already have a template for running the offline deal using a Lotus node. We'll soon add support for offline-deals in Powergate, and also add a command using the Powergate CLI. The pow offline car and pow offline commp subcommands work similarly, also having --json or --quiet flags, and supporting go-ipfs as a datasource. Filecoin batching \u00b6 The pow offline prepare CLI subcommand also supports a special mode of operation that aggregates files using a standardized spec without any extra dependencies. The way to use this mode as follows: $ pow offline prepare --json --aggregate [ folder-with-files ] [ car-output-path ] For example, say you have a folder foo that contains a list of files that you want to aggregate in a Filecoin batch: $ ls foo file.01 file.02 file.03 file.04 file.05 file.06 file.07 file.08 file.09 file.10 file.11 file.12 file.13 file.14 file.15 Now we run the command: $ pow offline prepare --json --aggregate foo myfoo.car 2 > & 1 | jq . { \"payload_cid\" : \"bafybeiehczj2ykdgttv4l3lvwkojxgdatvnze32sf44gg44pi4pnajlle4\" , \"piece_size\" : 1048576 , \"piece_cid\" : \"baga6ea4seaqgio3tohbma6ntoczzxl2qtcicmoio3axacndqoibym4klq5q6qly\" , \"files\" : [ { \"name\" : \"foo/file.01\" , \"Cid\" : \"QmQ9KtzTJz25YLn7sZTpAZTmbVGRnDPt2FKgT68drdPv3K\" } , { \"name\" : \"foo/file.02\" , \"Cid\" : \"QmQGPnRANZRQXonSR4N1YtrgQFHnQ29SfSfjYANGEDetqF\" } , { \"name\" : \"foo/file.03\" , \"Cid\" : \"QmcSJovnWD4qJFyBvJwJE9VhMn2MSf9CY2BjwqYsFgc4iM\" } , { \"name\" : \"foo/file.04\" , \"Cid\" : \"QmVB98xQUikGF6wjzujFL9ihK7hYHUQ3Uyac36iPJxBqQk\" } , { \"name\" : \"foo/file.05\" , \"Cid\" : \"QmR18QQizM8XXvvSVJBgjyj7WFNWkXWrsKF5mjusjmHvA8\" } , { \"name\" : \"foo/file.06\" , \"Cid\" : \"QmYJ6pDDcwhHf2a32fQjTHuJ5TiQGMKqbZasmPsB8VeQwx\" } , { \"name\" : \"foo/file.07\" , \"Cid\" : \"QmWBttk99EoYuQPL2GfMQ1PZXyc8eHujeggzax766mmQB3\" } , { \"name\" : \"foo/file.08\" , \"Cid\" : \"QmVUUNqkcpxcNNyTKSu5bJ9G5FJcEWrxUk9oxHB9usc2LD\" } , { \"name\" : \"foo/file.09\" , \"Cid\" : \"QmTcpKyPkCSn8HaLpGF4Xbf7trmRSBrNL9bBra6gx28qcc\" } , { \"name\" : \"foo/file.10\" , \"Cid\" : \"QmXj9nsbbSuToJaYMenJrP7ZbspJufxqKWoLneW9YxrZ12\" } , { \"name\" : \"foo/file.11\" , \"Cid\" : \"QmPDdrp8ZsiSQ4oXdVnGb1KTVK4FHsnxrHC1QYFAQrSDN7\" } , { \"name\" : \"foo/file.12\" , \"Cid\" : \"QmQGoUbriJQkFRQmvaUQSwLSVGzYGZJXq2K4Hkk9DFoZzp\" } , { \"name\" : \"foo/file.13\" , \"Cid\" : \"QmNuYjKiXitEVvdPG6Tfe99ZUSiSPi697cQaueGbRR7Dwy\" } , { \"name\" : \"foo/file.14\" , \"Cid\" : \"QmeU2EZpBrapKYYuzdEW21JRZMB1Qk7a38RpEzj7D4qPnT\" } , { \"name\" : \"foo/file.15\" , \"Cid\" : \"Qmbo7ysDSNonRpx1ZxU7yvEMrbS87dPo9yy3DNBeKrnW8U\" } ] } The command does some magic for you: It DAGifies each file in the foo folder as a UnixFS file. It creates a Filecoin batch as described by the spec, resulting in a single UnixFS batch. It generates a CAR file of this UnixFS batch. It calculates the PieceCid and PieceSize of the CAR file. Let's see some generated files in the current folder: $ ls foo myfoo.car myfoo.car.manifest The output of the command is: It creates the foo.car file. It creates the foo.car.manifest file, which is the @AggregateManifest.ndjson manifest file that's also inside the UnixFS batch. It prints to stdout: The PayloadCid of the UnixFS batch. The calculated PieceCid The calculated PieceSize The generated Cid of the processed files. The JSON output allows you to reference the corresponding entry of each file in foo into the manifest of batch. In addition, the manifest contains information that will allow making retrievals of individual files for deals made with the generated batch CAR file. We'll explain soon how to do retrievals whenever this feature is ready in the Lotus client; stay tuned!","title":"Offline Deals"},{"location":"powergate/offline/#offline-deals","text":"The Filecoin network allows clients to create offline deals. Offline deals are the same as online deals, but they skip the data-transfer stage of the data between clients and miners. Once an offline deal is active on-chain, it would be indistinguishable from online deals regarding its data, security, or another dimension. The purpose of offline deals is to have a way between clients and miners to coordinate other data transfer mediums apart from sending the data while negotiating the deal. If you have petabytes of storage that you want to onboard in Filecoin, it might become too slow or expensive to send it through the Internet to the miners. Similarly, you might prefer to send it still using an Internet connection but coordinating in some other way or days before making the deals on-chain. If you're interested in some more in-depth explanation of offline-deals, you can read this blog post .","title":"Offline deals"},{"location":"powergate/offline/#preparing-data","text":"If you want to make a deal with a miner, it's necessary to prepare your data. The source of data can be: A file path to a file. A file path to a folder. A Cid which data is stored in a go-ipfs node (use --ipfs-api flag). Despite your data source, the data preparation result consist of: A CAR file: This file is the one that should be sent to miners. Piece-Size and PieceCID: these two fields are needed to propose the deal to the miner. You can use pow to do the data preparation. The relevant commands are sub-commands under pow offline : pow offline prepare pow offline car pow offline commp In most cases, only pow offline prepare will be relevant for preparing data since it does all that's needed to prepare a file/folder/Cid. The pow offline car and pow offline commp might help power-users that might want to produce only the CAR file, or calculate piece-size and piece-cid from an existing CAR file. Using pow offline prepare does the job more efficiently than pow offline car + pow offline commp . It already starts calculating piece-size and piece-cid concurrently with the CAR file generation. All commands under pow offline are 100% local and don't require talking to a Powergate daemon ( powd ), or run an go-ipfs node. Enough talking, how this works? Let's try with an example: $ pow offline prepare foo.bin foo.car > Creating data DAG... 1 .00 GiB / 1 .00 GiB [ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ] 100 .00% 423 .84 MiB p/s > DAG created in 2 .62s. > Creating CAR and calculating piece-size and PieceCID... > Created CAR file, and piece digest in 9 .82s. > Piece size: 2147483648 ( 2 .0 GiB ) > Piece CID: baga6ea4seaqgfjuol7jhui7q6onijcese57vk4slqbgqck7vleifoxdoyqrl4fy > Lotus offline-deal command: > lotus client deal --manual-piece-cid = baga6ea4seaqgfjuol7jhui7q6onijcese57vk4slqbgqck7vleifoxdoyqrl4fy --manual-piece-size = 2147483648 QmTEsmWrxvzEhhPoiMkU2tMAfhwAsVpKQ8otCuHsFtTpmM <miner> <price> <duration> $ ls -lh foo.car -rwxr-xr-x 1 ignacio ignacio 1 ,1G abr 7 10 :41 foo.car In this single command run the following happened: The file was transformed to a UnixFS DAG. This DAG gets serialized to a CAR format, and saved in out.car . We calculate the final piece-size and piece-cid for this CAR file, which is data that's needed to make the offline deal. If you would like to use this tool for scripting, the --json flag is very convenient: \u279c code pow offline prepare --json foo.bin foo.car { \"piece_size\" :2147483648, \"piece_cid\" : \"baga6ea4seaqgfjuol7jhui7q6onijcese57vk4slqbgqck7vleifoxdoyqrl4fy\" } If you want to prepare a Cid which data is already in a running go-ipfs node: \u279c pow offline prepare --ipfs-api /ip4/127.0.0.1/tcp/5001 QmdTUqgQwDgEfQee7Qwi49iXp3McDUMwh7de3wQ4Kna84t foo.car > Creating CAR and calculating piece-size and PieceCID... > Created CAR file, and piece digest in 0 .03s. > Piece size: 1048576 ( 1 .0 MiB ) > Piece CID: baga6ea4seaqj622e4qcigzdwyog3w6oqeeptjeaih5nsv55v4w72wzvh24nkefy > Lotus offline-deal command: > lotus client deal --manual-piece-cid = baga6ea4seaqj622e4qcigzdwyog3w6oqeeptjeaih5nsv55v4w72wzvh24nkefy --manual-piece-size = 1048576 QmdTUqgQwDgEfQee7Qwi49iXp3McDUMwh7de3wQ4Kna84t <miner> <price> <duration> Note that in the pow offline prepare output we already have a template for running the offline deal using a Lotus node. We'll soon add support for offline-deals in Powergate, and also add a command using the Powergate CLI. The pow offline car and pow offline commp subcommands work similarly, also having --json or --quiet flags, and supporting go-ipfs as a datasource.","title":"Preparing data"},{"location":"powergate/offline/#filecoin-batching","text":"The pow offline prepare CLI subcommand also supports a special mode of operation that aggregates files using a standardized spec without any extra dependencies. The way to use this mode as follows: $ pow offline prepare --json --aggregate [ folder-with-files ] [ car-output-path ] For example, say you have a folder foo that contains a list of files that you want to aggregate in a Filecoin batch: $ ls foo file.01 file.02 file.03 file.04 file.05 file.06 file.07 file.08 file.09 file.10 file.11 file.12 file.13 file.14 file.15 Now we run the command: $ pow offline prepare --json --aggregate foo myfoo.car 2 > & 1 | jq . { \"payload_cid\" : \"bafybeiehczj2ykdgttv4l3lvwkojxgdatvnze32sf44gg44pi4pnajlle4\" , \"piece_size\" : 1048576 , \"piece_cid\" : \"baga6ea4seaqgio3tohbma6ntoczzxl2qtcicmoio3axacndqoibym4klq5q6qly\" , \"files\" : [ { \"name\" : \"foo/file.01\" , \"Cid\" : \"QmQ9KtzTJz25YLn7sZTpAZTmbVGRnDPt2FKgT68drdPv3K\" } , { \"name\" : \"foo/file.02\" , \"Cid\" : \"QmQGPnRANZRQXonSR4N1YtrgQFHnQ29SfSfjYANGEDetqF\" } , { \"name\" : \"foo/file.03\" , \"Cid\" : \"QmcSJovnWD4qJFyBvJwJE9VhMn2MSf9CY2BjwqYsFgc4iM\" } , { \"name\" : \"foo/file.04\" , \"Cid\" : \"QmVB98xQUikGF6wjzujFL9ihK7hYHUQ3Uyac36iPJxBqQk\" } , { \"name\" : \"foo/file.05\" , \"Cid\" : \"QmR18QQizM8XXvvSVJBgjyj7WFNWkXWrsKF5mjusjmHvA8\" } , { \"name\" : \"foo/file.06\" , \"Cid\" : \"QmYJ6pDDcwhHf2a32fQjTHuJ5TiQGMKqbZasmPsB8VeQwx\" } , { \"name\" : \"foo/file.07\" , \"Cid\" : \"QmWBttk99EoYuQPL2GfMQ1PZXyc8eHujeggzax766mmQB3\" } , { \"name\" : \"foo/file.08\" , \"Cid\" : \"QmVUUNqkcpxcNNyTKSu5bJ9G5FJcEWrxUk9oxHB9usc2LD\" } , { \"name\" : \"foo/file.09\" , \"Cid\" : \"QmTcpKyPkCSn8HaLpGF4Xbf7trmRSBrNL9bBra6gx28qcc\" } , { \"name\" : \"foo/file.10\" , \"Cid\" : \"QmXj9nsbbSuToJaYMenJrP7ZbspJufxqKWoLneW9YxrZ12\" } , { \"name\" : \"foo/file.11\" , \"Cid\" : \"QmPDdrp8ZsiSQ4oXdVnGb1KTVK4FHsnxrHC1QYFAQrSDN7\" } , { \"name\" : \"foo/file.12\" , \"Cid\" : \"QmQGoUbriJQkFRQmvaUQSwLSVGzYGZJXq2K4Hkk9DFoZzp\" } , { \"name\" : \"foo/file.13\" , \"Cid\" : \"QmNuYjKiXitEVvdPG6Tfe99ZUSiSPi697cQaueGbRR7Dwy\" } , { \"name\" : \"foo/file.14\" , \"Cid\" : \"QmeU2EZpBrapKYYuzdEW21JRZMB1Qk7a38RpEzj7D4qPnT\" } , { \"name\" : \"foo/file.15\" , \"Cid\" : \"Qmbo7ysDSNonRpx1ZxU7yvEMrbS87dPo9yy3DNBeKrnW8U\" } ] } The command does some magic for you: It DAGifies each file in the foo folder as a UnixFS file. It creates a Filecoin batch as described by the spec, resulting in a single UnixFS batch. It generates a CAR file of this UnixFS batch. It calculates the PieceCid and PieceSize of the CAR file. Let's see some generated files in the current folder: $ ls foo myfoo.car myfoo.car.manifest The output of the command is: It creates the foo.car file. It creates the foo.car.manifest file, which is the @AggregateManifest.ndjson manifest file that's also inside the UnixFS batch. It prints to stdout: The PayloadCid of the UnixFS batch. The calculated PieceCid The calculated PieceSize The generated Cid of the processed files. The JSON output allows you to reference the corresponding entry of each file in foo into the manifest of batch. In addition, the manifest contains information that will allow making retrievals of individual files for deals made with the generated batch CAR file. We'll explain soon how to do retrievals whenever this feature is ready in the Lotus client; stay tuned!","title":"Filecoin batching"},{"location":"powergate/storage/","text":"Storing Data \u00b6 The Powergate API leverages the concept of a user . On IPFS, the ability to: Store and retrieve data. Track long-term deals on Filecoin. Persist data on Filecoin. Is managed through and scoped to a user . Users can: Manage the necessary state and capabilities. Provide multi-tiered file storage. Intro to Users \u00b6 Users are associated with one or more Filecoin wallet addresses. You can use the Powergate admin API to create a new user. The Powergate will then: Create a new default wallet address for the user. You can configure the Powergate to automatically fund new wallets from a master address. Create a new API token linked to the user. Enable use of the user through the supplied token. Almost all Powergate APIs rely on the user, including the CLI, so you'll need to supply the token to indicate which user your requests are targeting. Since each user has its own address, it has its own balance and therefore limits on the Filecoin network. Warning If you're providing a --lotusmasteraddr and --walletinitialfund , be sure that address exists in the Lotus node and has enough funds, since walletinitialfund attoFILs will be sent from there to fund from newly created users. Both flags are optional, and if not present, there won't be any auto-funding transaction, so you're responsible to fund wallet addresses of new users. Multi-tiered design \u00b6 Powergate provides you API access to a multi-tiered storage system built on IPFS and Filecoin. In many places, we refer to these two tiers of storage as Hot (IPFS) and Cold (Filecoin). This mirrors multi-tiered storage often deployed with a hot storage layer in memory and a cold storage layer on disk . Hot storage layer \u00b6 Data stored in the Powergate hot layer is available to the IPFS network (or private network). Hot storage is designed to be fast and available on the IPFS network (private or public DHT). Data stored with hot enabled is pinned to the Powergate's IPFS node. If Hot Storage is disabled, the IPFS node is still used as transient storage for data in Filecoin. This data will still exist in the IPFS node until a garbage collection runs, so you might benefit from temporal hot storage for retrievals even if you don't have Hot Storage enabled. Cold storage layer \u00b6 Data stored in the Powergate Cold layer is stored by miners on the Filecoin network (localnet or mainnet). You can use the StorageConfig to configure many properties of the Cold storage layer per file you store, such as where, how many copies, and how long to store the file. Moving between tiers \u00b6 Hot to Cold \u00b6 The most common scenario is where data is stored initially with cold disabled and later a new StorageConfig is pushed that enables cold storage. In this scenario, Powergate will resolve the file from the hot layer, and create any newly required Filecoin deals to fulfill. Cold to Hot \u00b6 Data stored only in the cold layer isn't guaranteed to be available on the IPFS network. For it to be available, you need to push a new storage config that enables hot storage. You can automate this movement using the AllowUnfreeze flag of the StorageConfig . Either way, Powergate will always attempt to resolve the data first by trying to fetch it from the IPFS network. If unable to do that, Powergate will execute a retrieval deal to pull the data from Filecoin. Finally, the data will be pinned in hot layer IPFS storage and available on the IPFS network. Read more about updating the StorageConfig here . Using Powergate to store data \u00b6 To start using most Powergate APIs, you must first create a user . Create a user \u00b6 Using the Powergate CLI admin commands, you can create a new user easily. pow admin user create Success { \"user\" : { \"id\" : \"0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4\" , \"token\" : \"883f57b1-4e66-47f8-b291-7cf8b10f6370\" } } Add environmental variable (optional) The --token is used to scope the requests to the user we created. You can skip setting the --token flag on every command by adding your new token as an environmental variable. For the rest of the examples, we'll assume you've set this environmental variable. export POW_TOKEN = 883f57b1-4e66-47f8-b291-7cf8b10f6370 Make data available \u00b6 Powergate requires stored data to be available over IPFS. If you're using the CLI, you can ensure it's available by staging it on IPFS using stage . Note that stage does not store your data in the Powergate. It's an optional step that caches your data to ensure it's available on IPFS before being stored in Powergate. This is technically equivalent to ipfs add --pin=false , which is adding data without pinning it. pow data stage <path/filename> Success { \"cid\" : \"<cid>\" } Info If data exists on the IPFS network, you don't need to run stage as the Powergate will automatically fetch that data from remote peers. Initiate storage \u00b6 The Powergate manages stored files based on the setup defined in a StorageConfig . For Powergate to manage a new file by moving it from the cached state created above, to the Hot and/or Cold layers, we must apply a new StorageConfig for the CID we generated above. Every user has a default StorageConfig that will be used for every new deal unless overridden. pow config apply --watch <cid> Success { \"jobId\" : \"b4110048-5367-4ae5-8508-709bf7969748\" } JOB ID | STATUS | MINER | PRICE | DEAL STATUS ---------------------------------------+----------------------+--------+----------+-------------------- 70368cda-d65a-4e11-8a9f-fbf36135f563 | JOB_STATUS_EXECUTING | | | When complete, you should see, Success JOB ID | STATUS | MINER | PRICE | DEAL STATUS ---------------------------------------+--------------------+--------+----------+-------------------- b4110048-5367-4ae5-8508-709bf7969748 | JOB_STATUS_SUCCESS | | | | | f01000 | 62500000 | StorageDealActive Info Powergate is configured by default to run up to 50 pushes in parallel, though you can update this setting as needed. Read more about the design here . Storage Job Watch The status will update as the deal progresses. If you apply a storage config without the --watch flag, you can check the progress later using, watch . pow storage-job watch <jobid> Retrieve files \u00b6 Finally, you can verify that the file was stored on the network by making a request to get it back out. pow data get <cid> myfile2 Success Success! Data written to myfile2 Warning If you interact directly with the IPFS node, do not ever manually modify the pinset. The Powergate requires full control over the pinset since it's required when users specify HotStorage.Enabled=true . Manually interacting with the IPFS node's pinset could lead to unexpected behavior in the Powergate. Miner selection \u00b6 Powergate has many internal components that are used to simplify the process of using Filecoin. One set of components are the Powergate's indexes, where it collects information about miners including, power, sector size, storage ask price, etc. With that information, the Powergate can create a reasonable ranking of miners. Miners that are most promising for making deals will show up at the top. When storing data in cold storage, Powergate will use this information to automate finding miners and initiating deals. You can use the StorageConfig to help direct the Powergate to miners that match your particular requirements. Learn more \u00b6 Powergate does a lot of work out of the box. If you'd like to learn more about the components, design, and capabilities of Powergate, we encourage you to read the FFS Design document which gets into more of the technical detail behind Powergate's API.","title":"Storing Data"},{"location":"powergate/storage/#storing-data","text":"The Powergate API leverages the concept of a user . On IPFS, the ability to: Store and retrieve data. Track long-term deals on Filecoin. Persist data on Filecoin. Is managed through and scoped to a user . Users can: Manage the necessary state and capabilities. Provide multi-tiered file storage.","title":"Storing Data"},{"location":"powergate/storage/#intro-to-users","text":"Users are associated with one or more Filecoin wallet addresses. You can use the Powergate admin API to create a new user. The Powergate will then: Create a new default wallet address for the user. You can configure the Powergate to automatically fund new wallets from a master address. Create a new API token linked to the user. Enable use of the user through the supplied token. Almost all Powergate APIs rely on the user, including the CLI, so you'll need to supply the token to indicate which user your requests are targeting. Since each user has its own address, it has its own balance and therefore limits on the Filecoin network. Warning If you're providing a --lotusmasteraddr and --walletinitialfund , be sure that address exists in the Lotus node and has enough funds, since walletinitialfund attoFILs will be sent from there to fund from newly created users. Both flags are optional, and if not present, there won't be any auto-funding transaction, so you're responsible to fund wallet addresses of new users.","title":"Intro to Users"},{"location":"powergate/storage/#multi-tiered-design","text":"Powergate provides you API access to a multi-tiered storage system built on IPFS and Filecoin. In many places, we refer to these two tiers of storage as Hot (IPFS) and Cold (Filecoin). This mirrors multi-tiered storage often deployed with a hot storage layer in memory and a cold storage layer on disk .","title":"Multi-tiered design"},{"location":"powergate/storage/#hot-storage-layer","text":"Data stored in the Powergate hot layer is available to the IPFS network (or private network). Hot storage is designed to be fast and available on the IPFS network (private or public DHT). Data stored with hot enabled is pinned to the Powergate's IPFS node. If Hot Storage is disabled, the IPFS node is still used as transient storage for data in Filecoin. This data will still exist in the IPFS node until a garbage collection runs, so you might benefit from temporal hot storage for retrievals even if you don't have Hot Storage enabled.","title":"Hot storage layer"},{"location":"powergate/storage/#cold-storage-layer","text":"Data stored in the Powergate Cold layer is stored by miners on the Filecoin network (localnet or mainnet). You can use the StorageConfig to configure many properties of the Cold storage layer per file you store, such as where, how many copies, and how long to store the file.","title":"Cold storage layer"},{"location":"powergate/storage/#moving-between-tiers","text":"","title":"Moving between tiers"},{"location":"powergate/storage/#hot-to-cold","text":"The most common scenario is where data is stored initially with cold disabled and later a new StorageConfig is pushed that enables cold storage. In this scenario, Powergate will resolve the file from the hot layer, and create any newly required Filecoin deals to fulfill.","title":"Hot to Cold"},{"location":"powergate/storage/#cold-to-hot","text":"Data stored only in the cold layer isn't guaranteed to be available on the IPFS network. For it to be available, you need to push a new storage config that enables hot storage. You can automate this movement using the AllowUnfreeze flag of the StorageConfig . Either way, Powergate will always attempt to resolve the data first by trying to fetch it from the IPFS network. If unable to do that, Powergate will execute a retrieval deal to pull the data from Filecoin. Finally, the data will be pinned in hot layer IPFS storage and available on the IPFS network. Read more about updating the StorageConfig here .","title":"Cold to Hot"},{"location":"powergate/storage/#using-powergate-to-store-data","text":"To start using most Powergate APIs, you must first create a user .","title":"Using Powergate to store data"},{"location":"powergate/storage/#create-a-user","text":"Using the Powergate CLI admin commands, you can create a new user easily. pow admin user create Success { \"user\" : { \"id\" : \"0ac0fb4d-581c-4276-bd90-a9aa30dd4cb4\" , \"token\" : \"883f57b1-4e66-47f8-b291-7cf8b10f6370\" } } Add environmental variable (optional) The --token is used to scope the requests to the user we created. You can skip setting the --token flag on every command by adding your new token as an environmental variable. For the rest of the examples, we'll assume you've set this environmental variable. export POW_TOKEN = 883f57b1-4e66-47f8-b291-7cf8b10f6370","title":"Create a user"},{"location":"powergate/storage/#make-data-available","text":"Powergate requires stored data to be available over IPFS. If you're using the CLI, you can ensure it's available by staging it on IPFS using stage . Note that stage does not store your data in the Powergate. It's an optional step that caches your data to ensure it's available on IPFS before being stored in Powergate. This is technically equivalent to ipfs add --pin=false , which is adding data without pinning it. pow data stage <path/filename> Success { \"cid\" : \"<cid>\" } Info If data exists on the IPFS network, you don't need to run stage as the Powergate will automatically fetch that data from remote peers.","title":"Make data available"},{"location":"powergate/storage/#initiate-storage","text":"The Powergate manages stored files based on the setup defined in a StorageConfig . For Powergate to manage a new file by moving it from the cached state created above, to the Hot and/or Cold layers, we must apply a new StorageConfig for the CID we generated above. Every user has a default StorageConfig that will be used for every new deal unless overridden. pow config apply --watch <cid> Success { \"jobId\" : \"b4110048-5367-4ae5-8508-709bf7969748\" } JOB ID | STATUS | MINER | PRICE | DEAL STATUS ---------------------------------------+----------------------+--------+----------+-------------------- 70368cda-d65a-4e11-8a9f-fbf36135f563 | JOB_STATUS_EXECUTING | | | When complete, you should see, Success JOB ID | STATUS | MINER | PRICE | DEAL STATUS ---------------------------------------+--------------------+--------+----------+-------------------- b4110048-5367-4ae5-8508-709bf7969748 | JOB_STATUS_SUCCESS | | | | | f01000 | 62500000 | StorageDealActive Info Powergate is configured by default to run up to 50 pushes in parallel, though you can update this setting as needed. Read more about the design here . Storage Job Watch The status will update as the deal progresses. If you apply a storage config without the --watch flag, you can check the progress later using, watch . pow storage-job watch <jobid>","title":"Initiate storage"},{"location":"powergate/storage/#retrieve-files","text":"Finally, you can verify that the file was stored on the network by making a request to get it back out. pow data get <cid> myfile2 Success Success! Data written to myfile2 Warning If you interact directly with the IPFS node, do not ever manually modify the pinset. The Powergate requires full control over the pinset since it's required when users specify HotStorage.Enabled=true . Manually interacting with the IPFS node's pinset could lead to unexpected behavior in the Powergate.","title":"Retrieve files"},{"location":"powergate/storage/#miner-selection","text":"Powergate has many internal components that are used to simplify the process of using Filecoin. One set of components are the Powergate's indexes, where it collects information about miners including, power, sector size, storage ask price, etc. With that information, the Powergate can create a reasonable ranking of miners. Miners that are most promising for making deals will show up at the top. When storing data in cold storage, Powergate will use this information to automate finding miners and initiating deals. You can use the StorageConfig to help direct the Powergate to miners that match your particular requirements.","title":"Miner selection"},{"location":"powergate/storage/#learn-more","text":"Powergate does a lot of work out of the box. If you'd like to learn more about the components, design, and capabilities of Powergate, we encourage you to read the FFS Design document which gets into more of the technical detail behind Powergate's API.","title":"Learn more"},{"location":"powergate/storageconfig/","text":"Managing Storage with the StorageConfig \u00b6 Every user can manage how data is stored on IPFS and Filecoin using the StorageConfig ( details below ). The StorageConfig is a powerful tool for: Customizing the details about storing data on Filecoin. Making it available over IPFS. Enforcing replication. Managing expiring deals. And more. Setting the StorageConfig \u00b6 In every Powergate deployment, there are three ways to manage StorageConfigs throughout the system. The user default StorageConfig. This is initially set by the system default StorageConfig. It can be modified by the user after creation. The storage request StorageConfig. This will use the user default, but a custom StorageConfig can also be supplied during the request. A storage update StorageConfig. Any StorageConfigs attached to existing stored data can be updated with a new StorageConfig. Powergate will then work to modify the way data is stored to match the new configuration. Get the default StorageConfig of a user \u00b6 View the current default StorageConfig of a user. pow config default -t <token> Set the default StorageConfig of a user \u00b6 To set the default StorageConfig to one stored in new-config.json . pow config set-default new-config.json -t <token> Set a custom StorageConfig at storage time \u00b6 You can provide a flag ( -c ) to include a custom StorageConfig for a new storage request. Storage requests without a custom StorageConfig will use the instance default storage config. pow config apply <cid> -t <token> -c custom-config.json Get information about a previously stored cid \u00b6 To pull the StorageConfig and information about the associated storage jobs, use the of the stored data. pow data info <cid> -t <token> Update the StorageConfig of existing data \u00b6 To update the StorageConfig of data already stored and managed by the Powergate user, use a new config stored in updated-config.json . This command requires the override flag ( -o ) to confirm that you understand that the command will replace an existing config. pow config apply <cid> -t <token> -o -c updated-config.json StorageConfig Details \u00b6 Here is an example of the default StorageConfig . { // hot has this desired storing configuration in Hot Storage. \"hot\" : { // enabled indicates if Cid data is stored. If true, it will // consider further configurations to execute actions. \"enabled\" : true , // allowUnfreeze indicates that if data isn't available in the // Hot Storage, it's allowed to be feeded by Cold Storage if // available. \"allowUnfreeze\" : false , // ipfs configured ipfs behavior for hot storage \"ipfs\" : { // addTimeout is an upper bound on adding data to IPFS node from // the network before failing. \"addTimeout\" : 30 } }, // cold has desired storing configuration in the Cold Storage. \"cold\" : { // enabled indicates that data will be saved in Cold storage. // If is switched from false->true, it will consider the other // attributes as the desired state of the data in this Storage. \"enabled\" : true , // filecoin describes the desired Filecoin configuration for a // Cid in the Filecoin network. \"filecoin\" : { // repFactor indicates the desired amount of active deals // with different miners to store the data. While making deals // the other attributes of FilConfig are considered for miner // selection. \"repFactor\" : 1 , // dealMinDuration indicates the minimum duration to be used when making // new deals. \"dealMinDuration\" : 1000 , // excludedMiners is a set of miner addresses won't be ever be // selected when making new deals, even if they comply to other // filters. \"excludedMiners\" : [], // trustedMiners is a set of miner addresses which will be // forcibly used when making new deals. An empty/nil list // disables this feature. \"trustedMiners\" : [], // countryCodes indicates that new deals should select miners // on specific countries. \"countryCodes\" : [], // renew indicates deal-renewal configuration. \"renew\" : { // enabled indicates that deal-renewal is enabled for this // Cid. \"enabled\" : false , // threshold indicates how many epochs before expiring should // trigger deal renewal. e.g: 100 epoch before expiring. \"threshold\" : 0 }, // addr is the wallet address used to store the data in filecoin \"addr\" : \"<unique>\" , // maxPrice is the maximum price that will be spent per RepFactor // to store the data in units of attoFIL per GiB per epoch \"maxPrice\" : 0 , // fastRetrieval indicates that created deals should enable the // fast retrieval feature. \"fastRetrieval\" : true , // dealStartOffset indicates how many epochs in the future impose a // deadline to new deals being active on-chain. This value might influence // if miners accept deals, since they should seal fast enough to satisfy // this constraint. \"dealStartOffset\" : 8640 , // Equivalent to 72 hours // verifiedDeal indicates that new deals will be verified-deals, using // available data-cap from the wallet address. \"verifiedDeal\" : false } }, // If true, Powergate will detect if the data is no longer // stored according to the StorageConfig requirements and // make new storage arrangements that match the StorageConfig \"repairable\" : false }","title":"Storage Configs"},{"location":"powergate/storageconfig/#managing-storage-with-the-storageconfig","text":"Every user can manage how data is stored on IPFS and Filecoin using the StorageConfig ( details below ). The StorageConfig is a powerful tool for: Customizing the details about storing data on Filecoin. Making it available over IPFS. Enforcing replication. Managing expiring deals. And more.","title":"Managing Storage with the StorageConfig"},{"location":"powergate/storageconfig/#setting-the-storageconfig","text":"In every Powergate deployment, there are three ways to manage StorageConfigs throughout the system. The user default StorageConfig. This is initially set by the system default StorageConfig. It can be modified by the user after creation. The storage request StorageConfig. This will use the user default, but a custom StorageConfig can also be supplied during the request. A storage update StorageConfig. Any StorageConfigs attached to existing stored data can be updated with a new StorageConfig. Powergate will then work to modify the way data is stored to match the new configuration.","title":"Setting the StorageConfig"},{"location":"powergate/storageconfig/#get-the-default-storageconfig-of-a-user","text":"View the current default StorageConfig of a user. pow config default -t <token>","title":"Get the default StorageConfig of a user"},{"location":"powergate/storageconfig/#set-the-default-storageconfig-of-a-user","text":"To set the default StorageConfig to one stored in new-config.json . pow config set-default new-config.json -t <token>","title":"Set the default StorageConfig of a user"},{"location":"powergate/storageconfig/#set-a-custom-storageconfig-at-storage-time","text":"You can provide a flag ( -c ) to include a custom StorageConfig for a new storage request. Storage requests without a custom StorageConfig will use the instance default storage config. pow config apply <cid> -t <token> -c custom-config.json","title":"Set a custom StorageConfig at storage time"},{"location":"powergate/storageconfig/#get-information-about-a-previously-stored-cid","text":"To pull the StorageConfig and information about the associated storage jobs, use the of the stored data. pow data info <cid> -t <token>","title":"Get information about a previously stored cid"},{"location":"powergate/storageconfig/#update-the-storageconfig-of-existing-data","text":"To update the StorageConfig of data already stored and managed by the Powergate user, use a new config stored in updated-config.json . This command requires the override flag ( -o ) to confirm that you understand that the command will replace an existing config. pow config apply <cid> -t <token> -o -c updated-config.json","title":"Update the StorageConfig of existing data"},{"location":"powergate/storageconfig/#storageconfig-details","text":"Here is an example of the default StorageConfig . { // hot has this desired storing configuration in Hot Storage. \"hot\" : { // enabled indicates if Cid data is stored. If true, it will // consider further configurations to execute actions. \"enabled\" : true , // allowUnfreeze indicates that if data isn't available in the // Hot Storage, it's allowed to be feeded by Cold Storage if // available. \"allowUnfreeze\" : false , // ipfs configured ipfs behavior for hot storage \"ipfs\" : { // addTimeout is an upper bound on adding data to IPFS node from // the network before failing. \"addTimeout\" : 30 } }, // cold has desired storing configuration in the Cold Storage. \"cold\" : { // enabled indicates that data will be saved in Cold storage. // If is switched from false->true, it will consider the other // attributes as the desired state of the data in this Storage. \"enabled\" : true , // filecoin describes the desired Filecoin configuration for a // Cid in the Filecoin network. \"filecoin\" : { // repFactor indicates the desired amount of active deals // with different miners to store the data. While making deals // the other attributes of FilConfig are considered for miner // selection. \"repFactor\" : 1 , // dealMinDuration indicates the minimum duration to be used when making // new deals. \"dealMinDuration\" : 1000 , // excludedMiners is a set of miner addresses won't be ever be // selected when making new deals, even if they comply to other // filters. \"excludedMiners\" : [], // trustedMiners is a set of miner addresses which will be // forcibly used when making new deals. An empty/nil list // disables this feature. \"trustedMiners\" : [], // countryCodes indicates that new deals should select miners // on specific countries. \"countryCodes\" : [], // renew indicates deal-renewal configuration. \"renew\" : { // enabled indicates that deal-renewal is enabled for this // Cid. \"enabled\" : false , // threshold indicates how many epochs before expiring should // trigger deal renewal. e.g: 100 epoch before expiring. \"threshold\" : 0 }, // addr is the wallet address used to store the data in filecoin \"addr\" : \"<unique>\" , // maxPrice is the maximum price that will be spent per RepFactor // to store the data in units of attoFIL per GiB per epoch \"maxPrice\" : 0 , // fastRetrieval indicates that created deals should enable the // fast retrieval feature. \"fastRetrieval\" : true , // dealStartOffset indicates how many epochs in the future impose a // deadline to new deals being active on-chain. This value might influence // if miners accept deals, since they should seal fast enough to satisfy // this constraint. \"dealStartOffset\" : 8640 , // Equivalent to 72 hours // verifiedDeal indicates that new deals will be verified-deals, using // available data-cap from the wallet address. \"verifiedDeal\" : false } }, // If true, Powergate will detect if the data is no longer // stored according to the StorageConfig requirements and // make new storage arrangements that match the StorageConfig \"repairable\" : false }","title":"StorageConfig Details"},{"location":"powergate/cli/pow/","text":"pow \u00b6 A client for storage and retreival of powergate data Synopsis \u00b6 A client for storage and retreival of powergate data pow [flags] Options \u00b6 -h, --help help for pow --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token -v, --version display version information for pow and the connected server SEE ALSO \u00b6 pow admin - Provides admin commands pow config - Provides commands to interact with cid storage configs pow data - Provides commands to interact with general data APIs pow deals - Provides commands to view Filecoin deal information pow id - Returns the user id pow storage-info - Provides commands to get and query cid storage info. pow storage-jobs - Provides commands to query for storage jobs in various states pow version - Display version information for pow and the connected server pow wallet - Provides commands about filecoin wallets","title":"Overview"},{"location":"powergate/cli/pow/#pow","text":"A client for storage and retreival of powergate data","title":"pow"},{"location":"powergate/cli/pow/#synopsis","text":"A client for storage and retreival of powergate data pow [flags]","title":"Synopsis"},{"location":"powergate/cli/pow/#options","text":"-h, --help help for pow --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token -v, --version display version information for pow and the connected server","title":"Options"},{"location":"powergate/cli/pow/#see-also","text":"pow admin - Provides admin commands pow config - Provides commands to interact with cid storage configs pow data - Provides commands to interact with general data APIs pow deals - Provides commands to view Filecoin deal information pow id - Returns the user id pow storage-info - Provides commands to get and query cid storage info. pow storage-jobs - Provides commands to query for storage jobs in various states pow version - Display version information for pow and the connected server pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin/","text":"pow admin \u00b6 Provides admin commands Synopsis \u00b6 Provides admin commands Options \u00b6 --admin-token string admin auth token -h, --help help for admin Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow admin data - Provides admin data commands pow admin storage-info - Provides admin storage info commands pow admin storage-jobs - Provides admin jobs commands pow admin users - Provides admin users commands pow admin wallet - Provides admin wallet commands","title":"Admin"},{"location":"powergate/cli/pow_admin/#pow-admin","text":"Provides admin commands","title":"pow admin"},{"location":"powergate/cli/pow_admin/#synopsis","text":"Provides admin commands","title":"Synopsis"},{"location":"powergate/cli/pow_admin/#options","text":"--admin-token string admin auth token -h, --help help for admin","title":"Options"},{"location":"powergate/cli/pow_admin/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin/#see-also","text":"pow - A client for storage and retreival of powergate data pow admin data - Provides admin data commands pow admin storage-info - Provides admin storage info commands pow admin storage-jobs - Provides admin jobs commands pow admin users - Provides admin users commands pow admin wallet - Provides admin wallet commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_data/","text":"pow admin data \u00b6 Provides admin data commands Synopsis \u00b6 Provides admin data commands Options \u00b6 -h, --help help for data Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin - Provides admin commands pow admin data gcstaged - Unpins unused staged data. pow admin data pinnedcids - List pinned cids information in hot-storage.","title":"Pow admin data"},{"location":"powergate/cli/pow_admin_data/#pow-admin-data","text":"Provides admin data commands","title":"pow admin data"},{"location":"powergate/cli/pow_admin_data/#synopsis","text":"Provides admin data commands","title":"Synopsis"},{"location":"powergate/cli/pow_admin_data/#options","text":"-h, --help help for data","title":"Options"},{"location":"powergate/cli/pow_admin_data/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_data/#see-also","text":"pow admin - Provides admin commands pow admin data gcstaged - Unpins unused staged data. pow admin data pinnedcids - List pinned cids information in hot-storage.","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_data_gcstaged/","text":"pow admin data gcstaged \u00b6 Unpins unused staged data. Synopsis \u00b6 Unpins staged data not used by queued or executing jobs. pow admin data gcstaged [flags] Options \u00b6 -h, --help help for gcstaged Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin data - Provides admin data commands","title":"Pow admin data gcstaged"},{"location":"powergate/cli/pow_admin_data_gcstaged/#pow-admin-data-gcstaged","text":"Unpins unused staged data.","title":"pow admin data gcstaged"},{"location":"powergate/cli/pow_admin_data_gcstaged/#synopsis","text":"Unpins staged data not used by queued or executing jobs. pow admin data gcstaged [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_data_gcstaged/#options","text":"-h, --help help for gcstaged","title":"Options"},{"location":"powergate/cli/pow_admin_data_gcstaged/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_data_gcstaged/#see-also","text":"pow admin data - Provides admin data commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_data_pinnedcids/","text":"pow admin data pinnedcids \u00b6 List pinned cids information in hot-storage. Synopsis \u00b6 List pinned cids information in hot-storage. pow admin data pinnedcids [flags] Options \u00b6 -h, --help help for pinnedcids Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin data - Provides admin data commands","title":"Pow admin data pinnedcids"},{"location":"powergate/cli/pow_admin_data_pinnedcids/#pow-admin-data-pinnedcids","text":"List pinned cids information in hot-storage.","title":"pow admin data pinnedcids"},{"location":"powergate/cli/pow_admin_data_pinnedcids/#synopsis","text":"List pinned cids information in hot-storage. pow admin data pinnedcids [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_data_pinnedcids/#options","text":"-h, --help help for pinnedcids","title":"Options"},{"location":"powergate/cli/pow_admin_data_pinnedcids/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_data_pinnedcids/#see-also","text":"pow admin data - Provides admin data commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_storage-info/","text":"pow admin storage-info \u00b6 Provides admin storage info commands Synopsis \u00b6 Provides admin storage info commands Options \u00b6 -h, --help help for storage-info Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin - Provides admin commands pow admin storage-info get - Returns the information about a stored cid. pow admin storage-info list - Returns a list of information about all stored cids, filtered by user ids and cids if provided.","title":"Pow admin storage info"},{"location":"powergate/cli/pow_admin_storage-info/#pow-admin-storage-info","text":"Provides admin storage info commands","title":"pow admin storage-info"},{"location":"powergate/cli/pow_admin_storage-info/#synopsis","text":"Provides admin storage info commands","title":"Synopsis"},{"location":"powergate/cli/pow_admin_storage-info/#options","text":"-h, --help help for storage-info","title":"Options"},{"location":"powergate/cli/pow_admin_storage-info/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_storage-info/#see-also","text":"pow admin - Provides admin commands pow admin storage-info get - Returns the information about a stored cid. pow admin storage-info list - Returns a list of information about all stored cids, filtered by user ids and cids if provided.","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_storage-info_get/","text":"pow admin storage-info get \u00b6 Returns the information about a stored cid. Synopsis \u00b6 Returns the information about a stored cid. pow admin storage-info get [user-id] [cid] [flags] Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin storage-info - Provides admin storage info commands","title":"Pow admin storage info get"},{"location":"powergate/cli/pow_admin_storage-info_get/#pow-admin-storage-info-get","text":"Returns the information about a stored cid.","title":"pow admin storage-info get"},{"location":"powergate/cli/pow_admin_storage-info_get/#synopsis","text":"Returns the information about a stored cid. pow admin storage-info get [user-id] [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_storage-info_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"powergate/cli/pow_admin_storage-info_get/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_storage-info_get/#see-also","text":"pow admin storage-info - Provides admin storage info commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_storage-info_list/","text":"pow admin storage-info list \u00b6 Returns a list of information about all stored cids, filtered by user ids and cids if provided. Synopsis \u00b6 Returns a list of information about all stored cids, filtered by user ids and cids if provided. pow admin storage-info list [flags] Options \u00b6 --cids strings filter results by provided cids. -h, --help help for list --user-ids strings filter results by provided user ids. Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin storage-info - Provides admin storage info commands","title":"Pow admin storage info list"},{"location":"powergate/cli/pow_admin_storage-info_list/#pow-admin-storage-info-list","text":"Returns a list of information about all stored cids, filtered by user ids and cids if provided.","title":"pow admin storage-info list"},{"location":"powergate/cli/pow_admin_storage-info_list/#synopsis","text":"Returns a list of information about all stored cids, filtered by user ids and cids if provided. pow admin storage-info list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_storage-info_list/#options","text":"--cids strings filter results by provided cids. -h, --help help for list --user-ids strings filter results by provided user ids.","title":"Options"},{"location":"powergate/cli/pow_admin_storage-info_list/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_storage-info_list/#see-also","text":"pow admin storage-info - Provides admin storage info commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_storage-jobs/","text":"pow admin storage-jobs \u00b6 Provides admin jobs commands Synopsis \u00b6 Provides admin jobs commands Options \u00b6 -h, --help help for storage-jobs Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin - Provides admin commands pow admin storage-jobs list - List storage jobs according to query flag options. pow admin storage-jobs summary - Give a summary of storage jobs in all states","title":"Pow admin storage jobs"},{"location":"powergate/cli/pow_admin_storage-jobs/#pow-admin-storage-jobs","text":"Provides admin jobs commands","title":"pow admin storage-jobs"},{"location":"powergate/cli/pow_admin_storage-jobs/#synopsis","text":"Provides admin jobs commands","title":"Synopsis"},{"location":"powergate/cli/pow_admin_storage-jobs/#options","text":"-h, --help help for storage-jobs","title":"Options"},{"location":"powergate/cli/pow_admin_storage-jobs/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_storage-jobs/#see-also","text":"pow admin - Provides admin commands pow admin storage-jobs list - List storage jobs according to query flag options. pow admin storage-jobs summary - Give a summary of storage jobs in all states","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_storage-jobs_list/","text":"pow admin storage-jobs list \u00b6 List storage jobs according to query flag options. Synopsis \u00b6 List storage jobs according to query flag options. pow admin storage-jobs list [flags] Options \u00b6 -a, --ascending sort results ascending by time -c, --cid string return results only for the specified cid -h, --help help for list -l, --limit uint limit the number of results returned -s, --select string return only results using the specified selector: all, queued, executing, final (default \"all\") -u, --user string return results only for the specified user id Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin storage-jobs - Provides admin jobs commands","title":"Pow admin storage jobs list"},{"location":"powergate/cli/pow_admin_storage-jobs_list/#pow-admin-storage-jobs-list","text":"List storage jobs according to query flag options.","title":"pow admin storage-jobs list"},{"location":"powergate/cli/pow_admin_storage-jobs_list/#synopsis","text":"List storage jobs according to query flag options. pow admin storage-jobs list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_storage-jobs_list/#options","text":"-a, --ascending sort results ascending by time -c, --cid string return results only for the specified cid -h, --help help for list -l, --limit uint limit the number of results returned -s, --select string return only results using the specified selector: all, queued, executing, final (default \"all\") -u, --user string return results only for the specified user id","title":"Options"},{"location":"powergate/cli/pow_admin_storage-jobs_list/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_storage-jobs_list/#see-also","text":"pow admin storage-jobs - Provides admin jobs commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_storage-jobs_summary/","text":"pow admin storage-jobs summary \u00b6 Give a summary of storage jobs in all states Synopsis \u00b6 Give a summary of storage jobs in all states pow admin storage-jobs summary [flags] Options \u00b6 -c, --cid string optional cid filter to apply -h, --help help for summary -u, --user-id string optional user id filter to apply Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin storage-jobs - Provides admin jobs commands","title":"Pow admin storage jobs summary"},{"location":"powergate/cli/pow_admin_storage-jobs_summary/#pow-admin-storage-jobs-summary","text":"Give a summary of storage jobs in all states","title":"pow admin storage-jobs summary"},{"location":"powergate/cli/pow_admin_storage-jobs_summary/#synopsis","text":"Give a summary of storage jobs in all states pow admin storage-jobs summary [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_storage-jobs_summary/#options","text":"-c, --cid string optional cid filter to apply -h, --help help for summary -u, --user-id string optional user id filter to apply","title":"Options"},{"location":"powergate/cli/pow_admin_storage-jobs_summary/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_storage-jobs_summary/#see-also","text":"pow admin storage-jobs - Provides admin jobs commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_users/","text":"pow admin users \u00b6 Provides admin users commands Synopsis \u00b6 Provides admin users commands Options \u00b6 -h, --help help for users Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin - Provides admin commands pow admin users create - Create a Powergate user. pow admin users list - List all Powergate users.","title":"Pow admin users"},{"location":"powergate/cli/pow_admin_users/#pow-admin-users","text":"Provides admin users commands","title":"pow admin users"},{"location":"powergate/cli/pow_admin_users/#synopsis","text":"Provides admin users commands","title":"Synopsis"},{"location":"powergate/cli/pow_admin_users/#options","text":"-h, --help help for users","title":"Options"},{"location":"powergate/cli/pow_admin_users/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_users/#see-also","text":"pow admin - Provides admin commands pow admin users create - Create a Powergate user. pow admin users list - List all Powergate users.","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_users_create/","text":"pow admin users create \u00b6 Create a Powergate user. Synopsis \u00b6 Create a Powergate user. pow admin users create [flags] Options \u00b6 -h, --help help for create Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin users - Provides admin users commands","title":"Pow admin users create"},{"location":"powergate/cli/pow_admin_users_create/#pow-admin-users-create","text":"Create a Powergate user.","title":"pow admin users create"},{"location":"powergate/cli/pow_admin_users_create/#synopsis","text":"Create a Powergate user. pow admin users create [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_users_create/#options","text":"-h, --help help for create","title":"Options"},{"location":"powergate/cli/pow_admin_users_create/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_users_create/#see-also","text":"pow admin users - Provides admin users commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_users_list/","text":"pow admin users list \u00b6 List all Powergate users. Synopsis \u00b6 List all Powergate users. pow admin users list [flags] Options \u00b6 -h, --help help for list Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin users - Provides admin users commands","title":"Pow admin users list"},{"location":"powergate/cli/pow_admin_users_list/#pow-admin-users-list","text":"List all Powergate users.","title":"pow admin users list"},{"location":"powergate/cli/pow_admin_users_list/#synopsis","text":"List all Powergate users. pow admin users list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_users_list/#options","text":"-h, --help help for list","title":"Options"},{"location":"powergate/cli/pow_admin_users_list/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_users_list/#see-also","text":"pow admin users - Provides admin users commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_wallet/","text":"pow admin wallet \u00b6 Provides admin wallet commands Synopsis \u00b6 Provides admin wallet commands Options \u00b6 -h, --help help for wallet Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin - Provides admin commands pow admin wallet addrs - List all addresses associated with this Powergate. pow admin wallet new - Creates a new walllet address. pow admin wallet send - Sends FIL from an address associated with this Powergate to any other address.","title":"Pow admin wallet"},{"location":"powergate/cli/pow_admin_wallet/#pow-admin-wallet","text":"Provides admin wallet commands","title":"pow admin wallet"},{"location":"powergate/cli/pow_admin_wallet/#synopsis","text":"Provides admin wallet commands","title":"Synopsis"},{"location":"powergate/cli/pow_admin_wallet/#options","text":"-h, --help help for wallet","title":"Options"},{"location":"powergate/cli/pow_admin_wallet/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_wallet/#see-also","text":"pow admin - Provides admin commands pow admin wallet addrs - List all addresses associated with this Powergate. pow admin wallet new - Creates a new walllet address. pow admin wallet send - Sends FIL from an address associated with this Powergate to any other address.","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_wallet_addrs/","text":"pow admin wallet addrs \u00b6 List all addresses associated with this Powergate. Synopsis \u00b6 List all addresses associated with this Powergate. pow admin wallet addrs [flags] Options \u00b6 -h, --help help for addrs Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin wallet - Provides admin wallet commands","title":"Pow admin wallet addrs"},{"location":"powergate/cli/pow_admin_wallet_addrs/#pow-admin-wallet-addrs","text":"List all addresses associated with this Powergate.","title":"pow admin wallet addrs"},{"location":"powergate/cli/pow_admin_wallet_addrs/#synopsis","text":"List all addresses associated with this Powergate. pow admin wallet addrs [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_wallet_addrs/#options","text":"-h, --help help for addrs","title":"Options"},{"location":"powergate/cli/pow_admin_wallet_addrs/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_wallet_addrs/#see-also","text":"pow admin wallet - Provides admin wallet commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_wallet_new/","text":"pow admin wallet new \u00b6 Creates a new walllet address. Synopsis \u00b6 Creates a new wallet address. pow admin wallet new [flags] Options \u00b6 -f, --format string Optionally specify address format bls or secp256k1 (default \"bls\") -h, --help help for new Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin wallet - Provides admin wallet commands","title":"Pow admin wallet new"},{"location":"powergate/cli/pow_admin_wallet_new/#pow-admin-wallet-new","text":"Creates a new walllet address.","title":"pow admin wallet new"},{"location":"powergate/cli/pow_admin_wallet_new/#synopsis","text":"Creates a new wallet address. pow admin wallet new [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_wallet_new/#options","text":"-f, --format string Optionally specify address format bls or secp256k1 (default \"bls\") -h, --help help for new","title":"Options"},{"location":"powergate/cli/pow_admin_wallet_new/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_wallet_new/#see-also","text":"pow admin wallet - Provides admin wallet commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_admin_wallet_send/","text":"pow admin wallet send \u00b6 Sends FIL from an address associated with this Powergate to any other address. Synopsis \u00b6 Sends FIL from an address associated with this Powergate to any other address. pow admin wallet send [from] [to] [amount] [flags] Options \u00b6 -h, --help help for send Options inherited from parent commands \u00b6 --admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow admin wallet - Provides admin wallet commands","title":"Pow admin wallet send"},{"location":"powergate/cli/pow_admin_wallet_send/#pow-admin-wallet-send","text":"Sends FIL from an address associated with this Powergate to any other address.","title":"pow admin wallet send"},{"location":"powergate/cli/pow_admin_wallet_send/#synopsis","text":"Sends FIL from an address associated with this Powergate to any other address. pow admin wallet send [from] [to] [amount] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_admin_wallet_send/#options","text":"-h, --help help for send","title":"Options"},{"location":"powergate/cli/pow_admin_wallet_send/#options-inherited-from-parent-commands","text":"--admin-token string admin auth token --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_admin_wallet_send/#see-also","text":"pow admin wallet - Provides admin wallet commands","title":"SEE ALSO"},{"location":"powergate/cli/pow_config/","text":"pow config \u00b6 Provides commands to interact with cid storage configs Synopsis \u00b6 Provides commands to interact with cid storage configs Options \u00b6 -h, --help help for config Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow config apply - Apply the default or provided storage config to the specified cid pow config default - Returns the default storage config pow config remove - Removes a Cid from being tracked as an active storage pow config set-default - Sets the default storage config from stdin or a file","title":"Config"},{"location":"powergate/cli/pow_config/#pow-config","text":"Provides commands to interact with cid storage configs","title":"pow config"},{"location":"powergate/cli/pow_config/#synopsis","text":"Provides commands to interact with cid storage configs","title":"Synopsis"},{"location":"powergate/cli/pow_config/#options","text":"-h, --help help for config","title":"Options"},{"location":"powergate/cli/pow_config/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_config/#see-also","text":"pow - A client for storage and retreival of powergate data pow config apply - Apply the default or provided storage config to the specified cid pow config default - Returns the default storage config pow config remove - Removes a Cid from being tracked as an active storage pow config set-default - Sets the default storage config from stdin or a file","title":"SEE ALSO"},{"location":"powergate/cli/pow_config_apply/","text":"pow config apply \u00b6 Apply the default or provided storage config to the specified cid Synopsis \u00b6 Apply the default or provided storage config to the specified cid pow config apply [cid] [flags] Options \u00b6 -c, --conf string Optional path to a file containing storage config json, falls back to stdin, uses the user default by default -h, --help help for apply -i, --import-deals strings Comma-separated list of deal ids to import -e, --noexec If set, it doesn't create a job to ensure the new configuration -o, --override If set, override any pre-existing storage configuration for the cid -w, --watch Watch the progress of the resulting job Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow config - Provides commands to interact with cid storage configs","title":"Pow config apply"},{"location":"powergate/cli/pow_config_apply/#pow-config-apply","text":"Apply the default or provided storage config to the specified cid","title":"pow config apply"},{"location":"powergate/cli/pow_config_apply/#synopsis","text":"Apply the default or provided storage config to the specified cid pow config apply [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_config_apply/#options","text":"-c, --conf string Optional path to a file containing storage config json, falls back to stdin, uses the user default by default -h, --help help for apply -i, --import-deals strings Comma-separated list of deal ids to import -e, --noexec If set, it doesn't create a job to ensure the new configuration -o, --override If set, override any pre-existing storage configuration for the cid -w, --watch Watch the progress of the resulting job","title":"Options"},{"location":"powergate/cli/pow_config_apply/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_config_apply/#see-also","text":"pow config - Provides commands to interact with cid storage configs","title":"SEE ALSO"},{"location":"powergate/cli/pow_config_default/","text":"pow config default \u00b6 Returns the default storage config Synopsis \u00b6 Returns the default storage config pow config default [flags] Options \u00b6 -h, --help help for default Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow config - Provides commands to interact with cid storage configs","title":"Pow config default"},{"location":"powergate/cli/pow_config_default/#pow-config-default","text":"Returns the default storage config","title":"pow config default"},{"location":"powergate/cli/pow_config_default/#synopsis","text":"Returns the default storage config pow config default [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_config_default/#options","text":"-h, --help help for default","title":"Options"},{"location":"powergate/cli/pow_config_default/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_config_default/#see-also","text":"pow config - Provides commands to interact with cid storage configs","title":"SEE ALSO"},{"location":"powergate/cli/pow_config_remove/","text":"pow config remove \u00b6 Removes a Cid from being tracked as an active storage Synopsis \u00b6 Removes a Cid from being tracked as an active storage. The Cid should have both Hot and Cold storage disabled, if that isn't the case it will return ErrActiveInStorage pow config remove [cid] [flags] Options \u00b6 -h, --help help for remove Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow config - Provides commands to interact with cid storage configs","title":"Pow config remove"},{"location":"powergate/cli/pow_config_remove/#pow-config-remove","text":"Removes a Cid from being tracked as an active storage","title":"pow config remove"},{"location":"powergate/cli/pow_config_remove/#synopsis","text":"Removes a Cid from being tracked as an active storage. The Cid should have both Hot and Cold storage disabled, if that isn't the case it will return ErrActiveInStorage pow config remove [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_config_remove/#options","text":"-h, --help help for remove","title":"Options"},{"location":"powergate/cli/pow_config_remove/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_config_remove/#see-also","text":"pow config - Provides commands to interact with cid storage configs","title":"SEE ALSO"},{"location":"powergate/cli/pow_config_set-default/","text":"pow config set-default \u00b6 Sets the default storage config from stdin or a file Synopsis \u00b6 Sets the default storage config from stdin or a file pow config set-default [optional file] [flags] Options \u00b6 -h, --help help for set-default Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow config - Provides commands to interact with cid storage configs","title":"Pow config set default"},{"location":"powergate/cli/pow_config_set-default/#pow-config-set-default","text":"Sets the default storage config from stdin or a file","title":"pow config set-default"},{"location":"powergate/cli/pow_config_set-default/#synopsis","text":"Sets the default storage config from stdin or a file pow config set-default [optional file] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_config_set-default/#options","text":"-h, --help help for set-default","title":"Options"},{"location":"powergate/cli/pow_config_set-default/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_config_set-default/#see-also","text":"pow config - Provides commands to interact with cid storage configs","title":"SEE ALSO"},{"location":"powergate/cli/pow_data/","text":"pow data \u00b6 Provides commands to interact with general data APIs Synopsis \u00b6 Provides commands to interact with general data APIs Options \u00b6 -h, --help help for data Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow data get - Get data stored by the user by cid pow data info - Get information about the current storage state of a cid pow data log - Display logs for specified cid pow data replace - Applies a StorageConfig for c2 equal to that of c1, and removes c1 pow data stage - Temporarily stage data in Hot Storage in preparation for applying a cid storage config pow data summary - Get a summary about the current storage and jobs state of cids","title":"Data"},{"location":"powergate/cli/pow_data/#pow-data","text":"Provides commands to interact with general data APIs","title":"pow data"},{"location":"powergate/cli/pow_data/#synopsis","text":"Provides commands to interact with general data APIs","title":"Synopsis"},{"location":"powergate/cli/pow_data/#options","text":"-h, --help help for data","title":"Options"},{"location":"powergate/cli/pow_data/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data/#see-also","text":"pow - A client for storage and retreival of powergate data pow data get - Get data stored by the user by cid pow data info - Get information about the current storage state of a cid pow data log - Display logs for specified cid pow data replace - Applies a StorageConfig for c2 equal to that of c1, and removes c1 pow data stage - Temporarily stage data in Hot Storage in preparation for applying a cid storage config pow data summary - Get a summary about the current storage and jobs state of cids","title":"SEE ALSO"},{"location":"powergate/cli/pow_data_get/","text":"pow data get \u00b6 Get data stored by the user by cid Synopsis \u00b6 Get data stored by the user by cid pow data get [cid] [output file path] [flags] Options \u00b6 -f, --folder Indicates that the retrieved Cid is a folder -h, --help help for get --ipfsrevproxy string Powergate IPFS reverse proxy DNS address. If port 443, is assumed is a HTTPS endpoint. (default \"localhost:6002\") Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow data - Provides commands to interact with general data APIs","title":"Pow data get"},{"location":"powergate/cli/pow_data_get/#pow-data-get","text":"Get data stored by the user by cid","title":"pow data get"},{"location":"powergate/cli/pow_data_get/#synopsis","text":"Get data stored by the user by cid pow data get [cid] [output file path] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_data_get/#options","text":"-f, --folder Indicates that the retrieved Cid is a folder -h, --help help for get --ipfsrevproxy string Powergate IPFS reverse proxy DNS address. If port 443, is assumed is a HTTPS endpoint. (default \"localhost:6002\")","title":"Options"},{"location":"powergate/cli/pow_data_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data_get/#see-also","text":"pow data - Provides commands to interact with general data APIs","title":"SEE ALSO"},{"location":"powergate/cli/pow_data_info/","text":"pow data info \u00b6 Get information about the current storage state of a cid Synopsis \u00b6 Get information about the current storage state of a cid pow data info cid [flags] Options \u00b6 -h, --help help for info Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow data - Provides commands to interact with general data APIs","title":"Pow data info"},{"location":"powergate/cli/pow_data_info/#pow-data-info","text":"Get information about the current storage state of a cid","title":"pow data info"},{"location":"powergate/cli/pow_data_info/#synopsis","text":"Get information about the current storage state of a cid pow data info cid [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_data_info/#options","text":"-h, --help help for info","title":"Options"},{"location":"powergate/cli/pow_data_info/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data_info/#see-also","text":"pow data - Provides commands to interact with general data APIs","title":"SEE ALSO"},{"location":"powergate/cli/pow_data_log/","text":"pow data log \u00b6 Display logs for specified cid Synopsis \u00b6 Display logs for specified cid pow data log [cid] [flags] Options \u00b6 -h, --help help for log -j, --jid string Display information for only this job id Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow data - Provides commands to interact with general data APIs","title":"Pow data log"},{"location":"powergate/cli/pow_data_log/#pow-data-log","text":"Display logs for specified cid","title":"pow data log"},{"location":"powergate/cli/pow_data_log/#synopsis","text":"Display logs for specified cid pow data log [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_data_log/#options","text":"-h, --help help for log -j, --jid string Display information for only this job id","title":"Options"},{"location":"powergate/cli/pow_data_log/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data_log/#see-also","text":"pow data - Provides commands to interact with general data APIs","title":"SEE ALSO"},{"location":"powergate/cli/pow_data_replace/","text":"pow data replace \u00b6 Applies a StorageConfig for c2 equal to that of c1, and removes c1 Synopsis \u00b6 Applies a StorageConfig for c2 equal to that of c1, and removes c1. This operation is more efficient than manually removing and adding in two separate operations pow data replace [cid1] [cid2] [flags] Options \u00b6 -h, --help help for replace -w, --watch Watch the progress of the resulting job Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow data - Provides commands to interact with general data APIs","title":"Pow data replace"},{"location":"powergate/cli/pow_data_replace/#pow-data-replace","text":"Applies a StorageConfig for c2 equal to that of c1, and removes c1","title":"pow data replace"},{"location":"powergate/cli/pow_data_replace/#synopsis","text":"Applies a StorageConfig for c2 equal to that of c1, and removes c1. This operation is more efficient than manually removing and adding in two separate operations pow data replace [cid1] [cid2] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_data_replace/#options","text":"-h, --help help for replace -w, --watch Watch the progress of the resulting job","title":"Options"},{"location":"powergate/cli/pow_data_replace/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data_replace/#see-also","text":"pow data - Provides commands to interact with general data APIs","title":"SEE ALSO"},{"location":"powergate/cli/pow_data_stage/","text":"pow data stage \u00b6 Temporarily stage data in Hot Storage in preparation for applying a cid storage config Synopsis \u00b6 Temporarily stage data in Hot Storage in preparation for applying a cid storage config pow data stage [path|url] [flags] Options \u00b6 -h, --help help for stage --ipfsrevproxy string Powergate IPFS reverse proxy multiaddr (default \"127.0.0.1:6002\") Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow data - Provides commands to interact with general data APIs","title":"Pow data stage"},{"location":"powergate/cli/pow_data_stage/#pow-data-stage","text":"Temporarily stage data in Hot Storage in preparation for applying a cid storage config","title":"pow data stage"},{"location":"powergate/cli/pow_data_stage/#synopsis","text":"Temporarily stage data in Hot Storage in preparation for applying a cid storage config pow data stage [path|url] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_data_stage/#options","text":"-h, --help help for stage --ipfsrevproxy string Powergate IPFS reverse proxy multiaddr (default \"127.0.0.1:6002\")","title":"Options"},{"location":"powergate/cli/pow_data_stage/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data_stage/#see-also","text":"pow data - Provides commands to interact with general data APIs","title":"SEE ALSO"},{"location":"powergate/cli/pow_data_summary/","text":"pow data summary \u00b6 Get a summary about the current storage and jobs state of cids Synopsis \u00b6 Get a summary about the current storage and jobs state of cids pow data summary [optional cid1,cid2,...] [flags] Options \u00b6 -h, --help help for summary -j, --json output data in raw json instead of an interactive ui Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow data - Provides commands to interact with general data APIs","title":"Pow data summary"},{"location":"powergate/cli/pow_data_summary/#pow-data-summary","text":"Get a summary about the current storage and jobs state of cids","title":"pow data summary"},{"location":"powergate/cli/pow_data_summary/#synopsis","text":"Get a summary about the current storage and jobs state of cids pow data summary [optional cid1,cid2,...] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_data_summary/#options","text":"-h, --help help for summary -j, --json output data in raw json instead of an interactive ui","title":"Options"},{"location":"powergate/cli/pow_data_summary/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_data_summary/#see-also","text":"pow data - Provides commands to interact with general data APIs","title":"SEE ALSO"},{"location":"powergate/cli/pow_deals/","text":"pow deals \u00b6 Provides commands to view Filecoin deal information Synopsis \u00b6 Provides commands to view Filecoin deal information Options \u00b6 -h, --help help for deals Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow deals retrievals - List retrieval deal records for the user pow deals storage - List storage deal records for the user","title":"Deals"},{"location":"powergate/cli/pow_deals/#pow-deals","text":"Provides commands to view Filecoin deal information","title":"pow deals"},{"location":"powergate/cli/pow_deals/#synopsis","text":"Provides commands to view Filecoin deal information","title":"Synopsis"},{"location":"powergate/cli/pow_deals/#options","text":"-h, --help help for deals","title":"Options"},{"location":"powergate/cli/pow_deals/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_deals/#see-also","text":"pow - A client for storage and retreival of powergate data pow deals retrievals - List retrieval deal records for the user pow deals storage - List storage deal records for the user","title":"SEE ALSO"},{"location":"powergate/cli/pow_deals_retrievals/","text":"pow deals retrievals \u00b6 List retrieval deal records for the user Synopsis \u00b6 List retrieval deal records for the user pow deals retrievals [flags] Options \u00b6 --addrs strings limit the records to deals initiated from the specified wallet addresses -a, --ascending sort records ascending, default is descending --cids strings limit the records to deals for the specified data cids -h, --help help for retrievals -e, --include-failed include failed retrievals Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow deals - Provides commands to view Filecoin deal information","title":"Pow deals retrievals"},{"location":"powergate/cli/pow_deals_retrievals/#pow-deals-retrievals","text":"List retrieval deal records for the user","title":"pow deals retrievals"},{"location":"powergate/cli/pow_deals_retrievals/#synopsis","text":"List retrieval deal records for the user pow deals retrievals [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_deals_retrievals/#options","text":"--addrs strings limit the records to deals initiated from the specified wallet addresses -a, --ascending sort records ascending, default is descending --cids strings limit the records to deals for the specified data cids -h, --help help for retrievals -e, --include-failed include failed retrievals","title":"Options"},{"location":"powergate/cli/pow_deals_retrievals/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_deals_retrievals/#see-also","text":"pow deals - Provides commands to view Filecoin deal information","title":"SEE ALSO"},{"location":"powergate/cli/pow_deals_storage/","text":"pow deals storage \u00b6 List storage deal records for the user Synopsis \u00b6 List storage deal records for the user pow deals storage [flags] Options \u00b6 --addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for storage -e, --include-failed include failed deals -f, --include-final include final deals -p, --include-pending include pending deals Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow deals - Provides commands to view Filecoin deal information","title":"Pow deals storage"},{"location":"powergate/cli/pow_deals_storage/#pow-deals-storage","text":"List storage deal records for the user","title":"pow deals storage"},{"location":"powergate/cli/pow_deals_storage/#synopsis","text":"List storage deal records for the user pow deals storage [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_deals_storage/#options","text":"--addrs strings limit the records to deals initiated from the specified wallet addresses, treated as and AND operation if --cids is also provided -a, --ascending sort records ascending, default is sort descending --cids strings limit the records to deals for the specified data cids, treated as and AND operation if --addrs is also provided -h, --help help for storage -e, --include-failed include failed deals -f, --include-final include final deals -p, --include-pending include pending deals","title":"Options"},{"location":"powergate/cli/pow_deals_storage/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_deals_storage/#see-also","text":"pow deals - Provides commands to view Filecoin deal information","title":"SEE ALSO"},{"location":"powergate/cli/pow_id/","text":"pow id \u00b6 Returns the user id Synopsis \u00b6 Returns the user id pow id [flags] Options \u00b6 -h, --help help for id Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data","title":"Pow id"},{"location":"powergate/cli/pow_id/#pow-id","text":"Returns the user id","title":"pow id"},{"location":"powergate/cli/pow_id/#synopsis","text":"Returns the user id pow id [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_id/#options","text":"-h, --help help for id","title":"Options"},{"location":"powergate/cli/pow_id/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_id/#see-also","text":"pow - A client for storage and retreival of powergate data","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-info/","text":"pow storage-info \u00b6 Provides commands to get and query cid storage info. Synopsis \u00b6 Provides commands to get and query cid storage info. Options \u00b6 -h, --help help for storage-info Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow storage-info get - Returns the information about a stored cid. pow storage-info list - Returns a list of information about all stored cids, filtered by cids if provided.","title":"Storage Info"},{"location":"powergate/cli/pow_storage-info/#pow-storage-info","text":"Provides commands to get and query cid storage info.","title":"pow storage-info"},{"location":"powergate/cli/pow_storage-info/#synopsis","text":"Provides commands to get and query cid storage info.","title":"Synopsis"},{"location":"powergate/cli/pow_storage-info/#options","text":"-h, --help help for storage-info","title":"Options"},{"location":"powergate/cli/pow_storage-info/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-info/#see-also","text":"pow - A client for storage and retreival of powergate data pow storage-info get - Returns the information about a stored cid. pow storage-info list - Returns a list of information about all stored cids, filtered by cids if provided.","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-info_get/","text":"pow storage-info get \u00b6 Returns the information about a stored cid. Synopsis \u00b6 Returns the information about a stored cid. pow storage-info get [cid] [flags] Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-info - Provides commands to get and query cid storage info.","title":"Pow storage info get"},{"location":"powergate/cli/pow_storage-info_get/#pow-storage-info-get","text":"Returns the information about a stored cid.","title":"pow storage-info get"},{"location":"powergate/cli/pow_storage-info_get/#synopsis","text":"Returns the information about a stored cid. pow storage-info get [cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-info_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"powergate/cli/pow_storage-info_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-info_get/#see-also","text":"pow storage-info - Provides commands to get and query cid storage info.","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-info_list/","text":"pow storage-info list \u00b6 Returns a list of information about all stored cids, filtered by cids if provided. Synopsis \u00b6 Returns a list of information about all stored cids, filtered by cids if provided. pow storage-info list [optional cid1,cid2,...] [flags] Options \u00b6 -h, --help help for list Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-info - Provides commands to get and query cid storage info.","title":"Pow storage info list"},{"location":"powergate/cli/pow_storage-info_list/#pow-storage-info-list","text":"Returns a list of information about all stored cids, filtered by cids if provided.","title":"pow storage-info list"},{"location":"powergate/cli/pow_storage-info_list/#synopsis","text":"Returns a list of information about all stored cids, filtered by cids if provided. pow storage-info list [optional cid1,cid2,...] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-info_list/#options","text":"-h, --help help for list","title":"Options"},{"location":"powergate/cli/pow_storage-info_list/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-info_list/#see-also","text":"pow storage-info - Provides commands to get and query cid storage info.","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs/","text":"pow storage-jobs \u00b6 Provides commands to query for storage jobs in various states Synopsis \u00b6 Provides commands to query for storage jobs in various statess Options \u00b6 -h, --help help for storage-jobs Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow storage-jobs cancel - Cancel an executing storage job pow storage-jobs cancel-executing - Cancel all executing jobs pow storage-jobs cancel-queued - Cancel all queued jobs pow storage-jobs get - Get a storage job's current status pow storage-jobs list - List storage jobs according to query flag options. pow storage-jobs storage-config - Get the StorageConfig associated with the specified job pow storage-jobs summary - Give a summary of storage jobs in all states pow storage-jobs watch - Watch for storage job status updates","title":"Storage Jobs"},{"location":"powergate/cli/pow_storage-jobs/#pow-storage-jobs","text":"Provides commands to query for storage jobs in various states","title":"pow storage-jobs"},{"location":"powergate/cli/pow_storage-jobs/#synopsis","text":"Provides commands to query for storage jobs in various statess","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs/#options","text":"-h, --help help for storage-jobs","title":"Options"},{"location":"powergate/cli/pow_storage-jobs/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs/#see-also","text":"pow - A client for storage and retreival of powergate data pow storage-jobs cancel - Cancel an executing storage job pow storage-jobs cancel-executing - Cancel all executing jobs pow storage-jobs cancel-queued - Cancel all queued jobs pow storage-jobs get - Get a storage job's current status pow storage-jobs list - List storage jobs according to query flag options. pow storage-jobs storage-config - Get the StorageConfig associated with the specified job pow storage-jobs summary - Give a summary of storage jobs in all states pow storage-jobs watch - Watch for storage job status updates","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_cancel-executing/","text":"pow storage-jobs cancel-executing \u00b6 Cancel all executing jobs Synopsis \u00b6 Cancel all executing jobs pow storage-jobs cancel-executing [flags] Options \u00b6 -h, --help help for cancel-executing Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs cancel executing"},{"location":"powergate/cli/pow_storage-jobs_cancel-executing/#pow-storage-jobs-cancel-executing","text":"Cancel all executing jobs","title":"pow storage-jobs cancel-executing"},{"location":"powergate/cli/pow_storage-jobs_cancel-executing/#synopsis","text":"Cancel all executing jobs pow storage-jobs cancel-executing [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_cancel-executing/#options","text":"-h, --help help for cancel-executing","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_cancel-executing/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_cancel-executing/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_cancel-queued/","text":"pow storage-jobs cancel-queued \u00b6 Cancel all queued jobs Synopsis \u00b6 Cancel all queued jobs pow storage-jobs cancel-queued [flags] Options \u00b6 -h, --help help for cancel-queued Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs cancel queued"},{"location":"powergate/cli/pow_storage-jobs_cancel-queued/#pow-storage-jobs-cancel-queued","text":"Cancel all queued jobs","title":"pow storage-jobs cancel-queued"},{"location":"powergate/cli/pow_storage-jobs_cancel-queued/#synopsis","text":"Cancel all queued jobs pow storage-jobs cancel-queued [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_cancel-queued/#options","text":"-h, --help help for cancel-queued","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_cancel-queued/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_cancel-queued/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_cancel/","text":"pow storage-jobs cancel \u00b6 Cancel an executing storage job Synopsis \u00b6 Cancel an executing storage job pow storage-jobs cancel [jobid] [flags] Options \u00b6 -h, --help help for cancel Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs cancel"},{"location":"powergate/cli/pow_storage-jobs_cancel/#pow-storage-jobs-cancel","text":"Cancel an executing storage job","title":"pow storage-jobs cancel"},{"location":"powergate/cli/pow_storage-jobs_cancel/#synopsis","text":"Cancel an executing storage job pow storage-jobs cancel [jobid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_cancel/#options","text":"-h, --help help for cancel","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_cancel/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_cancel/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_get/","text":"pow storage-jobs get \u00b6 Get a storage job's current status Synopsis \u00b6 Get a storage job's current status pow storage-jobs get [jobid] [flags] Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs get"},{"location":"powergate/cli/pow_storage-jobs_get/#pow-storage-jobs-get","text":"Get a storage job's current status","title":"pow storage-jobs get"},{"location":"powergate/cli/pow_storage-jobs_get/#synopsis","text":"Get a storage job's current status pow storage-jobs get [jobid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_get/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_get/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_list/","text":"pow storage-jobs list \u00b6 List storage jobs according to query flag options. Synopsis \u00b6 List storage jobs according to query flag options. pow storage-jobs list [flags] Options \u00b6 -a, --ascending sort results ascending by time -c, --cid string return results only for the specified cid -h, --help help for list -l, --limit uint limit the number of results returned -s, --select string return only results using the specified selector: all, queued, executing, final (default \"all\") Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs list"},{"location":"powergate/cli/pow_storage-jobs_list/#pow-storage-jobs-list","text":"List storage jobs according to query flag options.","title":"pow storage-jobs list"},{"location":"powergate/cli/pow_storage-jobs_list/#synopsis","text":"List storage jobs according to query flag options. pow storage-jobs list [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_list/#options","text":"-a, --ascending sort results ascending by time -c, --cid string return results only for the specified cid -h, --help help for list -l, --limit uint limit the number of results returned -s, --select string return only results using the specified selector: all, queued, executing, final (default \"all\")","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_list/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_list/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_storage-config/","text":"pow storage-jobs storage-config \u00b6 Get the StorageConfig associated with the specified job Synopsis \u00b6 Get the StorageConfig associated with the specified job pow storage-jobs storage-config [job-id] [flags] Options \u00b6 -h, --help help for storage-config Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs storage config"},{"location":"powergate/cli/pow_storage-jobs_storage-config/#pow-storage-jobs-storage-config","text":"Get the StorageConfig associated with the specified job","title":"pow storage-jobs storage-config"},{"location":"powergate/cli/pow_storage-jobs_storage-config/#synopsis","text":"Get the StorageConfig associated with the specified job pow storage-jobs storage-config [job-id] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_storage-config/#options","text":"-h, --help help for storage-config","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_storage-config/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_storage-config/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_summary/","text":"pow storage-jobs summary \u00b6 Give a summary of storage jobs in all states Synopsis \u00b6 Give a summary of storage jobs in all states pow storage-jobs summary [optional cid] [flags] Options \u00b6 -h, --help help for summary Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs summary"},{"location":"powergate/cli/pow_storage-jobs_summary/#pow-storage-jobs-summary","text":"Give a summary of storage jobs in all states","title":"pow storage-jobs summary"},{"location":"powergate/cli/pow_storage-jobs_summary/#synopsis","text":"Give a summary of storage jobs in all states pow storage-jobs summary [optional cid] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_summary/#options","text":"-h, --help help for summary","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_summary/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_summary/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_storage-jobs_watch/","text":"pow storage-jobs watch \u00b6 Watch for storage job status updates Synopsis \u00b6 Watch for storage job status updates pow storage-jobs watch [jobid,...] [flags] Options \u00b6 -h, --help help for watch Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow storage-jobs - Provides commands to query for storage jobs in various states","title":"Pow storage jobs watch"},{"location":"powergate/cli/pow_storage-jobs_watch/#pow-storage-jobs-watch","text":"Watch for storage job status updates","title":"pow storage-jobs watch"},{"location":"powergate/cli/pow_storage-jobs_watch/#synopsis","text":"Watch for storage job status updates pow storage-jobs watch [jobid,...] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_storage-jobs_watch/#options","text":"-h, --help help for watch","title":"Options"},{"location":"powergate/cli/pow_storage-jobs_watch/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_storage-jobs_watch/#see-also","text":"pow storage-jobs - Provides commands to query for storage jobs in various states","title":"SEE ALSO"},{"location":"powergate/cli/pow_version/","text":"pow version \u00b6 Display version information for pow and the connected server Synopsis \u00b6 Display version information for pow and the connected server pow version [flags] Options \u00b6 -h, --help help for version Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data","title":"Pow version"},{"location":"powergate/cli/pow_version/#pow-version","text":"Display version information for pow and the connected server","title":"pow version"},{"location":"powergate/cli/pow_version/#synopsis","text":"Display version information for pow and the connected server pow version [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_version/#options","text":"-h, --help help for version","title":"Options"},{"location":"powergate/cli/pow_version/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_version/#see-also","text":"pow - A client for storage and retreival of powergate data","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet/","text":"pow wallet \u00b6 Provides commands about filecoin wallets Synopsis \u00b6 Provides commands about filecoin wallets Options \u00b6 -h, --help help for wallet Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow - A client for storage and retreival of powergate data pow wallet addrs - Print all wallet addresses for the current user pow wallet balance - Print the balance of the specified wallet address pow wallet new-addr - Create a new wallet address pow wallet send - Send fil from one managed address to any other address pow wallet sign - Signs a message with user wallet addresses. pow wallet verify - Verifies the signature of a message signed with a user wallet address.","title":"Wallet"},{"location":"powergate/cli/pow_wallet/#pow-wallet","text":"Provides commands about filecoin wallets","title":"pow wallet"},{"location":"powergate/cli/pow_wallet/#synopsis","text":"Provides commands about filecoin wallets","title":"Synopsis"},{"location":"powergate/cli/pow_wallet/#options","text":"-h, --help help for wallet","title":"Options"},{"location":"powergate/cli/pow_wallet/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet/#see-also","text":"pow - A client for storage and retreival of powergate data pow wallet addrs - Print all wallet addresses for the current user pow wallet balance - Print the balance of the specified wallet address pow wallet new-addr - Create a new wallet address pow wallet send - Send fil from one managed address to any other address pow wallet sign - Signs a message with user wallet addresses. pow wallet verify - Verifies the signature of a message signed with a user wallet address.","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_addrs/","text":"pow wallet addrs \u00b6 Print all wallet addresses for the current user Synopsis \u00b6 Print all wallet addresses for the current user pow wallet addrs [flags] Options \u00b6 -h, --help help for addrs Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet addrs"},{"location":"powergate/cli/pow_wallet_addrs/#pow-wallet-addrs","text":"Print all wallet addresses for the current user","title":"pow wallet addrs"},{"location":"powergate/cli/pow_wallet_addrs/#synopsis","text":"Print all wallet addresses for the current user pow wallet addrs [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_addrs/#options","text":"-h, --help help for addrs","title":"Options"},{"location":"powergate/cli/pow_wallet_addrs/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_addrs/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_balance/","text":"pow wallet balance \u00b6 Print the balance of the specified wallet address Synopsis \u00b6 Print the balance of the specified wallet address pow wallet balance [address] [flags] Options \u00b6 -h, --help help for balance Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet balance"},{"location":"powergate/cli/pow_wallet_balance/#pow-wallet-balance","text":"Print the balance of the specified wallet address","title":"pow wallet balance"},{"location":"powergate/cli/pow_wallet_balance/#synopsis","text":"Print the balance of the specified wallet address pow wallet balance [address] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_balance/#options","text":"-h, --help help for balance","title":"Options"},{"location":"powergate/cli/pow_wallet_balance/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_balance/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_new-addr/","text":"pow wallet new-addr \u00b6 Create a new wallet address Synopsis \u00b6 Create a new wallet address pow wallet new-addr [name] [flags] Options \u00b6 -d, --default Make the new address the user default -f, --format string Optionally specify address format bls or secp256k1 -h, --help help for new-addr Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet new addr"},{"location":"powergate/cli/pow_wallet_new-addr/#pow-wallet-new-addr","text":"Create a new wallet address","title":"pow wallet new-addr"},{"location":"powergate/cli/pow_wallet_new-addr/#synopsis","text":"Create a new wallet address pow wallet new-addr [name] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_new-addr/#options","text":"-d, --default Make the new address the user default -f, --format string Optionally specify address format bls or secp256k1 -h, --help help for new-addr","title":"Options"},{"location":"powergate/cli/pow_wallet_new-addr/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_new-addr/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_send/","text":"pow wallet send \u00b6 Send fil from one managed address to any other address Synopsis \u00b6 Send fil from one managed address to any other address pow wallet send [from address] [to address] [amount] [flags] Options \u00b6 -h, --help help for send Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet send"},{"location":"powergate/cli/pow_wallet_send/#pow-wallet-send","text":"Send fil from one managed address to any other address","title":"pow wallet send"},{"location":"powergate/cli/pow_wallet_send/#synopsis","text":"Send fil from one managed address to any other address pow wallet send [from address] [to address] [amount] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_send/#options","text":"-h, --help help for send","title":"Options"},{"location":"powergate/cli/pow_wallet_send/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_send/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_sign/","text":"pow wallet sign \u00b6 Signs a message with user wallet addresses. Synopsis \u00b6 Signs a message using all wallet addresses associated with the user pow wallet sign [hex-encoded-message] [flags] Options \u00b6 -h, --help help for sign Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet sign"},{"location":"powergate/cli/pow_wallet_sign/#pow-wallet-sign","text":"Signs a message with user wallet addresses.","title":"pow wallet sign"},{"location":"powergate/cli/pow_wallet_sign/#synopsis","text":"Signs a message using all wallet addresses associated with the user pow wallet sign [hex-encoded-message] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_sign/#options","text":"-h, --help help for sign","title":"Options"},{"location":"powergate/cli/pow_wallet_sign/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_sign/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"powergate/cli/pow_wallet_verify/","text":"pow wallet verify \u00b6 Verifies the signature of a message signed with a user wallet address. Synopsis \u00b6 Verifies the signature of a message signed with a user wallet address. pow wallet verify [addr] [hex-encoded-message] [hex-encoded-signature] [flags] Options \u00b6 -h, --help help for verify Options inherited from parent commands \u00b6 --serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token SEE ALSO \u00b6 pow wallet - Provides commands about filecoin wallets","title":"Pow wallet verify"},{"location":"powergate/cli/pow_wallet_verify/#pow-wallet-verify","text":"Verifies the signature of a message signed with a user wallet address.","title":"pow wallet verify"},{"location":"powergate/cli/pow_wallet_verify/#synopsis","text":"Verifies the signature of a message signed with a user wallet address. pow wallet verify [addr] [hex-encoded-message] [hex-encoded-signature] [flags]","title":"Synopsis"},{"location":"powergate/cli/pow_wallet_verify/#options","text":"-h, --help help for verify","title":"Options"},{"location":"powergate/cli/pow_wallet_verify/#options-inherited-from-parent-commands","text":"--serverAddress string address of the powergate service api (default \"127.0.0.1:5002\") -t, --token string user auth token","title":"Options inherited from parent commands"},{"location":"powergate/cli/pow_wallet_verify/#see-also","text":"pow wallet - Provides commands about filecoin wallets","title":"SEE ALSO"},{"location":"threads/","text":"Getting Started \u00b6 ThreadDB is a multi-party database built on IPFS and Libp2p that provides an alternative architecture for data on the web. ThreadDB aims to help power a new generation of web technologies by combining a novel use of event sourcing, Interplanetary Linked Data ( IPLD ), and access control to provide a distributed, scalable, and flexible database solution for decentralized applications. Thread Implementations \u00b6 There are two implementations of ThreadDB. Golang \u00b6 The first is written in Go and the implementation reference can be found at https://github.com/textileio/go-threads/ . In this reference, you'll find: All the latest components to use as a library. How to write trustless services. How to build a client connected to a threads daemon. More documentation for the Go implementation will be coming in the future. JavaScript \u00b6 The second implementation is written in JavaScript (Typescript, really). This implementation has some optimizations to make it more ideal when writing web applications. The JavaScript implementation is currently a Client of the Go implementation. You can run it against your own go-threads instance or connect it to the Textile Hub to use one of ours. Read more about the Client here . In general, when building apps that use threads in a remote context, like the browser, it's best to push the networking layer to remote services whenever possible (while using/allowing p2p when it works). You can also build your own remote relays and services using the go-threads library. For the rest of the explanation below, we'll focus on examples using the JavaScript library. Developer API \u00b6 ThreadDB is designed to be simple enough for any developer to start using. The API will feel familiar to developers who have worked with technologies like MongoDB. Important concepts \u00b6 The first three concepts developers will encounter with ThreadDB are Threads , Collections , and Instances . Instances are the individual records you create , update , or delete . Instances are stored in a Collection . Collections have one or many Schemas and can only store Instances that match one of those Schemas . Databases can store many Collections . Collections are similar to Tables in other databases. A Thread -based Database is tied to a single Thread (with associated Thread ID). Creating a new thread \u00b6 To start a new, empty Thread, with remote networking using the Hub APIs, initialize your Thread with the UserAuth object. You can read more about creating UserAuth objects in the creating web apps tutorial . Create a new Thread API client import { Client , PrivateKey , UserAuth } from \"@textile/hub\" ; async function setup ( auth : UserAuth ) { const user = await PrivateKey . fromRandom (); const client = await Client . withUserAuth ( auth ); return client ; } Authorize a new user to use your Hub API You must generate a new API token for each user you want on your API. import { Client , PrivateKey } from \"@textile/hub\" ; async function newToken ( client : Client , user : PrivateKey ) { const token = await client . getToken ( user ); return token ; } List a user's existing Threads import { Client } from \"@textile/hub\" ; async function list ( client : Client ) { const threads = await client . listThreads (); return threads ; } Create a new database import { Client , Identity , ThreadID , UserAuth } from \"@textile/hub\" ; async function createDB ( client : Client ) { const thread : ThreadID = await client . newDB (); return thread ; } Congrats! You now have a new ThreadDB! Each ThreadDB has a unique ThreadID . You can create your own ThreadIDs, or easily generate a random ThreadID as we do in the above example. Invite \u00b6 You can invite multiple users to the same thread. Use this to build chat apps, collaborative documents, and more. import { Client , DBInfo , ThreadID } from \"@textile/hub\" ; async function getInfo ( client : Client , threadID : ThreadID ) : Promise < DBInfo > { return await client . getDBInfo ( threadID ); } async function joinFromInfo ( client : Client , info : DBInfo ) { return await client . joinFromInfo ( info ); } Once you get the DB info, you need to send that to the other users you want to join. To do that, we recommend the User Mailbox API . Collections \u00b6 Collections are used to handle different data structures in the same Database. Each Collection is defined by a json-schema.org schema . These schemas define the shape of Collection Instances (the individual entries). Collections are similar to tables in other databases. Ultimately, a Collection is a single document store with a set of APIs to make it feel like a local database table . Collections can be created from an existing Schema or Object. Create from schema import { Client , ThreadID } from \"@textile/hub\" ; // Define a simple person schema const schema = { $schema : \"http://json-schema.org/draft-07/schema#\" , title : \"Person\" , type : \"object\" , properties : { _id : { type : \"string\" }, name : { type : \"string\" }, missions : { type : \"number\" , minimum : 0 , exclusiveMaximum : 100 , }, }, }; // Requires the started database we created above async function collectionFromSchema ( client : Client , threadID : ThreadID ) { await client . newCollection ( threadID , { name : \"Astronauts\" , schema : schema , }); } Instances \u00b6 Instances are the objects you store in your Collection. Instances are JSON documents with schemas that match those defined in your Collection. Get all Instances import { Client , ThreadID } from \"@textile/hub\" ; async function findEntity ( client : Client , threadId : ThreadID , collection : string ) { const found = await client . find ( threadId , collection , {}); console . debug ( \"found:\" , found . length ); } Add an Instance import { Client , ThreadID } from \"@textile/hub\" ; // matches YourModel and schema async function create ( client : Client , threadId : ThreadID , collection : string ) { const created = await client . create ( threadId , collection , [ { some : \"data\" , numbers : [ 1 , 2 , 3 ], }, ]); } Query \u00b6 Each Threads implementation supports query and look-up capabilities such as insert , findOne , has , and more. ThreadDB also supports the MongoDB query language . In the JavaScript library, you might write queries like the following. import { Client , ThreadID , QueryJSON } from \"@textile/hub\" ; // Requires the started database we generated above containing the Player collection async function createQuery ( client : Client , threadID : ThreadID , query : QueryJSON ) { // Get results const all = await client . find ( threadID , \"astronauts\" , query ); return all ; } Listen \u00b6 You can also subscribe to changes in a database. import { Client , PrivateKey , ThreadID , Update } from \"@textile/hub\" ; const userID = PrivateKey . fromRandom (); interface Astronaut { _id : string ; name : string ; missions : number ; } const callback = async ( reply? : Update < Astronaut > , err? : Error ) => { console . log ( reply . instance ); }; // Requires userID already be authenticated to the Users API async function startListener ( client : Client , threadID : ThreadID ) { const filters = [{ actionTypes : [ \"CREATE\" ] }]; const closer = client . listen < Astronaut > ( threadID , filters , callback ); return closer ; } Access-control \u00b6 ThreadDB uses a modular role-based access control system that allows access control lists (ACLs) to be declared in a wide variety of ways. ACLs are in active development and you can follow the development here . Identity \u00b6 ThreadDB allows you to handle user identities (for access control and security/encryption) in the best way for your app and users. To handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, ThreadDB expects a simple Identity interface for signing and validating database updates. See the Hub documentation on user identities for details. Connect to the Hub \u00b6 Create an Account Create an App Token Add the Textile Hub Library to your App Pinning, Relay, and Replication \u00b6 Thread Services (e.g. pinning encrypted data on IPFS and helping multiple peers relay updates across the network) can be built and deployed to the network using go-threads . Textile offers a number of these functions through the Hub. Attaching the Hub to your databases will allow you to deliver a high-quality user experience. Installation \u00b6 ThreadDB can be used with many languages and has libraries written in JavaScript and Go. Find documentation on each of those libraries below. JavaScript Add Threads to NodeJS, React Native or browser apps. Golang Use Threads in Go or compile to many other platforms. Advanced Details \u00b6 The protocols and design of ThreadDB can be explored in detail in the whitepaper: A protocol & event-sourced database for decentralized user-siloed data . For further technical details, the reference implementation of Threads is written in Go and the full implementation details can be found on godocs (jump to go-threads client ).","title":"ThreadDB"},{"location":"threads/#getting-started","text":"ThreadDB is a multi-party database built on IPFS and Libp2p that provides an alternative architecture for data on the web. ThreadDB aims to help power a new generation of web technologies by combining a novel use of event sourcing, Interplanetary Linked Data ( IPLD ), and access control to provide a distributed, scalable, and flexible database solution for decentralized applications.","title":"Getting Started"},{"location":"threads/#thread-implementations","text":"There are two implementations of ThreadDB.","title":"Thread Implementations"},{"location":"threads/#golang","text":"The first is written in Go and the implementation reference can be found at https://github.com/textileio/go-threads/ . In this reference, you'll find: All the latest components to use as a library. How to write trustless services. How to build a client connected to a threads daemon. More documentation for the Go implementation will be coming in the future.","title":"Golang"},{"location":"threads/#javascript","text":"The second implementation is written in JavaScript (Typescript, really). This implementation has some optimizations to make it more ideal when writing web applications. The JavaScript implementation is currently a Client of the Go implementation. You can run it against your own go-threads instance or connect it to the Textile Hub to use one of ours. Read more about the Client here . In general, when building apps that use threads in a remote context, like the browser, it's best to push the networking layer to remote services whenever possible (while using/allowing p2p when it works). You can also build your own remote relays and services using the go-threads library. For the rest of the explanation below, we'll focus on examples using the JavaScript library.","title":"JavaScript"},{"location":"threads/#developer-api","text":"ThreadDB is designed to be simple enough for any developer to start using. The API will feel familiar to developers who have worked with technologies like MongoDB.","title":"Developer API"},{"location":"threads/#important-concepts","text":"The first three concepts developers will encounter with ThreadDB are Threads , Collections , and Instances . Instances are the individual records you create , update , or delete . Instances are stored in a Collection . Collections have one or many Schemas and can only store Instances that match one of those Schemas . Databases can store many Collections . Collections are similar to Tables in other databases. A Thread -based Database is tied to a single Thread (with associated Thread ID).","title":"Important concepts"},{"location":"threads/#creating-a-new-thread","text":"To start a new, empty Thread, with remote networking using the Hub APIs, initialize your Thread with the UserAuth object. You can read more about creating UserAuth objects in the creating web apps tutorial . Create a new Thread API client import { Client , PrivateKey , UserAuth } from \"@textile/hub\" ; async function setup ( auth : UserAuth ) { const user = await PrivateKey . fromRandom (); const client = await Client . withUserAuth ( auth ); return client ; } Authorize a new user to use your Hub API You must generate a new API token for each user you want on your API. import { Client , PrivateKey } from \"@textile/hub\" ; async function newToken ( client : Client , user : PrivateKey ) { const token = await client . getToken ( user ); return token ; } List a user's existing Threads import { Client } from \"@textile/hub\" ; async function list ( client : Client ) { const threads = await client . listThreads (); return threads ; } Create a new database import { Client , Identity , ThreadID , UserAuth } from \"@textile/hub\" ; async function createDB ( client : Client ) { const thread : ThreadID = await client . newDB (); return thread ; } Congrats! You now have a new ThreadDB! Each ThreadDB has a unique ThreadID . You can create your own ThreadIDs, or easily generate a random ThreadID as we do in the above example.","title":"Creating a new thread"},{"location":"threads/#invite","text":"You can invite multiple users to the same thread. Use this to build chat apps, collaborative documents, and more. import { Client , DBInfo , ThreadID } from \"@textile/hub\" ; async function getInfo ( client : Client , threadID : ThreadID ) : Promise < DBInfo > { return await client . getDBInfo ( threadID ); } async function joinFromInfo ( client : Client , info : DBInfo ) { return await client . joinFromInfo ( info ); } Once you get the DB info, you need to send that to the other users you want to join. To do that, we recommend the User Mailbox API .","title":"Invite"},{"location":"threads/#collections","text":"Collections are used to handle different data structures in the same Database. Each Collection is defined by a json-schema.org schema . These schemas define the shape of Collection Instances (the individual entries). Collections are similar to tables in other databases. Ultimately, a Collection is a single document store with a set of APIs to make it feel like a local database table . Collections can be created from an existing Schema or Object. Create from schema import { Client , ThreadID } from \"@textile/hub\" ; // Define a simple person schema const schema = { $schema : \"http://json-schema.org/draft-07/schema#\" , title : \"Person\" , type : \"object\" , properties : { _id : { type : \"string\" }, name : { type : \"string\" }, missions : { type : \"number\" , minimum : 0 , exclusiveMaximum : 100 , }, }, }; // Requires the started database we created above async function collectionFromSchema ( client : Client , threadID : ThreadID ) { await client . newCollection ( threadID , { name : \"Astronauts\" , schema : schema , }); }","title":"Collections"},{"location":"threads/#instances","text":"Instances are the objects you store in your Collection. Instances are JSON documents with schemas that match those defined in your Collection. Get all Instances import { Client , ThreadID } from \"@textile/hub\" ; async function findEntity ( client : Client , threadId : ThreadID , collection : string ) { const found = await client . find ( threadId , collection , {}); console . debug ( \"found:\" , found . length ); } Add an Instance import { Client , ThreadID } from \"@textile/hub\" ; // matches YourModel and schema async function create ( client : Client , threadId : ThreadID , collection : string ) { const created = await client . create ( threadId , collection , [ { some : \"data\" , numbers : [ 1 , 2 , 3 ], }, ]); }","title":"Instances"},{"location":"threads/#query","text":"Each Threads implementation supports query and look-up capabilities such as insert , findOne , has , and more. ThreadDB also supports the MongoDB query language . In the JavaScript library, you might write queries like the following. import { Client , ThreadID , QueryJSON } from \"@textile/hub\" ; // Requires the started database we generated above containing the Player collection async function createQuery ( client : Client , threadID : ThreadID , query : QueryJSON ) { // Get results const all = await client . find ( threadID , \"astronauts\" , query ); return all ; }","title":"Query"},{"location":"threads/#listen","text":"You can also subscribe to changes in a database. import { Client , PrivateKey , ThreadID , Update } from \"@textile/hub\" ; const userID = PrivateKey . fromRandom (); interface Astronaut { _id : string ; name : string ; missions : number ; } const callback = async ( reply? : Update < Astronaut > , err? : Error ) => { console . log ( reply . instance ); }; // Requires userID already be authenticated to the Users API async function startListener ( client : Client , threadID : ThreadID ) { const filters = [{ actionTypes : [ \"CREATE\" ] }]; const closer = client . listen < Astronaut > ( threadID , filters , callback ); return closer ; }","title":"Listen"},{"location":"threads/#access-control","text":"ThreadDB uses a modular role-based access control system that allows access control lists (ACLs) to be declared in a wide variety of ways. ACLs are in active development and you can follow the development here .","title":"Access-control"},{"location":"threads/#identity","text":"ThreadDB allows you to handle user identities (for access control and security/encryption) in the best way for your app and users. To handle multiple peers collaborating on a single database, as well as the ability to handle storage on behalf of a user, ThreadDB expects a simple Identity interface for signing and validating database updates. See the Hub documentation on user identities for details.","title":"Identity"},{"location":"threads/#connect-to-the-hub","text":"Create an Account Create an App Token Add the Textile Hub Library to your App","title":"Connect to the Hub"},{"location":"threads/#pinning-relay-and-replication","text":"Thread Services (e.g. pinning encrypted data on IPFS and helping multiple peers relay updates across the network) can be built and deployed to the network using go-threads . Textile offers a number of these functions through the Hub. Attaching the Hub to your databases will allow you to deliver a high-quality user experience.","title":"Pinning, Relay, and Replication"},{"location":"threads/#installation","text":"ThreadDB can be used with many languages and has libraries written in JavaScript and Go. Find documentation on each of those libraries below.","title":"Installation"},{"location":"threads/#advanced-details","text":"The protocols and design of ThreadDB can be explored in detail in the whitepaper: A protocol & event-sourced database for decentralized user-siloed data . For further technical details, the reference implementation of Threads is written in Go and the full implementation details can be found on godocs (jump to go-threads client ).","title":"Advanced Details"},{"location":"tutorials/nodejs/","text":"Building with NodeJS \u00b6 The one difference between Textile's JavaScript libraries and NodeJS has to do with WebSockets. Most of the APIs exposed (Buckets daemon, Threads daemons, and the Hub) do so over WebSockets. WebSockets are baked into every major browser but don't come with NodeJS by default, so we'll have to add them. Adding WebSockets to NodeJS \u00b6 The easiest solution to make all libraries compatible is to add WebSockets to the global namespace. Install We'll use the isomorphic-ws library to add WebSockets to our Node app. npm install --save isomorphic-ws ws Setup You can now just add WebSockets to the global namespace in your apps. Add this to the first line in your js or ts files, usually index.js or main.js or similar. In TypeScript: ( global as any ). WebSocket = require ( \"isomorphic-ws\" ); In JavaScript: global . WebSocket = require ( \"isomorphic-ws\" ); Start building \u00b6 That's it. Now start building with the full suite of Textile tools. Check out the app-building tutorials for ideas.","title":"Build with NodeJS"},{"location":"tutorials/nodejs/#building-with-nodejs","text":"The one difference between Textile's JavaScript libraries and NodeJS has to do with WebSockets. Most of the APIs exposed (Buckets daemon, Threads daemons, and the Hub) do so over WebSockets. WebSockets are baked into every major browser but don't come with NodeJS by default, so we'll have to add them.","title":"Building with NodeJS"},{"location":"tutorials/nodejs/#adding-websockets-to-nodejs","text":"The easiest solution to make all libraries compatible is to add WebSockets to the global namespace. Install We'll use the isomorphic-ws library to add WebSockets to our Node app. npm install --save isomorphic-ws ws Setup You can now just add WebSockets to the global namespace in your apps. Add this to the first line in your js or ts files, usually index.js or main.js or similar. In TypeScript: ( global as any ). WebSocket = require ( \"isomorphic-ws\" ); In JavaScript: global . WebSocket = require ( \"isomorphic-ws\" );","title":"Adding WebSockets to NodeJS"},{"location":"tutorials/nodejs/#start-building","text":"That's it. Now start building with the full suite of Textile tools. Check out the app-building tutorials for ideas.","title":"Start building"},{"location":"tutorials/react-native-buckets/","text":"User Buckets from React Native \u00b6 The Hub gets really powerful when you allow users to leverage IPFS, IPNS, and ThreadDB from inside your applications. This tutorial will show you how you can let users create, own, and manage buckets in React Native. Click here to see an example app built with this tutorial. Preview video \u00b6 Install libraries \u00b6 Textile Libraries npm install --save @textile/hub @textile/threads-id We'll use the above combination of Textile libraries in our app below. rn-nodeify npm install -D rn-nodeify We're going to use rn-nodeify and a few other libraries it'll install to manage Buffer , crypto , and other tools to our JavaScript environment in React Native. Read about rn-nodeify here . Next, you need to run: ./node_modules/.bin/rn-nodeify --install This will install a shim.js into the root of your file. You need to import shim.js at the top of your app's root file (typically index.js ), import \"./shim\" ; This may need to be updated in the future. You can make this easier by adding a postinstall step to your package.json , as follows: \"scripts\" : { ... \"postinstall\" : \"./node_modules/.bin/rn-nodeify --install fs,path,process,buffer,crypto,stream,vm --hack\" } Environment variables If you plan to store your source-code anywhere public, you should not store those keys publicly. To securely add API keys to your app, you can use react-native-dotenv . npm install --save react-native-dotenv Next, create a .env file in the root of your project. You can find an example .env in our example project here . Warning Be certain that the .env is added to your .gitignore and not checked in with your code. The contents of .env will look like: USER_API_KEY = textile-hub-user-group-key You can follow the instructions to generate a User Group Key here . If you already generated keys, you can list them by executing hub keys ls . Add the values to your .env file on the right side of the equality sign. Typescript The rest of the JavaScript portions in this tutorial will be in TypeScript. You don't need to use TypeScript but if you don't, be sure to strip the typings from any code you copy below. Build your app \u00b6 Hint In the example app, we put all the ThreadDB and Bucket logic into a single component called checklist.ts . You can view that file for reference. Import Textile // Buckets client and an API Context helper import { Buckets , Client , ThreadID , PrivateKey , Where } from \"@textile/hub\" ; Register with remote API \u00b6 Next, we'll connect to the remote API using our key from an insecure (non-signing) API key. Read more about keys for development mode . We do this so the user can later push their bucket for remote persistence on IPFS and publishing on IPNS. import { Client } from \"@textile/hub\" ; const client = Client . withKeyInfo ({ key : \"USER_API_KEY\" , }); Hint Read more about the Context tool in the Threads Introduction . Generate an Identity \u00b6 Read the basic identities tutorial here . import { PrivateKey } from \"@textile/hub\" ; async function example() { const id = await PrivateKey . fromRandom (); return id ; } Here, we're just using a helper to generate a private-key identity for the user. Generate User Token \u00b6 import { Client , PrivateKey } from \"@textile/hub\" ; async function example ( client : Client , identity : PrivateKey ) { await client . getToken ( identity ); } This will register the user with your remote Hub account, granting them the ability to push data to IPFS through Threads and Buckets. Connect Buckets \u00b6 Now that your user is setup and connected to your API on the Hub, you can start creating Buckets. First, setup a Bucket instance. import { Buckets } from \"@textile/hub\" ; const buckets = Buckets . withKeyInfo ({ key : \"USER_API_KEY\" , }); In the code above, we reuse the Context we already created in our ThreadDB Client because it contains the token, API keys, etc. Info If you already created a connection using the Threads client , you can directly transfer that connection to Buckets with Buckets.copyAuth(client) . List all Buckets import { Buckets } from \"@textile/hub\" ; async function find ( buckets : Buckets ) { const roots = await buckets . list (); const exists = roots . find (( bucket ) => bucket . name === \"buckets\" ); return exists ; } Open a Bucket The easiest way to start pushing/pulling bucket files is to use the open method with just the bucket name you intend to use. import { Buckets } from \"@textile/hub\" ; async function find ( buckets : Buckets , name : string ) { const root = await buckets . open ( name ); return root ; // root.key is the bucket key } Push files to User Bucket \u00b6 Finally, let's push a simple file to the user's Bucket. In this example, we'll just create a simple HTML file that says, Hello world . import { Buckets } from \"@textile/hub\" ; async function example ( buckets : Buckets , bucketKey : string , content : string ) { const file = { path : \"/index.html\" , content : Buffer.from ( content ) }; const raw = await buckets . pushPath ( bucketKey , \"index.html\" , file ); } Updating User Bucket \u00b6 When you update your Bucket: The Thread containing the Bucket will be updated . The Bucket's HTTP URL and IPNS address updates to reflects those updates. The Bucket will get a new IPFS address (CID) any time you change it. This gives you a lot of options for building apps, delivering content, and doing cool things for your users with their data. To get each of the protocol addresses, read below. List the Bucket links \u00b6 Finally, you can list the links to the file on IPFS, IPNS, ThreadDB, and HTTP. HTTP Address \u00b6 Textile gives you and your users a public address for each Bucket created. They are created using the Bucket key and you can generate those as follows: https://${bucket-key}.textile.space IPFS Address \u00b6 The IPFS address is contained in the result of pushPath . import { Buckets } from \"@textile/hub\" ; async function example ( buckets : Buckets , bucketKey : string , file : Buffer ) { const raw = await buckets . pushPath ( bucketKey ! , \"index.html\" , file ); console . log ( raw . root ); } IPNS Address \u00b6 The IPNS Address is always the same and is the Bucket key! If you want to see the Bucket over IPNS from a gateway, you can use the Textile gateway as follows: https://${bucket-key}.ipns.hub.textile.io/ ThreadDB Address \u00b6 You can generate a link to the Bucket with the user thread as follows: https://${thread-id}.thread.hub.textile.io/buckets/${this.state.bucket-key} Warning Remember, at this point, Buckets are entirely open, data is available to be viewed or downloaded by anyone your app or user shares the link with. Code \u00b6 Check out a complete React Native project on GitHub that generates a User Identity, Thread, and Bucket. Android setup \u00b6 Simply npm install and then npm run android from the root of the react-native-hub-app folder. iOS setup \u00b6 If npm run ios doesn't work for you immediately after npm install , follow these steps. Be sure you ran npm install . Be sure you have updated your .env file. Start the react native server, npm run start . Open Xcode Open the iOS project, ./ios/threadsdb_app.xcworkspace . Click run in Xcode. Your app should now be running. Subsequent should work with just npm run ios .","title":"User Buckets in React Native"},{"location":"tutorials/react-native-buckets/#user-buckets-from-react-native","text":"The Hub gets really powerful when you allow users to leverage IPFS, IPNS, and ThreadDB from inside your applications. This tutorial will show you how you can let users create, own, and manage buckets in React Native. Click here to see an example app built with this tutorial.","title":"User Buckets from React Native"},{"location":"tutorials/react-native-buckets/#preview-video","text":"","title":"Preview video"},{"location":"tutorials/react-native-buckets/#install-libraries","text":"Textile Libraries npm install --save @textile/hub @textile/threads-id We'll use the above combination of Textile libraries in our app below. rn-nodeify npm install -D rn-nodeify We're going to use rn-nodeify and a few other libraries it'll install to manage Buffer , crypto , and other tools to our JavaScript environment in React Native. Read about rn-nodeify here . Next, you need to run: ./node_modules/.bin/rn-nodeify --install This will install a shim.js into the root of your file. You need to import shim.js at the top of your app's root file (typically index.js ), import \"./shim\" ; This may need to be updated in the future. You can make this easier by adding a postinstall step to your package.json , as follows: \"scripts\" : { ... \"postinstall\" : \"./node_modules/.bin/rn-nodeify --install fs,path,process,buffer,crypto,stream,vm --hack\" } Environment variables If you plan to store your source-code anywhere public, you should not store those keys publicly. To securely add API keys to your app, you can use react-native-dotenv . npm install --save react-native-dotenv Next, create a .env file in the root of your project. You can find an example .env in our example project here . Warning Be certain that the .env is added to your .gitignore and not checked in with your code. The contents of .env will look like: USER_API_KEY = textile-hub-user-group-key You can follow the instructions to generate a User Group Key here . If you already generated keys, you can list them by executing hub keys ls . Add the values to your .env file on the right side of the equality sign. Typescript The rest of the JavaScript portions in this tutorial will be in TypeScript. You don't need to use TypeScript but if you don't, be sure to strip the typings from any code you copy below.","title":"Install libraries"},{"location":"tutorials/react-native-buckets/#build-your-app","text":"Hint In the example app, we put all the ThreadDB and Bucket logic into a single component called checklist.ts . You can view that file for reference. Import Textile // Buckets client and an API Context helper import { Buckets , Client , ThreadID , PrivateKey , Where } from \"@textile/hub\" ;","title":"Build your app"},{"location":"tutorials/react-native-buckets/#register-with-remote-api","text":"Next, we'll connect to the remote API using our key from an insecure (non-signing) API key. Read more about keys for development mode . We do this so the user can later push their bucket for remote persistence on IPFS and publishing on IPNS. import { Client } from \"@textile/hub\" ; const client = Client . withKeyInfo ({ key : \"USER_API_KEY\" , }); Hint Read more about the Context tool in the Threads Introduction .","title":"Register with remote API"},{"location":"tutorials/react-native-buckets/#generate-an-identity","text":"Read the basic identities tutorial here . import { PrivateKey } from \"@textile/hub\" ; async function example() { const id = await PrivateKey . fromRandom (); return id ; } Here, we're just using a helper to generate a private-key identity for the user.","title":"Generate an Identity"},{"location":"tutorials/react-native-buckets/#generate-user-token","text":"import { Client , PrivateKey } from \"@textile/hub\" ; async function example ( client : Client , identity : PrivateKey ) { await client . getToken ( identity ); } This will register the user with your remote Hub account, granting them the ability to push data to IPFS through Threads and Buckets.","title":"Generate User Token"},{"location":"tutorials/react-native-buckets/#connect-buckets","text":"Now that your user is setup and connected to your API on the Hub, you can start creating Buckets. First, setup a Bucket instance. import { Buckets } from \"@textile/hub\" ; const buckets = Buckets . withKeyInfo ({ key : \"USER_API_KEY\" , }); In the code above, we reuse the Context we already created in our ThreadDB Client because it contains the token, API keys, etc. Info If you already created a connection using the Threads client , you can directly transfer that connection to Buckets with Buckets.copyAuth(client) . List all Buckets import { Buckets } from \"@textile/hub\" ; async function find ( buckets : Buckets ) { const roots = await buckets . list (); const exists = roots . find (( bucket ) => bucket . name === \"buckets\" ); return exists ; } Open a Bucket The easiest way to start pushing/pulling bucket files is to use the open method with just the bucket name you intend to use. import { Buckets } from \"@textile/hub\" ; async function find ( buckets : Buckets , name : string ) { const root = await buckets . open ( name ); return root ; // root.key is the bucket key }","title":"Connect Buckets"},{"location":"tutorials/react-native-buckets/#push-files-to-user-bucket","text":"Finally, let's push a simple file to the user's Bucket. In this example, we'll just create a simple HTML file that says, Hello world . import { Buckets } from \"@textile/hub\" ; async function example ( buckets : Buckets , bucketKey : string , content : string ) { const file = { path : \"/index.html\" , content : Buffer.from ( content ) }; const raw = await buckets . pushPath ( bucketKey , \"index.html\" , file ); }","title":"Push files to User Bucket"},{"location":"tutorials/react-native-buckets/#updating-user-bucket","text":"When you update your Bucket: The Thread containing the Bucket will be updated . The Bucket's HTTP URL and IPNS address updates to reflects those updates. The Bucket will get a new IPFS address (CID) any time you change it. This gives you a lot of options for building apps, delivering content, and doing cool things for your users with their data. To get each of the protocol addresses, read below.","title":"Updating User Bucket"},{"location":"tutorials/react-native-buckets/#list-the-bucket-links","text":"Finally, you can list the links to the file on IPFS, IPNS, ThreadDB, and HTTP.","title":"List the Bucket links"},{"location":"tutorials/react-native-buckets/#http-address","text":"Textile gives you and your users a public address for each Bucket created. They are created using the Bucket key and you can generate those as follows: https://${bucket-key}.textile.space","title":"HTTP Address"},{"location":"tutorials/react-native-buckets/#ipfs-address","text":"The IPFS address is contained in the result of pushPath . import { Buckets } from \"@textile/hub\" ; async function example ( buckets : Buckets , bucketKey : string , file : Buffer ) { const raw = await buckets . pushPath ( bucketKey ! , \"index.html\" , file ); console . log ( raw . root ); }","title":"IPFS Address"},{"location":"tutorials/react-native-buckets/#ipns-address","text":"The IPNS Address is always the same and is the Bucket key! If you want to see the Bucket over IPNS from a gateway, you can use the Textile gateway as follows: https://${bucket-key}.ipns.hub.textile.io/","title":"IPNS Address"},{"location":"tutorials/react-native-buckets/#threaddb-address","text":"You can generate a link to the Bucket with the user thread as follows: https://${thread-id}.thread.hub.textile.io/buckets/${this.state.bucket-key} Warning Remember, at this point, Buckets are entirely open, data is available to be viewed or downloaded by anyone your app or user shares the link with.","title":"ThreadDB Address"},{"location":"tutorials/react-native-buckets/#code","text":"Check out a complete React Native project on GitHub that generates a User Identity, Thread, and Bucket.","title":"Code"},{"location":"tutorials/react-native-buckets/#android-setup","text":"Simply npm install and then npm run android from the root of the react-native-hub-app folder.","title":"Android setup"},{"location":"tutorials/react-native-buckets/#ios-setup","text":"If npm run ios doesn't work for you immediately after npm install , follow these steps. Be sure you ran npm install . Be sure you have updated your .env file. Start the react native server, npm run start . Open Xcode Open the iOS project, ./ios/threadsdb_app.xcworkspace . Click run in Xcode. Your app should now be running. Subsequent should work with just npm run ios .","title":"iOS setup"},{"location":"tutorials/static-websites/","text":"Buckets make it simple to publish websites using IPFS. If you are using a static site builder such as Jekyll , Gatsby , Hugo , or Mkdocs you can add Buckets to your build steps for both staging and production site hosting. Site builder tutorials \u00b6 If you are using one of these static site builders, jump to the specific tutorials. Jekyll Site An example Jekyll site published in a Bucket. Gatsby Site An example Gatsby site published in a Bucket. Hugo Site An example Hugo site published in a Bucket. Automation and deployment (CI/CD) \u00b6 Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. If you kepe your website source code on GitHub, we have provided a configurable GitHub Action that allows you to automatically push updates to your Bucket whenever your website changes. View the Textile Buckets GitHub Action . Resources \u00b6 Domain Name Management \u00b6 Fleek Fleek offers domain management tools and soon, Bucket support. Cloudflare Easily add your Bucket IPNS address to Cloudflare with DNSLink. Network Replication \u00b6 Your website may be one of your most important assets on IPFS. Why not pin it on multiple infrastructure providers for added network speed. Pinata Simple and easy to use, Pinata offers a great pinning API for IPFS. Infura Seasoned builders of API portals for the dWeb, pin with confidence on Infura. Temporal Get the stopwatch out, Temporal is your pinning service with speed on the brain . Overview \u00b6 Initialize your Bucket \u00b6 If you are building a static site with an engine such as Jekyll or Gatsyb, or even React you will want to initialize your Bucket in the root of the project, not in the build folder. Your project might look like this. ls ./ build package.json src In this case, we are building the raw site code in src into the build folder. We should initialize the Bucket at the root of the project. cd build hub bucket init Push your Bucket \u00b6 Now, pushing your Bucket is simple. After you build your project so that build contains the latest version of your site ready to deploy you run the bucket push command. hub bucket push That's it! Your site is now available on the free subdomain and over IPNS. You can easily integrate it into your own DNS using DNSLink. DNSLink \u00b6 You can use Buckets to host websites from your own domain using DNSLink . The easiest way to do this is using your Bucket's IPNS link. On Cloudflare for example, your updated DNS records should look like the following. CNAME <site> www.cloudflare-ipfs.com TXT _dnslink.<site> dnslink = /ipns/<bucket ipns link>","title":"Static websites"},{"location":"tutorials/static-websites/#site-builder-tutorials","text":"If you are using one of these static site builders, jump to the specific tutorials.","title":"Site builder tutorials"},{"location":"tutorials/static-websites/#automation-and-deployment-cicd","text":"Buckets are an ideal tool for persisting your website, source code, or documentation on IPFS using continuous integration. Tools like Travis CI, CircleCI, and GitHub Actions all make it possible to do very easily. If you kepe your website source code on GitHub, we have provided a configurable GitHub Action that allows you to automatically push updates to your Bucket whenever your website changes. View the Textile Buckets GitHub Action .","title":"Automation and deployment (CI/CD)"},{"location":"tutorials/static-websites/#resources","text":"","title":"Resources"},{"location":"tutorials/static-websites/#domain-name-management","text":"","title":"Domain Name Management"},{"location":"tutorials/static-websites/#network-replication","text":"Your website may be one of your most important assets on IPFS. Why not pin it on multiple infrastructure providers for added network speed.","title":"Network Replication"},{"location":"tutorials/static-websites/#overview","text":"","title":"Overview"},{"location":"tutorials/static-websites/#initialize-your-bucket","text":"If you are building a static site with an engine such as Jekyll or Gatsyb, or even React you will want to initialize your Bucket in the root of the project, not in the build folder. Your project might look like this. ls ./ build package.json src In this case, we are building the raw site code in src into the build folder. We should initialize the Bucket at the root of the project. cd build hub bucket init","title":"Initialize your Bucket"},{"location":"tutorials/static-websites/#push-your-bucket","text":"Now, pushing your Bucket is simple. After you build your project so that build contains the latest version of your site ready to deploy you run the bucket push command. hub bucket push That's it! Your site is now available on the free subdomain and over IPNS. You can easily integrate it into your own DNS using DNSLink.","title":"Push your Bucket"},{"location":"tutorials/static-websites/#dnslink","text":"You can use Buckets to host websites from your own domain using DNSLink . The easiest way to do this is using your Bucket's IPNS link. On Cloudflare for example, your updated DNS records should look like the following. CNAME <site> www.cloudflare-ipfs.com TXT _dnslink.<site> dnslink = /ipns/<bucket ipns link>","title":"DNSLink"},{"location":"tutorials/go/getting-started/","text":"ThreadDB & Buckets and in Go \u00b6 Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. You have access to the full suite of Textile APIs and technologies in Go. This includes access to: Hub-based persistence Thread client Local Thread databases Bucket client And more. Below, we'll walk you through the basic flow for interacting with the Hub-backed ThreadDB . Set up your project \u00b6 Create a directory for your project and initialize a new go module. mkdir hello-threads cd hello-threads go mod init github.com/example/hello-threads Go is particular about how you install libraries above v2. To ensure you are using the latest, grab v2 now. go get github.com/textileio/textile/v2 Next, create a main.go that you'll use to build your first thread client. touch main.go Connect a new thread client \u00b6 Inside main.go you'll create a new client connection to the Textile Hub's thread APIs. package main import ( \"context\" \"crypto/rand\" \"crypto/tls\" \"fmt\" \"time\" crypto \"github.com/libp2p/go-libp2p-crypto\" \"github.com/textileio/go-threads/api/client\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/textile/api/common\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials\" ) func main () { // Create an API Client creds := credentials . NewTLS ( & tls . Config {}) auth := common . Credentials {} opts := [] grpc . DialOption { grpc . WithTransportCredentials ( creds ), grpc . WithPerRPCCredentials ( auth )} cli , err := client . NewClient ( \"api.hub.textile.io:443\" , opts ... ) if err != nil { panic ( err ) } fmt . Println ( \"Success!\" ) } You can now run your example, go run main.go > Success! Create a random user \u00b6 This function will use the crypto and thread libraries to generate a new random private key identity. func GetRandomUser () ( thread . Identity , error ) { privateKey , _ , err := crypto . GenerateEd25519Key ( rand . Reader ) if err != nil { return nil , err } myIdentity := thread . NewLibp2pIdentity ( privateKey ) return myIdentity , nil } Hub authentication \u00b6 Authentication on the Hub is done with either your Account Keys or User Group Keys depending on what type of application you're building and which APIs you plan on using. Below is an example of using your user key to generate an authenticated API context to use with Hub-backed buckets and threadDB APIs. You can generate a similar context using account keys for accessing a developer or organization account. func NewUserAuthCtx ( ctx context . Context , userGroupKey string , userGroupSecret string ) ( context . Context , error ) { // Add our user group key to the context ctx = common . NewAPIKeyContext ( ctx , userGroupKey ) // Add a signature using our user group secret return common . CreateAPISigContext ( ctx , time . Now (). Add ( time . Minute ), userGroupSecret ) } The above function will take your API key and secret and set up a context ready to prove to the API that the user is who they claim to be. Request and specify a user token \u00b6 A user token is generated per-user and can then be used with subsequent API calls to specify what user is making the request. They can only be created using valid API credentials and provable user identity. func NewTokenCtx ( ctx context . Context , user thread . Identity ) ( context . Context , error ){ // Generate a new token for the user token , err := cli . GetToken ( ctx , user ) if err != nil { return nil , err } return thread . NewTokenContext ( ctx , token ), nil } You can also store and reuse the token, but it needs to be attached the the context before future API calls. Create a new DB \u00b6 Let's put it all together and then create a new Thread database for our user. package main import ( \"context\" \"crypto/rand\" \"crypto/tls\" \"fmt\" \"time\" crypto \"github.com/libp2p/go-libp2p-crypto\" \"github.com/textileio/go-threads/api/client\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/textile/api/common\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials\" ) func GetRandomUser () ( thread . Identity , error ) { privateKey , _ , err := crypto . GenerateEd25519Key ( rand . Reader ) if err != nil { return nil , err } myIdentity := thread . NewLibp2pIdentity ( privateKey ) return myIdentity , nil } func NewUserAuthCtx ( ctx context . Context , userGroupKey string , userGroupSecret string ) ( context . Context , error ) { // Add our user group key to the context ctx = common . NewAPIKeyContext ( ctx , userGroupKey ) // Add a signature using our user group secret return common . CreateAPISigContext ( ctx , time . Now (). Add ( time . Minute ), userGroupSecret ) } func NewTokenCtx ( ctx context . Context , cli * client . Client , user thread . Identity ) ( context . Context , error ){ // Generate a new token for the user token , err := cli . GetToken ( ctx , user ) if err != nil { return nil , err } return thread . NewTokenContext ( ctx , token ), nil } func main () { // Create an API Client creds := credentials . NewTLS ( & tls . Config {}) auth := common . Credentials {} opts := [] grpc . DialOption { grpc . WithTransportCredentials ( creds ), grpc . WithPerRPCCredentials ( auth )} cli , err := client . NewClient ( \"api.hub.textile.io:443\" , opts ... ) if err != nil { panic ( err ) } user , err := GetRandomUser () if err != nil { panic ( err ) } authCtx , err := NewUserAuthCtx ( context . Background (), \"<key>\" , \"<secret>\" ) if err != nil { panic ( err ) } tokenCtx , err := NewTokenCtx ( authCtx , cli , user ) if err != nil { panic ( err ) } // Generate a new thread ID threadID := thread . NewIDV1 ( thread . Raw , 32 ) // Create your new thread err = cli . NewDB ( tokenCtx , threadID ) if err != nil { panic ( err ) } fmt . Println ( \"> Success!\" ) fmt . Println ( threadID ) } Please refer to the ThreadDB and Buckets docs for more.","title":"Getting started with Go"},{"location":"tutorials/go/getting-started/#threaddb-buckets-and-in-go","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. You have access to the full suite of Textile APIs and technologies in Go. This includes access to: Hub-based persistence Thread client Local Thread databases Bucket client And more. Below, we'll walk you through the basic flow for interacting with the Hub-backed ThreadDB .","title":"ThreadDB &amp; Buckets and in Go"},{"location":"tutorials/go/getting-started/#set-up-your-project","text":"Create a directory for your project and initialize a new go module. mkdir hello-threads cd hello-threads go mod init github.com/example/hello-threads Go is particular about how you install libraries above v2. To ensure you are using the latest, grab v2 now. go get github.com/textileio/textile/v2 Next, create a main.go that you'll use to build your first thread client. touch main.go","title":"Set up your project"},{"location":"tutorials/go/getting-started/#connect-a-new-thread-client","text":"Inside main.go you'll create a new client connection to the Textile Hub's thread APIs. package main import ( \"context\" \"crypto/rand\" \"crypto/tls\" \"fmt\" \"time\" crypto \"github.com/libp2p/go-libp2p-crypto\" \"github.com/textileio/go-threads/api/client\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/textile/api/common\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials\" ) func main () { // Create an API Client creds := credentials . NewTLS ( & tls . Config {}) auth := common . Credentials {} opts := [] grpc . DialOption { grpc . WithTransportCredentials ( creds ), grpc . WithPerRPCCredentials ( auth )} cli , err := client . NewClient ( \"api.hub.textile.io:443\" , opts ... ) if err != nil { panic ( err ) } fmt . Println ( \"Success!\" ) } You can now run your example, go run main.go > Success!","title":"Connect a new thread client"},{"location":"tutorials/go/getting-started/#create-a-random-user","text":"This function will use the crypto and thread libraries to generate a new random private key identity. func GetRandomUser () ( thread . Identity , error ) { privateKey , _ , err := crypto . GenerateEd25519Key ( rand . Reader ) if err != nil { return nil , err } myIdentity := thread . NewLibp2pIdentity ( privateKey ) return myIdentity , nil }","title":"Create a random user"},{"location":"tutorials/go/getting-started/#hub-authentication","text":"Authentication on the Hub is done with either your Account Keys or User Group Keys depending on what type of application you're building and which APIs you plan on using. Below is an example of using your user key to generate an authenticated API context to use with Hub-backed buckets and threadDB APIs. You can generate a similar context using account keys for accessing a developer or organization account. func NewUserAuthCtx ( ctx context . Context , userGroupKey string , userGroupSecret string ) ( context . Context , error ) { // Add our user group key to the context ctx = common . NewAPIKeyContext ( ctx , userGroupKey ) // Add a signature using our user group secret return common . CreateAPISigContext ( ctx , time . Now (). Add ( time . Minute ), userGroupSecret ) } The above function will take your API key and secret and set up a context ready to prove to the API that the user is who they claim to be.","title":"Hub authentication"},{"location":"tutorials/go/getting-started/#request-and-specify-a-user-token","text":"A user token is generated per-user and can then be used with subsequent API calls to specify what user is making the request. They can only be created using valid API credentials and provable user identity. func NewTokenCtx ( ctx context . Context , user thread . Identity ) ( context . Context , error ){ // Generate a new token for the user token , err := cli . GetToken ( ctx , user ) if err != nil { return nil , err } return thread . NewTokenContext ( ctx , token ), nil } You can also store and reuse the token, but it needs to be attached the the context before future API calls.","title":"Request and specify a user token"},{"location":"tutorials/go/getting-started/#create-a-new-db","text":"Let's put it all together and then create a new Thread database for our user. package main import ( \"context\" \"crypto/rand\" \"crypto/tls\" \"fmt\" \"time\" crypto \"github.com/libp2p/go-libp2p-crypto\" \"github.com/textileio/go-threads/api/client\" \"github.com/textileio/go-threads/core/thread\" \"github.com/textileio/textile/api/common\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials\" ) func GetRandomUser () ( thread . Identity , error ) { privateKey , _ , err := crypto . GenerateEd25519Key ( rand . Reader ) if err != nil { return nil , err } myIdentity := thread . NewLibp2pIdentity ( privateKey ) return myIdentity , nil } func NewUserAuthCtx ( ctx context . Context , userGroupKey string , userGroupSecret string ) ( context . Context , error ) { // Add our user group key to the context ctx = common . NewAPIKeyContext ( ctx , userGroupKey ) // Add a signature using our user group secret return common . CreateAPISigContext ( ctx , time . Now (). Add ( time . Minute ), userGroupSecret ) } func NewTokenCtx ( ctx context . Context , cli * client . Client , user thread . Identity ) ( context . Context , error ){ // Generate a new token for the user token , err := cli . GetToken ( ctx , user ) if err != nil { return nil , err } return thread . NewTokenContext ( ctx , token ), nil } func main () { // Create an API Client creds := credentials . NewTLS ( & tls . Config {}) auth := common . Credentials {} opts := [] grpc . DialOption { grpc . WithTransportCredentials ( creds ), grpc . WithPerRPCCredentials ( auth )} cli , err := client . NewClient ( \"api.hub.textile.io:443\" , opts ... ) if err != nil { panic ( err ) } user , err := GetRandomUser () if err != nil { panic ( err ) } authCtx , err := NewUserAuthCtx ( context . Background (), \"<key>\" , \"<secret>\" ) if err != nil { panic ( err ) } tokenCtx , err := NewTokenCtx ( authCtx , cli , user ) if err != nil { panic ( err ) } // Generate a new thread ID threadID := thread . NewIDV1 ( thread . Raw , 32 ) // Create your new thread err = cli . NewDB ( tokenCtx , threadID ) if err != nil { panic ( err ) } fmt . Println ( \"> Success!\" ) fmt . Println ( threadID ) } Please refer to the ThreadDB and Buckets docs for more.","title":"Create a new DB"},{"location":"tutorials/hub/development-mode/","text":"Development mode \u00b6 This section will cover how to get started in development mode by using insecure API keys. To start running your app, you'll need API keys. The Hub generates API keys that grant your app access to your APIs. There are two flavors of API keys: Account keys that are not ideal for apps since they grant admin access to your developer account. User group keys which are designed for apps where you want one set of keys to grant API access for many users. API Access \u00b6 User group keys \u00b6 User group keys come with a key and a secret . You never want to share your secret or save it in a place where it may be exposed. However, when you are in development mode, you can create keys that have signing disabled , meaning no secret is required. This is ideal during development or working with your internal team because it will make your first steps of app development a bit faster. Create insecure keys \u00b6 You can create your insecure keys during the key generation step, simply select N for requiring signature authentication. \u25b6 hub keys create \u2714 user group ? Require Signature Authentication ( recommended ) ? [ y/N ] N \u2588 Use insecure keys \u00b6 Now you can use the insecure keys for building your app without having to first setup a user login flow. However, when you are ready to deploy your app, be sure to use a new set of keys. You can read more about production setup in the next part of this tutorial . Start building \u00b6 With your insecure API key, you have everything you need to start building with the Hub APIs, Threads, and Buckets. Using the API \u00b6 Now your users have identities and they've verified themselves. Next, you'll want to start creating Buckets and ThreadDBs for your user. Let's start using the Hub from inside the web app. Install dependencies # Textile libraries npm install --save @textile/hub Connect to the API Now, you just need to create a KeyInfo object above to connect to the API. import { Client , Identity , KeyInfo } from \"@textile/hub\" ; async function authorize ( key : KeyInfo , identity : Identity ) { const client = await Client . withKeyInfo ( key ); await client . getToken ( identity ); return client ; } The KeyInfo you supply to the API will look like: import { KeyInfo } from \"@textile/hub\" ; const keyinfo : KeyInfo = { key : \"INSECURE API KEY\" , }; Your user is now setup to start creating Threads and Buckets that replicate on the Hub API! Read more tutorials or jump over to the js-threads docs to keep building.","title":"Development mode"},{"location":"tutorials/hub/development-mode/#development-mode","text":"This section will cover how to get started in development mode by using insecure API keys. To start running your app, you'll need API keys. The Hub generates API keys that grant your app access to your APIs. There are two flavors of API keys: Account keys that are not ideal for apps since they grant admin access to your developer account. User group keys which are designed for apps where you want one set of keys to grant API access for many users.","title":"Development mode"},{"location":"tutorials/hub/development-mode/#api-access","text":"","title":"API Access"},{"location":"tutorials/hub/development-mode/#user-group-keys","text":"User group keys come with a key and a secret . You never want to share your secret or save it in a place where it may be exposed. However, when you are in development mode, you can create keys that have signing disabled , meaning no secret is required. This is ideal during development or working with your internal team because it will make your first steps of app development a bit faster.","title":"User group keys"},{"location":"tutorials/hub/development-mode/#create-insecure-keys","text":"You can create your insecure keys during the key generation step, simply select N for requiring signature authentication. \u25b6 hub keys create \u2714 user group ? Require Signature Authentication ( recommended ) ? [ y/N ] N \u2588","title":"Create insecure keys"},{"location":"tutorials/hub/development-mode/#use-insecure-keys","text":"Now you can use the insecure keys for building your app without having to first setup a user login flow. However, when you are ready to deploy your app, be sure to use a new set of keys. You can read more about production setup in the next part of this tutorial .","title":"Use insecure keys"},{"location":"tutorials/hub/development-mode/#start-building","text":"With your insecure API key, you have everything you need to start building with the Hub APIs, Threads, and Buckets.","title":"Start building"},{"location":"tutorials/hub/development-mode/#using-the-api","text":"Now your users have identities and they've verified themselves. Next, you'll want to start creating Buckets and ThreadDBs for your user. Let's start using the Hub from inside the web app. Install dependencies # Textile libraries npm install --save @textile/hub Connect to the API Now, you just need to create a KeyInfo object above to connect to the API. import { Client , Identity , KeyInfo } from \"@textile/hub\" ; async function authorize ( key : KeyInfo , identity : Identity ) { const client = await Client . withKeyInfo ( key ); await client . getToken ( identity ); return client ; } The KeyInfo you supply to the API will look like: import { KeyInfo } from \"@textile/hub\" ; const keyinfo : KeyInfo = { key : \"INSECURE API KEY\" , }; Your user is now setup to start creating Threads and Buckets that replicate on the Hub API! Read more tutorials or jump over to the js-threads docs to keep building.","title":"Using the API"},{"location":"tutorials/hub/pki-identities/","text":"User identities \u00b6 This section will focus on how to create user identities with private-keys. The Textile Hub supports public-key infrastructure (PKI), which allows your app to integrate different PKI-based user identity providers (e.g. Metamask, 3Box, uPort, Blockstack) or roll your own. Most of our examples use a simple, platform-agnostic keypair identity based on ed25519 and by extending the Noble ed25519 library . Key-based identity access \u00b6 The Hub can help verify that users are who they claim to be by using encryption. The general flow is as follows: A user attempts to sign-in by providing their public key . Your app creates a one-time challenge for the users. The user signs the challenge with their private key to generate credentials . Your app verifies the credentials . Below, we'll simplify these steps by using the Hub's helpful token generation endpoint that also does credential verification. Generating an identity \u00b6 In this example, we'll use an identity based on an ed25519 signature scheme and made available through the @textile/hub library. Install dependency npm install --save @textile/hub Generating Identities You can use the PrivateKey utility to generate random new identities (private and public keys) and later, to sign challenges to prove private key ownership. import { PrivateKey } from \"@textile/hub\" ; async function example() { /** Random new identity */ const identity = await PrivateKey . fromRandom (); /** Convert to string. */ const identityString = identity . toString (); /** Restore an identity object from a string */ const restored = PrivateKey . fromString ( identityString ); } All of the instances above are different representations of the same user-generated by PrivateKey.fromRandom() . Each instance holds a different copy of the user's private key and therefore should remain private between your app and your user. Caching user identity \u00b6 You can add simple client-side caching to store a user's identity in the browser and restore it when the user returns to the app. Warning localStorage isn't a secure place to store secrets. localStorage access is also not guaranteed and may be cleared by the browser, the system, or the users. You should provide alternative storage mechanisms if maintaining identity (and therefore data ownership and access) over time is important. import { PrivateKey } from \"@textile/hub\" ; const getIdentity = async () : Promise < PrivateKey > => { /** Restore any cached user identity first */ const cached = localStorage . getItem ( \"user-private-identity\" ); if ( cached !== null ) { /** Convert the cached identity string to a PrivateKey and return */ return PrivateKey . fromString ( cached ); } /** No cached identity existed, so create a new one */ const identity = await PrivateKey . fromRandom (); /** Add the string copy to the cache */ localStorage . setItem ( \"user-private-identity\" , identity . toString ()); /** Return the random identity */ return identity ; }; Signing transactions \u00b6 The PrivateKey object contains a signing method that allows your app to sign arbitrary bytes for your users. You can create your own identity verification endpoint or use the Hub's token endpoint to verify the credentials. import { PrivateKey } from \"@textile/hub\" ; async function sign ( identity : PrivateKey ) { const challenge = Buffer . from ( \"Sign this string\" ); const credentials = identity . sign ( challenge ); return credentials ; } Advanced identity providers \u00b6 Public key provider \u00b6 The code below shows two generic identity interfaces. You can import these interfaces from @textile/hub . // Read more https://textileio.github.io/js-textile/docs/hub.public interface Public { verify ( data : Buffer , sig : Buffer ) : Promise < boolean > ; } // Read more https://textileio.github.io/js-textile/docs/hub.identity interface Identity { sign ( data : Buffer ) : Promise < Buffer > ; public : Public ; } Identity here represents any entity capable of signing a message. It requires that the implementer is capable of returning an associated public key for verification. This interface design was inspired by public key infrastructure . In many cases, the Identity will just be a private key, but callers can use any setup that suits their needs. The default implementation is based on the Noble ed25519 library but many developers will want to use alternative identity provides, such as 3box/Ceramic , Fortmatic , and existing private/public key-pair, or a web3 provider such as Metamask . Textile Hub also provides email-based identities. Metamask \u00b6 One issue with the above workflow is that you need to help users store and recover their private keys. You could do this with your user model stored over an API. Alternatively, you can use any key-pair manager, such as Metamask . There are a few steps to generate a Textile compatible identity from the Metamask API. We've provided an example using Metamask here . In the above example, we allow you to generate a new ed25519 key for your users based on their Ethereum address in Metamask. This key is deterministic, meaning that as long as your user maintains access to their address in Metamask and their account secret, they can recover the same ed25519 key. This is handy if you don't want to store your user's private keys outside the app or use unreliable storage (e.g. local storage in browsers). It does this as follows: It prompts the user for a new secret . The secret helps ensure that another app cannot easily trick the user into generating their ed25519 key. The app then creates a unique string that contains a hashed version of the secret, the app name, and some additional text . The app can regenerate this string at any time in the future if the user supplies their secret . The unique string is then signed with the user's Ethereum address by using the Metamask API . The resulting signature is used to generate an ed25519 key that can be used as an identity with all Textile APIs. There are some benefits to this approach over using the ethereum address directly. An obvious one is that there is no public association between an ethereum address and the ed25519 key. 3Box \u00b6 Another good starting point is with 3Box SDK . 3Box manages a cluster of nodes where web3 users can push small bits of information. 3Box provides some helpful abstractions that integrate with Metamask and can help you create, manage, and recover keys for your users. In this approach, a user with a 3Box identity can use that identity to create and track Buckets or Threads generated on Textile. We've provided an example using 3Box here . Info As of the time of writing, November 16, 2020, 3Box does not have Typescript typings available. import { PrivateKey } from '@textile/hub' const Box = require ( \"3box\" ); const getIdentity = async () : Promise < PrivateKey > => { const box = await Box . create (( window as any ). ethereum ) const [ address ] = await ( window as any ). ethereum . enable () await box . auth ([], { address }) const space = await box . openSpace ( 'io-textile-3box-docs' ) await box . syncDone let identity : PrivateKey try { var storedIdent = await space . private . get ( \"ed25519-identity\" ) if ( storedIdent === null ) { throw new Error ( 'No identity' ) } identity = await PrivateKey . fromString ( storedIdent ) return identity } catch ( e ) { try { identity = await PrivateKey . fromRandom () const identityString = identity . toString () await space . private . set ( \"ed25519-identity\" , identityString ) } catch ( err ) { return err . message } } } Next steps \u00b6 Time to setup your app in development mode .","title":"User identities"},{"location":"tutorials/hub/pki-identities/#user-identities","text":"This section will focus on how to create user identities with private-keys. The Textile Hub supports public-key infrastructure (PKI), which allows your app to integrate different PKI-based user identity providers (e.g. Metamask, 3Box, uPort, Blockstack) or roll your own. Most of our examples use a simple, platform-agnostic keypair identity based on ed25519 and by extending the Noble ed25519 library .","title":"User identities"},{"location":"tutorials/hub/pki-identities/#key-based-identity-access","text":"The Hub can help verify that users are who they claim to be by using encryption. The general flow is as follows: A user attempts to sign-in by providing their public key . Your app creates a one-time challenge for the users. The user signs the challenge with their private key to generate credentials . Your app verifies the credentials . Below, we'll simplify these steps by using the Hub's helpful token generation endpoint that also does credential verification.","title":"Key-based identity access"},{"location":"tutorials/hub/pki-identities/#generating-an-identity","text":"In this example, we'll use an identity based on an ed25519 signature scheme and made available through the @textile/hub library. Install dependency npm install --save @textile/hub Generating Identities You can use the PrivateKey utility to generate random new identities (private and public keys) and later, to sign challenges to prove private key ownership. import { PrivateKey } from \"@textile/hub\" ; async function example() { /** Random new identity */ const identity = await PrivateKey . fromRandom (); /** Convert to string. */ const identityString = identity . toString (); /** Restore an identity object from a string */ const restored = PrivateKey . fromString ( identityString ); } All of the instances above are different representations of the same user-generated by PrivateKey.fromRandom() . Each instance holds a different copy of the user's private key and therefore should remain private between your app and your user.","title":"Generating an identity"},{"location":"tutorials/hub/pki-identities/#caching-user-identity","text":"You can add simple client-side caching to store a user's identity in the browser and restore it when the user returns to the app. Warning localStorage isn't a secure place to store secrets. localStorage access is also not guaranteed and may be cleared by the browser, the system, or the users. You should provide alternative storage mechanisms if maintaining identity (and therefore data ownership and access) over time is important. import { PrivateKey } from \"@textile/hub\" ; const getIdentity = async () : Promise < PrivateKey > => { /** Restore any cached user identity first */ const cached = localStorage . getItem ( \"user-private-identity\" ); if ( cached !== null ) { /** Convert the cached identity string to a PrivateKey and return */ return PrivateKey . fromString ( cached ); } /** No cached identity existed, so create a new one */ const identity = await PrivateKey . fromRandom (); /** Add the string copy to the cache */ localStorage . setItem ( \"user-private-identity\" , identity . toString ()); /** Return the random identity */ return identity ; };","title":"Caching user identity"},{"location":"tutorials/hub/pki-identities/#signing-transactions","text":"The PrivateKey object contains a signing method that allows your app to sign arbitrary bytes for your users. You can create your own identity verification endpoint or use the Hub's token endpoint to verify the credentials. import { PrivateKey } from \"@textile/hub\" ; async function sign ( identity : PrivateKey ) { const challenge = Buffer . from ( \"Sign this string\" ); const credentials = identity . sign ( challenge ); return credentials ; }","title":"Signing transactions"},{"location":"tutorials/hub/pki-identities/#advanced-identity-providers","text":"","title":"Advanced identity providers"},{"location":"tutorials/hub/pki-identities/#public-key-provider","text":"The code below shows two generic identity interfaces. You can import these interfaces from @textile/hub . // Read more https://textileio.github.io/js-textile/docs/hub.public interface Public { verify ( data : Buffer , sig : Buffer ) : Promise < boolean > ; } // Read more https://textileio.github.io/js-textile/docs/hub.identity interface Identity { sign ( data : Buffer ) : Promise < Buffer > ; public : Public ; } Identity here represents any entity capable of signing a message. It requires that the implementer is capable of returning an associated public key for verification. This interface design was inspired by public key infrastructure . In many cases, the Identity will just be a private key, but callers can use any setup that suits their needs. The default implementation is based on the Noble ed25519 library but many developers will want to use alternative identity provides, such as 3box/Ceramic , Fortmatic , and existing private/public key-pair, or a web3 provider such as Metamask . Textile Hub also provides email-based identities.","title":"Public key provider"},{"location":"tutorials/hub/pki-identities/#metamask","text":"One issue with the above workflow is that you need to help users store and recover their private keys. You could do this with your user model stored over an API. Alternatively, you can use any key-pair manager, such as Metamask . There are a few steps to generate a Textile compatible identity from the Metamask API. We've provided an example using Metamask here . In the above example, we allow you to generate a new ed25519 key for your users based on their Ethereum address in Metamask. This key is deterministic, meaning that as long as your user maintains access to their address in Metamask and their account secret, they can recover the same ed25519 key. This is handy if you don't want to store your user's private keys outside the app or use unreliable storage (e.g. local storage in browsers). It does this as follows: It prompts the user for a new secret . The secret helps ensure that another app cannot easily trick the user into generating their ed25519 key. The app then creates a unique string that contains a hashed version of the secret, the app name, and some additional text . The app can regenerate this string at any time in the future if the user supplies their secret . The unique string is then signed with the user's Ethereum address by using the Metamask API . The resulting signature is used to generate an ed25519 key that can be used as an identity with all Textile APIs. There are some benefits to this approach over using the ethereum address directly. An obvious one is that there is no public association between an ethereum address and the ed25519 key.","title":"Metamask"},{"location":"tutorials/hub/pki-identities/#3box","text":"Another good starting point is with 3Box SDK . 3Box manages a cluster of nodes where web3 users can push small bits of information. 3Box provides some helpful abstractions that integrate with Metamask and can help you create, manage, and recover keys for your users. In this approach, a user with a 3Box identity can use that identity to create and track Buckets or Threads generated on Textile. We've provided an example using 3Box here . Info As of the time of writing, November 16, 2020, 3Box does not have Typescript typings available. import { PrivateKey } from '@textile/hub' const Box = require ( \"3box\" ); const getIdentity = async () : Promise < PrivateKey > => { const box = await Box . create (( window as any ). ethereum ) const [ address ] = await ( window as any ). ethereum . enable () await box . auth ([], { address }) const space = await box . openSpace ( 'io-textile-3box-docs' ) await box . syncDone let identity : PrivateKey try { var storedIdent = await space . private . get ( \"ed25519-identity\" ) if ( storedIdent === null ) { throw new Error ( 'No identity' ) } identity = await PrivateKey . fromString ( storedIdent ) return identity } catch ( e ) { try { identity = await PrivateKey . fromRandom () const identityString = identity . toString () await space . private . set ( \"ed25519-identity\" , identityString ) } catch ( err ) { return err . message } } }","title":"3Box"},{"location":"tutorials/hub/pki-identities/#next-steps","text":"Time to setup your app in development mode .","title":"Next steps"},{"location":"tutorials/hub/production-auth/","text":"Production mode \u00b6 This section will cover how to work in a production environment with secure keys, unlike using insecure keys in development mode . To work with API keys in a production environment: Generate a new API key and secret that has mandatory signing enabled. Setup an authorization endpoint that will hold your API secret and any optional user model for your app. Add a login step to your app that will use the new endpoint to authorize users in your app. Differences from development mode \u00b6 Users need a signature to accompany their API requests. Those signatures can only be created with your API secret and will expire. You'll need to re-verify the signatures occasionally. For this, we'll move from using the withKeyInfo APIs to a new one called withUserAuth that can request updated signatures in your app. withUserAuth is also designed to work without access to your secret , so your app can authorize users on your back-end and provide API key signatures on demand. Other than that, all the APIs work the same way. User identity \u00b6 If you've followed the tutorials up until now, you're already using PKI , so your users will only ever share their public key with your API (or any API). Therefore, you just need to verify that they hold the private key linked with the public key. Otherwise, users could spoof your system very easily. From there, you can provide Hub API access to your users based on that verification. Authentication server \u00b6 Now, we'll setup a simple server that accepts a user's public key, verifies that they control the private key (via a challenge), and then grant the user access to the Hub APIs. The user can pass the result (a UserAuth object) to the API and start creating Threads and Buckets. Setup \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users access the Hub APIs. Consider creating the key in an organization and not your personal account so you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but it could just as easily be written with Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities used in example npm install --save dotenv emittery isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser koa-route koa-websocket Environment variables We use a .env file in the root of our project repo. The values in this file will be pulled into the app each time it's run. This is where you'll add your Hub API key and secret. Danger The .env file should be added to your .gitignore so your key and secret are never shared. Contents of .env . USER_API_KEY=<insert user group key> USER_API_SECRET=<insert user group secret> Create the server \u00b6 In our project setup, our main server is defined in src/index.ts . Unlike the simple credentials example , our server needs to handle two-way communication with the client during identity verification. The flow is as follows: The client makes a login request . The server initiates the request with the Hub and gets back an identity challenge . The server passes the challenge to the client . The client confirms they own their private key by signing the challenge and passing it back to the server . The server passes it to the Hub. If successful , a token is generated for the user and the server generates API credentials and passes the credentials, token, and API key back to the client . Now, the client can use the Hub APIs directly! It sounds complicated, but you'll see it happens very fast with only a few lines of code. In our example, we use websockets to enable the multi-step communication between the server and the client. /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) import koa from \"koa\" import Router from \"koa-router\" import logger from \"koa-logger\" import json from \"koa-json\" import bodyParser from \"koa-bodyparser\" import route from \"koa-route\" import websockify from \"koa-websocket\" import Emittery from \"emittery\" import dotenv from \"dotenv\" import { Client , UserAuth } from \"@textile/hub\" /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 /** Init Koa with Websocket support */ const app = websockify ( new koa ()) /** Middlewares */ app . use ( json () ) app . use ( logger () ) app . use ( bodyParser () ) /** * Add websocket login endpoint */ /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) ) Add a websocket login handler \u00b6 Next, we'll add a websocket endpoint to our server. Note the Add websocket login endpoint location in the server code above. The primary step the server needs to do is accept a pubkey and issue a new challenge back to the client. When successful, new API credentials can be handed to the client. View the full code example in the repo . import { Client } from \"@textile/hub\" ; async function example ( pubkey : string ) { /** * Init new Hub API Client with the user group API keys */ const client = await Client . withKeyInfo ({ key : \"USER_API_KEY\" , secret : \"USER_API_SECRET\" , }); /** * Request a token from the Hub based on the user public key */ const token = await client . getTokenChallenge ( pubkey , /** The callback passes the challenge back to the client */ ( challenge : Buffer ) => { return new Promise (( resolve , reject ) => { // Send the challenge back to the client and // resolve(Buffer.from(sig)) resolve (); }); } ); } Now when you refresh your locally running server, you should have a websocket endpoint for client token creation. Wrap-up \u00b6 With the user verified in your system, you can keep their public key without any security issues. However, you should never trust an API call only by the public key, the challenge step is critical . The token provided in the response should be considered a secret that only should be shared with a single user. It does not expire. Example on GitHub \u00b6 If you'd like to learn more, we've provided a fully working example on GitHub: Login API Source code for login and Hub credentials endpoint. Client (app) authentication \u00b6 Now that our credentials endpoint is setup, we need to generate new credentials for each user's identity. A basic client needs to be able to: Submit a login request . Handle a challenge request from the server. Sign the challenge . Return it over websockets . We'll create a login function that handles the back and forth of the websocket and can combine with the withUserAuth function. Login function \u00b6 import { Buckets , Client , Identity , PrivateKey , UserAuth } from \"@textile/hub\" ; /** * loginWithChallenge uses websocket to initiate and respond to * a challenge for the user based on their keypair. * * Read more about setting up user verification here: * https://docs.textile.io/tutorials/hub/web-app/ */ const loginWithChallenge = ( id : Identity ) => { return () : Promise < UserAuth > => { return new Promise (( resolve , reject ) => { /** * Configured for our development server * * Note: this should be upgraded to wss for production environments. */ const socketUrl = `ws://localhost:3001/ws/userauth` ; /** Initialize our websocket connection */ const socket = new WebSocket ( socketUrl ); /** Wait for our socket to open successfully */ socket . onopen = () => { /** Get public key string */ const publicKey = id . public . toString (); /** Send a new token request */ socket . send ( JSON . stringify ({ pubkey : publicKey , type : \"token\" , }) ); /** Listen for messages from the server */ socket . onmessage = async ( event ) => { const data = JSON . parse ( event . data ); switch ( data . type ) { /** Error never happen :) */ case \"error\" : { reject ( data . value ); break ; } /** The server issued a new challenge */ case \"challenge\" : { /** Convert the challenge json to a Buffer */ const buf = Buffer . from ( data . value ); /** User our identity to sign the challenge */ const signed = await id . sign ( buf ); /** Send the signed challenge back to the server */ socket . send ( JSON . stringify ({ type : \"challenge\" , sig : Buffer.from ( signed ). toJSON (), }) ); break ; } /** New token generated */ case \"token\" : { resolve ( data . value ); break ; } } }; }; }); }; }; const setupThreads = async ( identity : Identity ) => { /** * By passing a callback, the Threads library can refresh * the api signature whenever expiring. */ const callback = loginWithChallenge ( identity ); const client = Client . withUserAuth ( callback ); client . getToken ( identity ); return client ; }; Convert Buckets from insecure API to secure API \u00b6 If you're looking to convert your Buckets from using the insecure API to the secure one, see the code below: Insecure keys example When using your insecure API key, you typically initialized Buckets like the following: import { Buckets , Identity , KeyInfo } from \"@textile/hub\" ; const init = async ( key : KeyInfo , identity : Identity ) => { const buckets = await Buckets . withKeyInfo ( key ); await buckets . getToken ( identity ); return buckets ; }; Secure keys example You'll now replace withKeyInfo and getToken with the single, withUserAuth method that requires the callback method: import { Buckets , UserAuth } from \"@textile/hub\" ; const init = ( getUserAuth : () => Promise < UserAuth > ) => { const buckets = Buckets . withUserAuth ( getUserAuth ); return buckets ; }; Wrap-up \u00b6 Now you've had a chance to see how identities work with API keys to provide Hub resources to your users. If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. Example on GitHub \u00b6 git clone git@github.com:textileio/js-examples.git cd js-examples/hub-browser-auth-app Explore the repo Clone the source code for a server and client using the Hub.","title":"Production authentication"},{"location":"tutorials/hub/production-auth/#production-mode","text":"This section will cover how to work in a production environment with secure keys, unlike using insecure keys in development mode . To work with API keys in a production environment: Generate a new API key and secret that has mandatory signing enabled. Setup an authorization endpoint that will hold your API secret and any optional user model for your app. Add a login step to your app that will use the new endpoint to authorize users in your app.","title":"Production mode"},{"location":"tutorials/hub/production-auth/#differences-from-development-mode","text":"Users need a signature to accompany their API requests. Those signatures can only be created with your API secret and will expire. You'll need to re-verify the signatures occasionally. For this, we'll move from using the withKeyInfo APIs to a new one called withUserAuth that can request updated signatures in your app. withUserAuth is also designed to work without access to your secret , so your app can authorize users on your back-end and provide API key signatures on demand. Other than that, all the APIs work the same way.","title":"Differences from development mode"},{"location":"tutorials/hub/production-auth/#user-identity","text":"If you've followed the tutorials up until now, you're already using PKI , so your users will only ever share their public key with your API (or any API). Therefore, you just need to verify that they hold the private key linked with the public key. Otherwise, users could spoof your system very easily. From there, you can provide Hub API access to your users based on that verification.","title":"User identity"},{"location":"tutorials/hub/production-auth/#authentication-server","text":"Now, we'll setup a simple server that accepts a user's public key, verifies that they control the private key (via a challenge), and then grant the user access to the Hub APIs. The user can pass the result (a UserAuth object) to the API and start creating Threads and Buckets.","title":"Authentication server"},{"location":"tutorials/hub/production-auth/#setup","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users access the Hub APIs. Consider creating the key in an organization and not your personal account so you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but it could just as easily be written with Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities used in example npm install --save dotenv emittery isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser koa-route koa-websocket Environment variables We use a .env file in the root of our project repo. The values in this file will be pulled into the app each time it's run. This is where you'll add your Hub API key and secret. Danger The .env file should be added to your .gitignore so your key and secret are never shared. Contents of .env . USER_API_KEY=<insert user group key> USER_API_SECRET=<insert user group secret>","title":"Setup"},{"location":"tutorials/hub/production-auth/#create-the-server","text":"In our project setup, our main server is defined in src/index.ts . Unlike the simple credentials example , our server needs to handle two-way communication with the client during identity verification. The flow is as follows: The client makes a login request . The server initiates the request with the Hub and gets back an identity challenge . The server passes the challenge to the client . The client confirms they own their private key by signing the challenge and passing it back to the server . The server passes it to the Hub. If successful , a token is generated for the user and the server generates API credentials and passes the credentials, token, and API key back to the client . Now, the client can use the Hub APIs directly! It sounds complicated, but you'll see it happens very fast with only a few lines of code. In our example, we use websockets to enable the multi-step communication between the server and the client. /** Provides nodejs access to a global Websocket value, required by Hub API */ ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) import koa from \"koa\" import Router from \"koa-router\" import logger from \"koa-logger\" import json from \"koa-json\" import bodyParser from \"koa-bodyparser\" import route from \"koa-route\" import websockify from \"koa-websocket\" import Emittery from \"emittery\" import dotenv from \"dotenv\" import { Client , UserAuth } from \"@textile/hub\" /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 /** Init Koa with Websocket support */ const app = websockify ( new koa ()) /** Middlewares */ app . use ( json () ) app . use ( logger () ) app . use ( bodyParser () ) /** * Add websocket login endpoint */ /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" ) )","title":"Create the server"},{"location":"tutorials/hub/production-auth/#add-a-websocket-login-handler","text":"Next, we'll add a websocket endpoint to our server. Note the Add websocket login endpoint location in the server code above. The primary step the server needs to do is accept a pubkey and issue a new challenge back to the client. When successful, new API credentials can be handed to the client. View the full code example in the repo . import { Client } from \"@textile/hub\" ; async function example ( pubkey : string ) { /** * Init new Hub API Client with the user group API keys */ const client = await Client . withKeyInfo ({ key : \"USER_API_KEY\" , secret : \"USER_API_SECRET\" , }); /** * Request a token from the Hub based on the user public key */ const token = await client . getTokenChallenge ( pubkey , /** The callback passes the challenge back to the client */ ( challenge : Buffer ) => { return new Promise (( resolve , reject ) => { // Send the challenge back to the client and // resolve(Buffer.from(sig)) resolve (); }); } ); } Now when you refresh your locally running server, you should have a websocket endpoint for client token creation.","title":"Add a websocket login handler"},{"location":"tutorials/hub/production-auth/#wrap-up","text":"With the user verified in your system, you can keep their public key without any security issues. However, you should never trust an API call only by the public key, the challenge step is critical . The token provided in the response should be considered a secret that only should be shared with a single user. It does not expire.","title":"Wrap-up"},{"location":"tutorials/hub/production-auth/#example-on-github","text":"If you'd like to learn more, we've provided a fully working example on GitHub:","title":"Example on GitHub"},{"location":"tutorials/hub/production-auth/#client-app-authentication","text":"Now that our credentials endpoint is setup, we need to generate new credentials for each user's identity. A basic client needs to be able to: Submit a login request . Handle a challenge request from the server. Sign the challenge . Return it over websockets . We'll create a login function that handles the back and forth of the websocket and can combine with the withUserAuth function.","title":"Client (app) authentication"},{"location":"tutorials/hub/production-auth/#login-function","text":"import { Buckets , Client , Identity , PrivateKey , UserAuth } from \"@textile/hub\" ; /** * loginWithChallenge uses websocket to initiate and respond to * a challenge for the user based on their keypair. * * Read more about setting up user verification here: * https://docs.textile.io/tutorials/hub/web-app/ */ const loginWithChallenge = ( id : Identity ) => { return () : Promise < UserAuth > => { return new Promise (( resolve , reject ) => { /** * Configured for our development server * * Note: this should be upgraded to wss for production environments. */ const socketUrl = `ws://localhost:3001/ws/userauth` ; /** Initialize our websocket connection */ const socket = new WebSocket ( socketUrl ); /** Wait for our socket to open successfully */ socket . onopen = () => { /** Get public key string */ const publicKey = id . public . toString (); /** Send a new token request */ socket . send ( JSON . stringify ({ pubkey : publicKey , type : \"token\" , }) ); /** Listen for messages from the server */ socket . onmessage = async ( event ) => { const data = JSON . parse ( event . data ); switch ( data . type ) { /** Error never happen :) */ case \"error\" : { reject ( data . value ); break ; } /** The server issued a new challenge */ case \"challenge\" : { /** Convert the challenge json to a Buffer */ const buf = Buffer . from ( data . value ); /** User our identity to sign the challenge */ const signed = await id . sign ( buf ); /** Send the signed challenge back to the server */ socket . send ( JSON . stringify ({ type : \"challenge\" , sig : Buffer.from ( signed ). toJSON (), }) ); break ; } /** New token generated */ case \"token\" : { resolve ( data . value ); break ; } } }; }; }); }; }; const setupThreads = async ( identity : Identity ) => { /** * By passing a callback, the Threads library can refresh * the api signature whenever expiring. */ const callback = loginWithChallenge ( identity ); const client = Client . withUserAuth ( callback ); client . getToken ( identity ); return client ; };","title":"Login function"},{"location":"tutorials/hub/production-auth/#convert-buckets-from-insecure-api-to-secure-api","text":"If you're looking to convert your Buckets from using the insecure API to the secure one, see the code below: Insecure keys example When using your insecure API key, you typically initialized Buckets like the following: import { Buckets , Identity , KeyInfo } from \"@textile/hub\" ; const init = async ( key : KeyInfo , identity : Identity ) => { const buckets = await Buckets . withKeyInfo ( key ); await buckets . getToken ( identity ); return buckets ; }; Secure keys example You'll now replace withKeyInfo and getToken with the single, withUserAuth method that requires the callback method: import { Buckets , UserAuth } from \"@textile/hub\" ; const init = ( getUserAuth : () => Promise < UserAuth > ) => { const buckets = Buckets . withUserAuth ( getUserAuth ); return buckets ; };","title":"Convert Buckets from insecure API to secure API"},{"location":"tutorials/hub/production-auth/#wrap-up_1","text":"Now you've had a chance to see how identities work with API keys to provide Hub resources to your users. If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub.","title":"Wrap-up"},{"location":"tutorials/hub/production-auth/#example-on-github_1","text":"git clone git@github.com:textileio/js-examples.git cd js-examples/hub-browser-auth-app","title":"Example on GitHub"},{"location":"tutorials/hub/simple-credentials-endpoint/","text":"Create a simple credentials endpoint \u00b6 The simple credentials endpoint requires no user-identity to be sent to the server. It simply receives a request for new API credentials, uses the key and secret, and then returns the credentials to the client. This type of flow is useful for developers or apps with an existing user-validation flow, or who are able to utilize domain whitelisting and/or are hosting their own app. Setup \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser Environment variables \u00b6 We'll use a .env file in the root of our project repo where you'll add your Hub API key and secret. The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=alk3rlkjvl323r09fqpoweruw34 USER_API_SECRET=balkweop3jflk9f43lkjs9df2jlght94nzlkv93s Replace the example key and secret values with values you create usint the CLI Create the server \u00b6 In our project setup, our main server is defined in src/index.ts . /** Import our server libraries */ import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; /** For using values in our .env */ import dotenv from \"dotenv\" ; /** Textile libraries */ import { Client , createAPISig , PrivateKey } from \"@textile/hub\" ; /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa */ const app = new koa (); /** Middlewares */ app . use ( json ()); app . use ( logger ()); app . use ( bodyParser ()); /** * Start API Routes * * All prefixed with `/api/` */ const api = new Router ({ prefix : \"/api\" , }); /** * Basic foo-bar endpoint * * https://localhost:3000/api/foo */ api . get ( \"/foo\" , async ( ctx : koa.Context , next : () => Promise < any > ) => { ctx . body = { foo : \"bar\" }; await next (); }); /** * Add credentials API here */ /** Tell Koa to use the API routes we generate */ app . use ( api . routes ()). use ( api . allowedMethods ()); /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" )); We now have our basic server setup, we can run it and visit http://localhost/api/foo . ts-node src/index.ts Info Follow your Typescript setup guide for specific ways of launching the server. Add the credentials endpoint \u00b6 Next, we'll add an endpoint so the client can get new or refreshed credentials. Note the Add credentials API here location in the server code above. /** * Add credentials API here */ api . get ( \"/credentials\" , async ( ctx : koa.Context , next : () => Promise < any > ) => { // Custom validation could be done here... /** Get API authorization for the user */ const expiration = new Date ( Date . now () + 60 * seconds ); const auth = await createAPISig ( process . env . USER_API_SECRET , expiration ); /** Include the API KEY in the auth payload */ const credentials = { ... auth , key : process.env.USER_API_KEY , }; /** Return the credentials in a JSON object */ ctx . body = credentials ; await next (); }); Now when you refresh your locally running server you should be able to visit the following and receive valid credentials. http://localhost:3000/api/credentials Response: { \"key\" : \"<your user group api key>\" , \"msg\" : \"<your credentials expiration>\" , \"sig\" : \"<the api signature>\" } Create a client \u00b6 Back in the browser, you can now make requests to your credentials endpoint. From their, each user can use the Hub token endpoint directly and begin making calls to the Hub APIs. import { Client , UserAuth } from \"@textile/hub\" ; const createCredentials = async () : Promise < UserAuth > => { const response = await fetch ( `/api/credentials` , { method : \"GET\" , }); const userAuth = await response . json (); return userAuth ; }; /** Use the simple auth REST endpoint to get API access */ console . log ( \"Verified on Textile API\" ); displayStatus (); /** The simple auth endpoint generates a user's Hub API Token */ const client = Client . withUserAuth ( createCredentials ); /** See identity tutorial */ const token = await client . getToken ( identity ); /** Now, full auth object includes the token */ auth = { ... this . auth , token : token , }; GitHub Example \u00b6 If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. The simple credentials endpoint is part of a more complete example, you can see it here. Simple Credentials API Source code for simple Hub credentials endpoint.","title":"Create a simple credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-a-simple-credentials-endpoint","text":"The simple credentials endpoint requires no user-identity to be sent to the server. It simply receives a request for new API credentials, uses the key and secret, and then returns the credentials to the client. This type of flow is useful for developers or apps with an existing user-validation flow, or who are able to utilize domain whitelisting and/or are hosting their own app.","title":"Create a simple credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#setup","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A user group key . This is how your users will be able to access your Hub APIs. Consider creating the key in an organization not your personal account so that you can invite collaborators later. A new Typescript project . We recommend using Typescript, as Textile libraries are in a stage rapid of development and type detection is valuable during upgrades. A server framework. The example below uses KoaJS but could just as easily be written for Express or the basic Node server. Install dependencies # Textile libraries npm install --save @textile/hub # Other utilities use in example npm install --save dotenv isomorphic-ws # Libraries specific to our server framework, koajs npm install --save koa koa-router koa-logger koa-json koa-bodyparser","title":"Setup"},{"location":"tutorials/hub/simple-credentials-endpoint/#environment-variables","text":"We'll use a .env file in the root of our project repo where you'll add your Hub API key and secret. The .env file should be added to your .gitignore so that your key and secret are never shared. Contents of .env . USER_API_KEY=alk3rlkjvl323r09fqpoweruw34 USER_API_SECRET=balkweop3jflk9f43lkjs9df2jlght94nzlkv93s Replace the example key and secret values with values you create usint the CLI","title":"Environment variables"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-the-server","text":"In our project setup, our main server is defined in src/index.ts . /** Import our server libraries */ import koa from \"koa\" ; import Router from \"koa-router\" ; import logger from \"koa-logger\" ; import json from \"koa-json\" ; import bodyParser from \"koa-bodyparser\" ; /** For using values in our .env */ import dotenv from \"dotenv\" ; /** Textile libraries */ import { Client , createAPISig , PrivateKey } from \"@textile/hub\" ; /** Read the values of .env into the environment */ dotenv . config (); /** Port our server will run */ const PORT : number = 3000 ; /** Init Koa */ const app = new koa (); /** Middlewares */ app . use ( json ()); app . use ( logger ()); app . use ( bodyParser ()); /** * Start API Routes * * All prefixed with `/api/` */ const api = new Router ({ prefix : \"/api\" , }); /** * Basic foo-bar endpoint * * https://localhost:3000/api/foo */ api . get ( \"/foo\" , async ( ctx : koa.Context , next : () => Promise < any > ) => { ctx . body = { foo : \"bar\" }; await next (); }); /** * Add credentials API here */ /** Tell Koa to use the API routes we generate */ app . use ( api . routes ()). use ( api . allowedMethods ()); /** Start the server! */ app . listen ( PORT , () => console . log ( \"Server started.\" )); We now have our basic server setup, we can run it and visit http://localhost/api/foo . ts-node src/index.ts Info Follow your Typescript setup guide for specific ways of launching the server.","title":"Create the server"},{"location":"tutorials/hub/simple-credentials-endpoint/#add-the-credentials-endpoint","text":"Next, we'll add an endpoint so the client can get new or refreshed credentials. Note the Add credentials API here location in the server code above. /** * Add credentials API here */ api . get ( \"/credentials\" , async ( ctx : koa.Context , next : () => Promise < any > ) => { // Custom validation could be done here... /** Get API authorization for the user */ const expiration = new Date ( Date . now () + 60 * seconds ); const auth = await createAPISig ( process . env . USER_API_SECRET , expiration ); /** Include the API KEY in the auth payload */ const credentials = { ... auth , key : process.env.USER_API_KEY , }; /** Return the credentials in a JSON object */ ctx . body = credentials ; await next (); }); Now when you refresh your locally running server you should be able to visit the following and receive valid credentials. http://localhost:3000/api/credentials Response: { \"key\" : \"<your user group api key>\" , \"msg\" : \"<your credentials expiration>\" , \"sig\" : \"<the api signature>\" }","title":"Add the credentials endpoint"},{"location":"tutorials/hub/simple-credentials-endpoint/#create-a-client","text":"Back in the browser, you can now make requests to your credentials endpoint. From their, each user can use the Hub token endpoint directly and begin making calls to the Hub APIs. import { Client , UserAuth } from \"@textile/hub\" ; const createCredentials = async () : Promise < UserAuth > => { const response = await fetch ( `/api/credentials` , { method : \"GET\" , }); const userAuth = await response . json (); return userAuth ; }; /** Use the simple auth REST endpoint to get API access */ console . log ( \"Verified on Textile API\" ); displayStatus (); /** The simple auth endpoint generates a user's Hub API Token */ const client = Client . withUserAuth ( createCredentials ); /** See identity tutorial */ const token = await client . getToken ( identity ); /** Now, full auth object includes the token */ auth = { ... this . auth , token : token , };","title":"Create a client"},{"location":"tutorials/hub/simple-credentials-endpoint/#github-example","text":"If you'd like to explore the examples explained above more, we've provided a fully working example on GitHub. The simple credentials endpoint is part of a more complete example, you can see it here.","title":"GitHub Example"},{"location":"tutorials/hub/user-buckets/","text":"User Buckets \u00b6 This section will cover how to share and host files with Buckets. We'll build an example that allows users of your app to post photo galleries to IPFS, IPNS, and HTTP using Buckets. Getting Started \u00b6 There are a few resources you'll need before you start writing code. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. You should already be familiar with how to create user identities and how to generate API keys. Initialize Buckets \u00b6 In your app, there are two items you'll regularly use when building with Buckets. The Buckets class object where you'll initialize an API client for your user and call bucket methods. The key of any bucket you want to interact with regularly since you'll need to tell the API which Bucket you're acting on. So, to get started in our app, we're going to do three things at once. Create a new Bucket object . Create or fetch the existing bucket of interest by name. Get the key of the bucket. Info For this tutorial, you'll be using an API key generated as part of a User Group key. It's possible to use Account Keys together with these APIs but they do not work in the same way since only Account owners (or Org members) can use them. A User Group key will allow you to create buckets for each user of your app. import { Buckets , Identity , KeyInfo } from \"@textile/hub\" ; const setup = async ( key : KeyInfo , identity : Identity ) => { // Use the insecure key to set up the buckets client const buckets = await Buckets . withKeyInfo ( key ); // Authorize the user and your insecure keys with getToken await buckets . getToken ( identity ); const result = await buckets . open ( \"io.textile.dropzone\" ); if ( ! result . root ) { throw new Error ( \"Failed to open bucket\" ); } return { buckets : buckets , bucketKey : result.root.key , }; }; Create a photo index \u00b6 If you're going to allow users to upload more than a few images or files, it can be helpful to track the metadata in an index. In our final example, we resample the photos on the fly, storing multiple sizes for better display performance. We track all those files with a simple JSON index in the root of our bucket. It would be better to store that index right in the user's Thread! But we wanted to keep this tutorial simple. import { Buckets , Identity } from \"@textile/hub\" ; const initIndex = async ( buckets : Buckets , bucketKey : string , identity : Identity ) => { // Create a json model for the index const index = { author : identity.public.toString (), date : new Date (). getTime (), paths : [], }; // Store the index in the Bucket (or in the Thread later) const buf = Buffer . from ( JSON . stringify ( index , null , 2 )); const path = `index.json` ; await buckets . pushPath ( bucketKey , path , buf ); }; Now you can update the paths each time you add new images to the bucket. In our example, we add 4 files for every image, full-res, medium-res, thumbnail, and metadata. We also update the paths with a link to the file's metadata on each update. In this way, an app can load just the single list of metadata and decide what to display. Create a public view \u00b6 Buckets are cross-protocol objects meaning that you can use them in IPFS, IPNS, or HTTP. If you want to create a public view of a bucket over HTTP, you should add an index.html to the root. In our example, we add an index.html that knows how to parse and display files based on the ./index.json stored above, in the same bucket. import { Buckets , Identity } from \"@textile/hub\" ; const addIndexHTML = async ( buckets : Buckets , bucketKey : string , html : string ) => { // Store the index.html in the root of the bucket const buf = Buffer . from ( html ); const path = `index.html` ; await buckets . pushPath ( bucketKey , path , buf ); }; Push files \u00b6 You're now ready to start pushing files to the bucket. You can push each binary file to a specific path in the bucket by using pushPath . import { Buckets , PushPathResult } from \"@textile/hub\" ; const insertFile = ( buckets : Buckets , bucketKey : string , file : File , path : string ) : Promise < PushPathResult > => { return new Promise (( resolve , reject ) => { const reader = new FileReader (); reader . onabort = () => reject ( \"file reading was aborted\" ); reader . onerror = () => reject ( \"file reading has failed\" ); reader . onload = () => { const binaryStr = reader . result ; // Finally, push the full file to the bucket buckets . pushPath ( bucketKey , path , binaryStr ). then (( raw ) => { resolve ( raw ); }); }; reader . readAsArrayBuffer ( file ); }); }; At this point, we also update our index.json with the new file. Push encrypted buckets \u00b6 If your app is providing private spaces for your users to organize their photos or files, you can also create encrypted buckets for them. The open and init methods on the Bucket class take an isEncrypted option. Your bucket start method may look like: import { Buckets } from \"@textile/hub\" ; const openEncrypted = async ( buckets : Buckets ) => { const isEncrypted = true ; const result = await buckets . open ( \"io.textile.encrypted\" , undefined , isEncrypted ); if ( ! result . root ) { throw new Error ( \"Failed to open bucket\" ); } return { buckets : buckets , bucketKey : result.root.key , }; }; Sharing encrypted buckets \u00b6 There is no way to convert encrypted Buckets to non-encrypted or vice-versa. However, it should be straight-forward to move files from an encrypted Bucket into a non-encrypted Bucket and back again. Adding multiple readers or writers to Buckets is only currently available through orgs for developers, not app users. However, we will include this ability in future releases. This is dependent on our work to implement more advanced Threads ACLs . Be aware that creating encrypted Buckets still posts files to IPFS. Meaning the encrypted contents of Buckets are still publicly available, just encrypted so not possible to view without the encryption keys. Example on GitHub \u00b6 git clone git@github.com:textileio/js-examples.git cd js-examples/bucket-photo-gallery Explore the repo Try out the gallery app built with dropzone.js and buckets.","title":"Add images to Buckets"},{"location":"tutorials/hub/user-buckets/#user-buckets","text":"This section will cover how to share and host files with Buckets. We'll build an example that allows users of your app to post photo galleries to IPFS, IPNS, and HTTP using Buckets.","title":"User Buckets"},{"location":"tutorials/hub/user-buckets/#getting-started","text":"There are a few resources you'll need before you start writing code. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. You should already be familiar with how to create user identities and how to generate API keys.","title":"Getting Started"},{"location":"tutorials/hub/user-buckets/#initialize-buckets","text":"In your app, there are two items you'll regularly use when building with Buckets. The Buckets class object where you'll initialize an API client for your user and call bucket methods. The key of any bucket you want to interact with regularly since you'll need to tell the API which Bucket you're acting on. So, to get started in our app, we're going to do three things at once. Create a new Bucket object . Create or fetch the existing bucket of interest by name. Get the key of the bucket. Info For this tutorial, you'll be using an API key generated as part of a User Group key. It's possible to use Account Keys together with these APIs but they do not work in the same way since only Account owners (or Org members) can use them. A User Group key will allow you to create buckets for each user of your app. import { Buckets , Identity , KeyInfo } from \"@textile/hub\" ; const setup = async ( key : KeyInfo , identity : Identity ) => { // Use the insecure key to set up the buckets client const buckets = await Buckets . withKeyInfo ( key ); // Authorize the user and your insecure keys with getToken await buckets . getToken ( identity ); const result = await buckets . open ( \"io.textile.dropzone\" ); if ( ! result . root ) { throw new Error ( \"Failed to open bucket\" ); } return { buckets : buckets , bucketKey : result.root.key , }; };","title":"Initialize Buckets"},{"location":"tutorials/hub/user-buckets/#create-a-photo-index","text":"If you're going to allow users to upload more than a few images or files, it can be helpful to track the metadata in an index. In our final example, we resample the photos on the fly, storing multiple sizes for better display performance. We track all those files with a simple JSON index in the root of our bucket. It would be better to store that index right in the user's Thread! But we wanted to keep this tutorial simple. import { Buckets , Identity } from \"@textile/hub\" ; const initIndex = async ( buckets : Buckets , bucketKey : string , identity : Identity ) => { // Create a json model for the index const index = { author : identity.public.toString (), date : new Date (). getTime (), paths : [], }; // Store the index in the Bucket (or in the Thread later) const buf = Buffer . from ( JSON . stringify ( index , null , 2 )); const path = `index.json` ; await buckets . pushPath ( bucketKey , path , buf ); }; Now you can update the paths each time you add new images to the bucket. In our example, we add 4 files for every image, full-res, medium-res, thumbnail, and metadata. We also update the paths with a link to the file's metadata on each update. In this way, an app can load just the single list of metadata and decide what to display.","title":"Create a photo index"},{"location":"tutorials/hub/user-buckets/#create-a-public-view","text":"Buckets are cross-protocol objects meaning that you can use them in IPFS, IPNS, or HTTP. If you want to create a public view of a bucket over HTTP, you should add an index.html to the root. In our example, we add an index.html that knows how to parse and display files based on the ./index.json stored above, in the same bucket. import { Buckets , Identity } from \"@textile/hub\" ; const addIndexHTML = async ( buckets : Buckets , bucketKey : string , html : string ) => { // Store the index.html in the root of the bucket const buf = Buffer . from ( html ); const path = `index.html` ; await buckets . pushPath ( bucketKey , path , buf ); };","title":"Create a public view"},{"location":"tutorials/hub/user-buckets/#push-files","text":"You're now ready to start pushing files to the bucket. You can push each binary file to a specific path in the bucket by using pushPath . import { Buckets , PushPathResult } from \"@textile/hub\" ; const insertFile = ( buckets : Buckets , bucketKey : string , file : File , path : string ) : Promise < PushPathResult > => { return new Promise (( resolve , reject ) => { const reader = new FileReader (); reader . onabort = () => reject ( \"file reading was aborted\" ); reader . onerror = () => reject ( \"file reading has failed\" ); reader . onload = () => { const binaryStr = reader . result ; // Finally, push the full file to the bucket buckets . pushPath ( bucketKey , path , binaryStr ). then (( raw ) => { resolve ( raw ); }); }; reader . readAsArrayBuffer ( file ); }); }; At this point, we also update our index.json with the new file.","title":"Push files"},{"location":"tutorials/hub/user-buckets/#push-encrypted-buckets","text":"If your app is providing private spaces for your users to organize their photos or files, you can also create encrypted buckets for them. The open and init methods on the Bucket class take an isEncrypted option. Your bucket start method may look like: import { Buckets } from \"@textile/hub\" ; const openEncrypted = async ( buckets : Buckets ) => { const isEncrypted = true ; const result = await buckets . open ( \"io.textile.encrypted\" , undefined , isEncrypted ); if ( ! result . root ) { throw new Error ( \"Failed to open bucket\" ); } return { buckets : buckets , bucketKey : result.root.key , }; };","title":"Push encrypted buckets"},{"location":"tutorials/hub/user-buckets/#sharing-encrypted-buckets","text":"There is no way to convert encrypted Buckets to non-encrypted or vice-versa. However, it should be straight-forward to move files from an encrypted Bucket into a non-encrypted Bucket and back again. Adding multiple readers or writers to Buckets is only currently available through orgs for developers, not app users. However, we will include this ability in future releases. This is dependent on our work to implement more advanced Threads ACLs . Be aware that creating encrypted Buckets still posts files to IPFS. Meaning the encrypted contents of Buckets are still publicly available, just encrypted so not possible to view without the encryption keys.","title":"Sharing encrypted buckets"},{"location":"tutorials/hub/user-buckets/#example-on-github","text":"git clone git@github.com:textileio/js-examples.git cd js-examples/bucket-photo-gallery","title":"Example on GitHub"},{"location":"tutorials/hub/web-app/","text":"Build a Web App using the Hub \u00b6 Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. In this section, you'll find guides on building JavaScript apps that push Threads and Buckets to the IPFS network (and beyond). We'll walk through basic setup options and how to build different types of apps. These tutorials will show you how to add interoperable, content addressed datasets to your app, how to get started with basic cryptographic identities, how to integrate your existing identity solution, and more. Getting Started \u00b6 There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. Once you have those two things, you can continue to read the overview or jump ahead to User identity to create simple user identities for the rest of the tutorial. Or, if you plan to provide your own identity setup, you can skip to the development mode setup instructions. Typescript setup \u00b6 Our examples will primarily be built using Typescript. For instructions on how to setup a Typescript app, visit here . Info With your basic Typescript web app setup, you should have a primary .ts (or .js if you decided to stick with Javascript) file where your web app exists. We'll work within this single file to start, but the instructions below should be adaptable to any application architecture. Browser, Node, or React Native? \u00b6 You can use the JavaScript libraries for all three, though there are some differences to be aware of. Browser \u00b6 Go go go! Green lights ahead. Just read the rest of the docs and get building. Node \u00b6 Some of our libraries rely on WebSockets for moving data around. WebSockets is packed in every major browser out of the box but doesn't exist in Node the same way. This can be solved by adding WebSockets to the environment. We've solved this in past examples by using isomorphic-ws . Install isomorphic-ws : npm install --save isomorphic-ws ws Add websockets to the global namespace at the start of your app: ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) See an example of that here . React Native \u00b6 The React Native environment is missing a whole number of required packages including crypto . Read the React Native tutorial's installation steps to learn how to add the necessary packages. Tutorial overview \u00b6 User identities \u00b6 Setup simple key-pair based identities for your app users. View tutorial . To secure or not to secure \u00b6 Learn how to use non-signing API keys for faster app development. View tutorial . Start building apps \u00b6 Build a photo gallery sharing app for users with Buckets. View tutorial . Add API authorization \u00b6 Add secure API keys and a login flow to your app. View tutorial .","title":"Introduction"},{"location":"tutorials/hub/web-app/#build-a-web-app-using-the-hub","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. In this section, you'll find guides on building JavaScript apps that push Threads and Buckets to the IPFS network (and beyond). We'll walk through basic setup options and how to build different types of apps. These tutorials will show you how to add interoperable, content addressed datasets to your app, how to get started with basic cryptographic identities, how to integrate your existing identity solution, and more.","title":"Build a Web App using the Hub"},{"location":"tutorials/hub/web-app/#getting-started","text":"There are a few resources you'll need before you start writing code. An account . This is your developer account on the Hub. A new Typescript web app . We recommend using Typescript, as Textile libraries are in a period rapid of development and type detection is valuable during upgrades. Once you have those two things, you can continue to read the overview or jump ahead to User identity to create simple user identities for the rest of the tutorial. Or, if you plan to provide your own identity setup, you can skip to the development mode setup instructions.","title":"Getting Started"},{"location":"tutorials/hub/web-app/#typescript-setup","text":"Our examples will primarily be built using Typescript. For instructions on how to setup a Typescript app, visit here . Info With your basic Typescript web app setup, you should have a primary .ts (or .js if you decided to stick with Javascript) file where your web app exists. We'll work within this single file to start, but the instructions below should be adaptable to any application architecture.","title":"Typescript setup"},{"location":"tutorials/hub/web-app/#browser-node-or-react-native","text":"You can use the JavaScript libraries for all three, though there are some differences to be aware of.","title":"Browser, Node, or React Native?"},{"location":"tutorials/hub/web-app/#browser","text":"Go go go! Green lights ahead. Just read the rest of the docs and get building.","title":"Browser"},{"location":"tutorials/hub/web-app/#node","text":"Some of our libraries rely on WebSockets for moving data around. WebSockets is packed in every major browser out of the box but doesn't exist in Node the same way. This can be solved by adding WebSockets to the environment. We've solved this in past examples by using isomorphic-ws . Install isomorphic-ws : npm install --save isomorphic-ws ws Add websockets to the global namespace at the start of your app: ;( global as any ). WebSocket = require ( 'isomorphic-ws' ) See an example of that here .","title":"Node"},{"location":"tutorials/hub/web-app/#react-native","text":"The React Native environment is missing a whole number of required packages including crypto . Read the React Native tutorial's installation steps to learn how to add the necessary packages.","title":"React Native"},{"location":"tutorials/hub/web-app/#tutorial-overview","text":"","title":"Tutorial overview"},{"location":"tutorials/hub/web-app/#user-identities","text":"Setup simple key-pair based identities for your app users. View tutorial .","title":"User identities"},{"location":"tutorials/hub/web-app/#to-secure-or-not-to-secure","text":"Learn how to use non-signing API keys for faster app development. View tutorial .","title":"To secure or not to secure"},{"location":"tutorials/hub/web-app/#start-building-apps","text":"Build a photo gallery sharing app for users with Buckets. View tutorial .","title":"Start building apps"},{"location":"tutorials/hub/web-app/#add-api-authorization","text":"Add secure API keys and a login flow to your app. View tutorial .","title":"Add API authorization"},{"location":"tutorials/static-websites/gatsby-site/","text":"Gatsby is an open source, free, and easy to use static site builder. Gatsby uses React and helps you deploy your website or app as a progressive web app with the smallest amount of effort. Gatsby allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Gatsby will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Gatsby site to IPFS , IPNS , and HTTP. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Gatsby. If you don't, at a minimum, you'll need to complete the Gatsby Quickstart . You should now have a basic webpage setup with Gatsby. If you have run gatsby develop , you should be able to see your website at http://localhost:8000 . Building your website \u00b6 When you run your website on your computer, Gatsby will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Gatsby will build your site into a folder public . The content of public is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Gatsby folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with gatsby build . CD into your Gatsby public directory and initialize a Bucket with textile bucket init . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Gatsby site"},{"location":"tutorials/static-websites/gatsby-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Gatsby. If you don't, at a minimum, you'll need to complete the Gatsby Quickstart . You should now have a basic webpage setup with Gatsby. If you have run gatsby develop , you should be able to see your website at http://localhost:8000 .","title":"Getting started"},{"location":"tutorials/static-websites/gatsby-site/#building-your-website","text":"When you run your website on your computer, Gatsby will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Gatsby will build your site into a folder public . The content of public is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/gatsby-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Gatsby folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with gatsby build . CD into your Gatsby public directory and initialize a Bucket with textile bucket init . That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"tutorials/static-websites/hugo-site/","text":"Hugo is a static website development framework written in Go, meaning it's fast. In fact, Hugo claims to be the fastest framework for building websites. Like many of the popular static website frameworks, Hugo allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Hugo will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Hugo site to IPFS , IPNS , and HTTP. Here's how. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Hugo. If you don't, at a minimum, you'll need to complete the Hugo Quickstart tutorial. You should now have a basic webpage setup with Hugo. If you have run hugo server -D , you should be able to see your website at http://localhost:1313 . Building your website \u00b6 When you run your site on your computer, Hugo will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Hugo will build your site into a folder public . The content of public is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Hugo folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with hugo -D . CD into your Hugo public directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Hugo site"},{"location":"tutorials/static-websites/hugo-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Hugo. If you don't, at a minimum, you'll need to complete the Hugo Quickstart tutorial. You should now have a basic webpage setup with Hugo. If you have run hugo server -D , you should be able to see your website at http://localhost:1313 .","title":"Getting started"},{"location":"tutorials/static-websites/hugo-site/#building-your-website","text":"When you run your site on your computer, Hugo will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Hugo will build your site into a folder public . The content of public is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/hugo-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Hugo folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with hugo -D . CD into your Hugo public directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"tutorials/static-websites/jekyll-site/","text":"Jekyll is one of the most popular static website building frameworks around. Bonus, Jekyll is also open-source and free. Jekyll allows you to write your content in Markdown and then compile it to HTML with a command-line tool. When you compile your website, Jekyll will create a single folder containing your final website. When you add that folder to a Textile Bucket, you can simultaneously publishing your Jekyll site to IPFS , IPNS , and HTTP. Getting started \u00b6 The rest of this post assumes that you have a basic familiarity with Jekyll. If you don't, at a minimum, you'll need to complete the Jekyll Quickstart tutorial. You should now have a basic webpage setup with Jekyll. If you have run bundle exec jekyll serve , you should be able to see your website at http://localhost:4000 . Building your website \u00b6 When you run your Jekyll site on your computer, Jekyll will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Jekyll will build your site into a folder _site . The content of _site is what you'll want to publish to your Bucket. Publish your Bucket \u00b6 First, you'll need to login to Textile and initialize a Project in the root of your Jekyll folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with Jekyll build. CD into your Jekyll _site directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Jekyll site"},{"location":"tutorials/static-websites/jekyll-site/#getting-started","text":"The rest of this post assumes that you have a basic familiarity with Jekyll. If you don't, at a minimum, you'll need to complete the Jekyll Quickstart tutorial. You should now have a basic webpage setup with Jekyll. If you have run bundle exec jekyll serve , you should be able to see your website at http://localhost:4000 .","title":"Getting started"},{"location":"tutorials/static-websites/jekyll-site/#building-your-website","text":"When you run your Jekyll site on your computer, Jekyll will dynamically render HTML from the Markdown you write. When you are ready to publish your website to the world, you need to build your website. By default, Jekyll will build your site into a folder _site . The content of _site is what you'll want to publish to your Bucket.","title":"Building your website"},{"location":"tutorials/static-websites/jekyll-site/#publish-your-bucket","text":"First, you'll need to login to Textile and initialize a Project in the root of your Jekyll folder. Download and install Textile CLI (see installation ). Init and login to Textile (see account intro ). Build your site with Jekyll build. CD into your Jekyll _site directory and initialize a Bucket with textile bucket init . Now, you are ready to push your Bucket. textile buckets push That's it! You can now view the content of your Bucket on the free domain, on the Gateway, or using IPNS.","title":"Publish your Bucket"},{"location":"users/","text":"User Mailboxes \u00b6 Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. The Hub user APIs provide tools for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Visit the GoDoc or JavaScript Users doc for a complete list of methods and more usage descriptions. Mailbox overview \u00b6 User Mailboxes provide an encrypted endpoint where encrypted messages can be left for users while they're offline. User mailboxes are designed to be used with private key based identities where each user will privately encrypt messages for recipients based on the recipient's public key. Info You can read more about creating basic PKI identities in our tutorial . A common challenge app developers face is how to exchange small, private information from one user to another. Take for example, using Threads to handle chat messages between users. Chat is a great use for Threads but faces an initial challenge: Challenge How do you send Thread invite details from one user to another, before the thread exists? Solution User mailboxes! Mailboxes allow one user of your app to encrypt and leave private messages or data for another user. Mailboxes are always online, so the user creating the message can do it immediately and the recipient can find it the next time they use your app. Sending messages \u00b6 To send messages, the sender only needs to know the recipient's public key and to be able to encrypt their message with that public key. Your app creates a new user using their identity and your Hub API key. Your app user authors a new message for a contact, based on the remote contact's public key. Your app user encrypts the message using the remote user's public key (encryption is handled by the Hub library). Your app sends the message to the remote user's inbox Receiving \u00b6 To receive messages, a user simply needs to check their inbox and decrypt any messages using their private key. Your app user checks their Hub inbox using your API key. Your user can pull any available messages (by recency or other simple filters). Any message body will be encrypted, so decrypting the message using their private key is required. The user can then read and verify that the message came from the recipient. Creating mailboxes \u00b6 A user's mailbox needs to be initialized by them (through your app) before other users can begin sending them messages. We suggest you do this as part of the onboarding steps in your app. You can read about this creation process in Go and Javascript . Using inboxes and sentboxes \u00b6 After a mailbox is set up, you can add the following methods to your application: Get an existing mailbox. Golang , JavaScript . Send messages. Golang , JavaScript . Watch inbox. Golang , JavaScript . And more! Message encryption and signing \u00b6 Messages are encrypted using the recipient's ed2559 public key, meaning that the body of the message can only be read by the private key holder. Read more about the identity utilities in the identity tutorial . Some methods you will find useful include: PrivateKey Identities Encryption by PublicKey Decrypt by PrivateKey Sign by PrivateKey Try it out \u00b6 Mailbox example A single-user example sending message to an inbox.","title":"User Mailboxes"},{"location":"users/#user-mailboxes","text":"Warning We are shutting down our hosted Hub infrastructure. Please see this deprecation notice for details. The Hub user APIs provide tools for sending and receiving messages between Hub users. Mailboxes are built on ThreadDB. Visit the GoDoc or JavaScript Users doc for a complete list of methods and more usage descriptions.","title":"User Mailboxes"},{"location":"users/#mailbox-overview","text":"User Mailboxes provide an encrypted endpoint where encrypted messages can be left for users while they're offline. User mailboxes are designed to be used with private key based identities where each user will privately encrypt messages for recipients based on the recipient's public key. Info You can read more about creating basic PKI identities in our tutorial . A common challenge app developers face is how to exchange small, private information from one user to another. Take for example, using Threads to handle chat messages between users. Chat is a great use for Threads but faces an initial challenge: Challenge How do you send Thread invite details from one user to another, before the thread exists? Solution User mailboxes! Mailboxes allow one user of your app to encrypt and leave private messages or data for another user. Mailboxes are always online, so the user creating the message can do it immediately and the recipient can find it the next time they use your app.","title":"Mailbox overview"},{"location":"users/#sending-messages","text":"To send messages, the sender only needs to know the recipient's public key and to be able to encrypt their message with that public key. Your app creates a new user using their identity and your Hub API key. Your app user authors a new message for a contact, based on the remote contact's public key. Your app user encrypts the message using the remote user's public key (encryption is handled by the Hub library). Your app sends the message to the remote user's inbox","title":"Sending messages"},{"location":"users/#receiving","text":"To receive messages, a user simply needs to check their inbox and decrypt any messages using their private key. Your app user checks their Hub inbox using your API key. Your user can pull any available messages (by recency or other simple filters). Any message body will be encrypted, so decrypting the message using their private key is required. The user can then read and verify that the message came from the recipient.","title":"Receiving"},{"location":"users/#creating-mailboxes","text":"A user's mailbox needs to be initialized by them (through your app) before other users can begin sending them messages. We suggest you do this as part of the onboarding steps in your app. You can read about this creation process in Go and Javascript .","title":"Creating mailboxes"},{"location":"users/#using-inboxes-and-sentboxes","text":"After a mailbox is set up, you can add the following methods to your application: Get an existing mailbox. Golang , JavaScript . Send messages. Golang , JavaScript . Watch inbox. Golang , JavaScript . And more!","title":"Using inboxes and sentboxes"},{"location":"users/#message-encryption-and-signing","text":"Messages are encrypted using the recipient's ed2559 public key, meaning that the body of the message can only be read by the private key holder. Read more about the identity utilities in the identity tutorial . Some methods you will find useful include: PrivateKey Identities Encryption by PublicKey Decrypt by PrivateKey Sign by PrivateKey","title":"Message encryption and signing"},{"location":"users/#try-it-out","text":"","title":"Try it out"}]}